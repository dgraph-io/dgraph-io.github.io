<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dgraph Blog</title>
    <link>https://blog.dgraph.io/post/index.xml</link>
    <description>Recent content in Posts on Dgraph Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2017, Dgraph Labs, Inc. All rights reserved.</copyright>
    <lastBuildDate>Tue, 14 Nov 2017 15:30:04 +1100</lastBuildDate>
    <atom:link href="https://blog.dgraph.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Releasing distributed transactions in v0.9</title>
      <link>https://blog.dgraph.io/post/v0.9/</link>
      <pubDate>Tue, 14 Nov 2017 15:30:04 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/v0.9/</guid>
      <description>

&lt;p&gt;&lt;strong&gt;It all started with a Github issue.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;At Dgraph, we really care about user feedback. Most of what we&amp;rsquo;ve built starting
January 2017, has been based what our community (&lt;em&gt;that&amp;rsquo;s you!&lt;/em&gt;) told us.  The
biggest contribution that we get from our community, is in the form of feedback.
We&amp;rsquo;ll forgo any code contribution for quality feedback based on real-world
usage.&lt;/p&gt;

&lt;p&gt;Since the beginning of Dgraph, transactions were road mapped as a post v1.0
feature.  Dgraph is a distributed and synchronously replicated system. Adding
transactions in such a system is a hard challenge; something that we felt
wasn&amp;rsquo;t worth the complexity to tackle early on.&lt;/p&gt;

&lt;p&gt;That changed when &lt;a href=&#34;https://twitter.com/gniemeyer&#34;&gt;Gustavo Niemeyer&lt;/a&gt; filed &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/1445&#34;&gt;this issue&lt;/a&gt;. In
this issue, he made a very convincing case for supporting transactions sooner
rather than later.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;So, coming back to Dgraph, if the idea is indeed to position it as a general
alternative for existing databases as I&amp;rsquo;ve watched in one of your videos,
please don&amp;rsquo;t make the same mistake of postponing transactions for too long,
or voicing them as relevant mainly for financial transactions. The sort of
consistency at stake is relevant for pretty much any application at all that
uses data, even more when even basic details about a record are recorded as
multiple individual terms. This would make the situation even worse than with
MongoDB. &amp;ndash;Gustavo&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The arguments made by Gustavo were intriguing enough for us to look seriously
in that direction. Once we started looking, evidence was everywhere.  People
have been complaining about lack of transactions in MongoDB. Bigtable author
and Google Fellow, Jeff Dean, considered not implementing transactions in Bigtable
his &lt;a href=&#34;http://highscalability.com/blog/2016/3/16/jeff-dean-on-large-scale-deep-learning-at-google.html&#34;&gt;&amp;ldquo;biggest mistake as an engineer&amp;rdquo;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was clear that transactions were something that we should implement right
away.&lt;/p&gt;

&lt;p&gt;So that&amp;rsquo;s what we did. We used what we call the &lt;strong&gt;Blitzkrieg approach&lt;/strong&gt;.
Explaining it can be a blog post of its own, but the general idea is that a
single or a very small set of engineers work initially to make changes deep into
the core, which would break most things minus the core (possibly one package).
And then the rest of the team helps fix up the outer shells level by level. We
use this technique regularly to implement major design changes at a lightning
speed.&lt;/p&gt;

&lt;p&gt;The entire work from the reporting of the &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/1445&#34;&gt;issue&lt;/a&gt; (Sep 13) to implementing
&lt;a href=&#34;https://blog.dgraph.io/post/badger-txn/&#34;&gt;transactions in Badger&lt;/a&gt; (Oct 5), to releasing &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases/tag/v0.9.0&#34;&gt;v0.9 with
transactions&lt;/a&gt; (on Nov 14), was done &lt;strong&gt;within a time span of two
months.&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Wow.. that&amp;#39;s an amazing turnaround time for that level of complexity. Thank you! &lt;a href=&#34;https://t.co/niILz03jw0&#34;&gt;https://t.co/niILz03jw0&lt;/a&gt;&lt;/p&gt;&amp;mdash; Gustavo Niemeyer (@gniemeyer) &lt;a href=&#34;https://twitter.com/gniemeyer/status/930459384131538944?ref_src=twsrc%5Etfw&#34;&gt;November 14, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;


&lt;p&gt;&lt;em&gt;In this blog post, we won&amp;rsquo;t go into the details of how Dgraph&amp;rsquo;s transactions
work. There&amp;rsquo;s a lot of interesting bits there, due to the uniqueness of this
challenge; so the team decided that a blog post won&amp;rsquo;t do justice to what has
gone into building this amazingly distributed graph database over the past two
years. Instead, we plan to write a technical paper about Dgraph&amp;rsquo;s unique design.
Watch for that in the coming months!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;So, instead of how it works, this blog post focuses on how to use transactions
to build your application.&lt;/p&gt;

&lt;h2 id=&#34;the-transaction-model&#34;&gt;The transaction model&lt;/h2&gt;

&lt;p&gt;Transactions come along with a new model for how to interact with Dgraph.
Previously, it has just been single queries and data mutations on their own.
Now all queries and mutations are performed as part of a transaction.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph can perform read-modify-write transactions,&lt;/strong&gt; the typical lifecycle
being:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Create a transaction. Go client: &lt;code&gt;client.NewTxn()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Execute a series of queries and mutations. Go client: &lt;code&gt;txn.Mutate(...)&lt;/code&gt; and
&lt;code&gt;txn.Query(...)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Finally, commit or abort the transaction. Go client: &lt;code&gt;txn.Commit()&lt;/code&gt; and
&lt;code&gt;txn.Abort()&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If two concurrently running transactions write to the same data, then one of the
commits will fail. It&amp;rsquo;s up to the user to retry.&lt;/p&gt;

&lt;h2 id=&#34;why-are-transactions-important&#34;&gt;Why are transactions important?&lt;/h2&gt;

&lt;p&gt;Database transactions are important for any app that needs to update its state
based upon its previous state in a consistent manner or has operations that
need to apply in atomic units.&lt;/p&gt;

&lt;p&gt;That covers a lot of different things. Just to name a few:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Marking inventory in an online shop as sold. You wouldn&amp;rsquo;t want to sell the
last remaining item to two customers.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Paying out bets on an online poker site. It&amp;rsquo;s important to ensure the same
win isn&amp;rsquo;t paid twice.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Inventory management for a warehouse. Restocking an item twice without seeing
the new quantity could result in twice as much held stock as intended.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Financial transactions. When transferring money, it&amp;rsquo;s important that credits
and debts on two accounts are either both applied or not applied at all.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dgraph v0.9 introduces &lt;strong&gt;distributed ACID transactions with synchronous
replication&lt;/strong&gt;. What this means is that transactions work across multiple servers
each holding a part of the graph, providing &lt;a href=&#34;https://en.wikipedia.org/wiki/ACID&#34;&gt;ACID&lt;/a&gt; guarantees.&lt;/p&gt;

&lt;p&gt;Increasing throughput is still just a matter of bringing up additional dgraph
instances. There is no need to worry about seeing a previous database state when
querying a replica.  From the point of view of a single client, once a
transaction is committed its changes are guaranteed to be visible in all future
transactions.  These guarantees help simplify application code significantly
while providing a high level of scalability and crash resilience.&lt;/p&gt;

&lt;h2 id=&#34;client-libraries&#34;&gt;Client Libraries&lt;/h2&gt;

&lt;p&gt;Dgraph exposes its API via gRPC and HTTP. &lt;em&gt;However&amp;hellip;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Transactions require some bookkeeping and state management on the client side.
Because of this, it&amp;rsquo;s strongly recommended to use a client library to interact
with dgraph.&lt;/p&gt;

&lt;p&gt;At the time of writing, official &lt;a href=&#34;https://docs.dgraph.io/clients/#go&#34;&gt;Go&lt;/a&gt;, &lt;a href=&#34;https://docs.dgraph.io/clients/#java&#34;&gt;Java&lt;/a&gt; and a
community-driven &lt;a href=&#34;https://github.com/calummoore/dgraph-node&#34;&gt;Javascript&lt;/a&gt; clients are available.&lt;/p&gt;

&lt;p&gt;Client libraries for other languages can be implemented on top of the gRPC or
HTTP APIs. The best way to approach this is to read the documentation about how
to use the &lt;a href=&#34;https://docs.dgraph.io/clients/#raw-http&#34;&gt;raw HTTP API&lt;/a&gt; and look at the implementations for other
existing clients.&lt;/p&gt;

&lt;p&gt;The examples in this blog post will use the Go client.&lt;/p&gt;

&lt;h4 id=&#34;a-simple-login-system&#34;&gt;A simple login system&lt;/h4&gt;

&lt;p&gt;Prior to v0.9.0 dgraph had an upsert feature which is now removed. Upsert
atomically searches and retrieves or creates and retrieves depending on whether
an entity exists or not.&lt;/p&gt;

&lt;p&gt;With transactions, an explicit upsert feature is no longer required. This is
because upsert style operations can be performed atomically within a transaction.&lt;/p&gt;

&lt;p&gt;So how is this done?&lt;/p&gt;

&lt;p&gt;In this example, we model a simple login system, where a user has to provide an
email address and password in order to gain access to the system.&lt;/p&gt;

&lt;p&gt;If the user already exists, then the password must match. If the user &lt;em&gt;doesn&amp;rsquo;t&lt;/em&gt;
yet exist, then their password should be stored for later logins.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s important to do all of this in a transaction. If it&amp;rsquo;s not, then the same
account might inadvertently be created twice.&lt;/p&gt;

&lt;p&gt;Error checking and JSON marshalling/unmarshalling have been omitted for
brevity:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;// Create a new transaction. The deferred call to Discard
// ensures that server-side resources are cleaned up.
txn := client.NewTxn()
defer txn.Discard(ctx)

// Create and execute a query to looks up an email and checks if the password
matches.
q := fmt.Sprintf(`
    {
        login_attempt(func: eq(email, %q)) {
            checkpwd(pass, %q)
        }
    }
`, email, pass)
resp, err := txn.Query(ctx, q)

// Unmarshal the response into a struct. It will be empty if the email couldn&#39;t
// be found. Otherwise it will contain a bool to indicate if the password matched.
var login struct {
    Account []struct {
        Pass []struct {
            CheckPwd bool `json:&amp;quot;checkpwd&amp;quot;`
        } `json:&amp;quot;pass&amp;quot;`
    } `json:&amp;quot;login_attempt&amp;quot;`
}
err = json.Unmarshal(resp.GetJson(), &amp;amp;login)

// Now perform the upsert logic.
if len(login.Account) == 0 {
    fmt.Println(&amp;quot;Account doesn&#39;t exist! Creating new account.&amp;quot;)
    mu := &amp;amp;protos.Mutation{
        SetJson: []byte(fmt.Sprintf(`{ &amp;quot;email&amp;quot;: %q, &amp;quot;pass&amp;quot;: %q }`, email, pass)),
    }
    _, err = txn.Mutate(ctx, mu)
    // Commit the mutation, making it visible outside of the transaction.
    err = txn.Commit(ctx)
} else if login.Account[0].Pass[0].CheckPwd {
    fmt.Println(&amp;quot;Login successful!&amp;quot;)
} else {
    fmt.Println(&amp;quot;Wrong email or password.&amp;quot;)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;bank-account-transfers&#34;&gt;Bank Account Transfers&lt;/h4&gt;

&lt;p&gt;The classical example for database transactions is to transfer money between
two bank accounts. In this example, we have a set of bank accounts, each
represented by a node in the graph. Each node is known by a uid and has its
balance represented by a &lt;code&gt;bal&lt;/code&gt; predicate.&lt;/p&gt;

&lt;p&gt;This example was extracted from a tool we used when testing the correctness of
our transaction implementation. The full source is &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/contrib/integration/bank/main.go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Given the uid of two accounts, we want to transfer money from one account to
the other, i.e. reduce one balance and increase the other by the same amount.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s important that this is done in a transaction; if it isn&amp;rsquo;t, then two
transfers happening concurrently could result in the net balance of all
accounts changing. It could also result in double spending.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;txn := s.dg.NewTxn()
defer txn.Discard(ctx)

// Get current balances for the two accounts.
q := fmt.Sprintf(`{both(func: uid(%s, %s)) { uid, bal }}`, from, to)
resp, err := txn.Query(ctx, q)
type Accounts struct {
    Both []Account `json:&amp;quot;both&amp;quot;`
}
var a Accounts
err := json.Unmarshal(resp.Json, &amp;amp;a)

// Perform the transfer.
a.Both[0].Bal += 5
a.Both[1].Bal -= 5
if a.Both[0].Bal &amp;lt; 0 || a.Both[1].Bal &amp;lt; 0 {
    // Abandon the transaction if there are insufficient funds.
    return
}

// Write back to dgraph.
var mu protos.Mutation
data, err := json.Marshal(a.Both)
mu.SetJson = data
_, err = txn.Mutate(ctx, &amp;amp;mu)
err = txn.Commit(ctx)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;It has historically been difficult to implement transactions in NoSQL
technologies. Notably, MongoDB has been
&lt;a href=&#34;https://jira.mongodb.org/browse/SERVER-11500&#34;&gt;working&lt;/a&gt; on a
&lt;a href=&#34;https://jira.mongodb.org/browse/SERVER-11508&#34;&gt;solution&lt;/a&gt; for a
&lt;a href=&#34;https://jira.mongodb.org/browse/SERVER-2804&#34;&gt;while&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So implementing transactions with synchronous replication is a massive
milestone for Dgraph. With this complex but valuable feature, our community
will be able to build apps on top of dgraph without having to worry about
tricky data integrity issues!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/sites/default/files/thumbnails/image/neutron_star_merger_still_3.jpg&#34;&gt;When (Neutron) Stars Colide&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Loading close to 1M edges/sec into Dgraph</title>
      <link>https://blog.dgraph.io/post/bulkloader/</link>
      <pubDate>Mon, 09 Oct 2017 17:09:10 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/bulkloader/</guid>
      <description>

&lt;p&gt;We&amp;rsquo;re seeing more and more users who want to load massive data sets into
&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;. Many users want to load billions of edges, and some even want to load
up to 50 billion edges! When we heard about the size of these datasets, we knew
we needed to have a solid data loading story so that we could support the most
extreme demands from our users.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.dgraph.io/post/scaling-dgraph/&#34;&gt;In a previous blog post&lt;/a&gt;, we
discussed some of the challenges that we met on our journey towards loading
massive datasets into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;.  In this post, we will discuss an alternate
approach that has yielded significantly faster loading times.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR:&lt;/strong&gt; &lt;em&gt;We created a new tool called &lt;a href=&#34;https://docs.dgraph.io/deploy/#dgraph-bulk-loader&#34;&gt;Bulkloader&lt;/a&gt; to populate Dgraph with
an initial dataset.  It&amp;rsquo;s highly performant and is able to load the entire
&lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;Stack Overflow dataset&lt;/a&gt; in just
over 1 hour on a single 64 core machine. The Stack Overflow dataset is massive
and consists of ~2 billion RDFs. An additional ~1 billion edges are created for
indexing and other internal usages.  This gives&lt;/em&gt; &lt;strong&gt;~3 billion edges&lt;/strong&gt; &lt;em&gt;in
total. This equates to a loading rate of&lt;/em&gt; &lt;strong&gt;~820k edges per second!&lt;/strong&gt; &lt;em&gt;Note
that we had a significant skew in the predicate distribution which slowed the
load down (all the text for questions, answers and comments was on the same
predicate). Better results can likely be achieved on datasets with a more even
predicate distribution.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;previous-approach&#34;&gt;Previous approach&lt;/h2&gt;

&lt;p&gt;All of our previous approaches have involved writing batch mutations to a
running &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; instance. This is a convenient approach; we just have to
iterate over the RDFs we want to load, batch them up, then send them to Dgraph.&lt;/p&gt;

&lt;p&gt;We were able to achieve over 50k edges per second, which is really good
throughput for a live system. But doing so seemed insufficient when you&amp;rsquo;re
starting out with billions of edges and just want to bulk load them up into a
new Dgraph instance.&lt;/p&gt;

&lt;p&gt;Our previous approaches at speeding up the loading process had a focus on
performance improvements to Dgraph&amp;rsquo;s mutation handling capabilities. We made
great strides here, facing some tough challenges related to memory management
along the way. Ultimately we hit some speed roadblocks though. We had to
propose the mutations via Raft, which would write to a WAL for durability (to
deal with crashes) and achieve consensus for consistency. We also needed to
read the key to merge the new mutations coming in. Some of these keys
(particularly index keys) were in such high demand that they&amp;rsquo;d become
stragglers for the entire bulk load operation.&lt;/p&gt;

&lt;p&gt;A key observation about loading massive datasets is that Dgraph does not have
to be live while the loading happens. This is because loading large
amounts of data is usually a step taken by users when migrating from another
database technology stack (whether a graph database or otherwise).&lt;/p&gt;

&lt;p&gt;Because Dgraph doesn&amp;rsquo;t have to be up and running while data is being loaded,
this opens up lots of avenues for alternate (&lt;strong&gt;faster!&lt;/strong&gt;) approaches.&lt;/p&gt;

&lt;p&gt;This is where Bulkloader comes in. It&amp;rsquo;s a new program that performs the initial
population of a &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; instance. It runs very quickly and scales well on
high-end hardware.&lt;/p&gt;

&lt;h2 id=&#34;the-new-approach&#34;&gt;The new approach&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.dgraph.io/deploy/#dgraph-bulk-loader&#34;&gt;Bulkloader&lt;/a&gt; utilises the map/shuffle/reduce paradigm. The diagram below shows
the data flow through the system, from RDFs in files all the way to posting
lists stored in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;&amp;rsquo;s key-value store).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/bulkloader_map_shuffle_reduce.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a lot going on here, so let&amp;rsquo;s break it down:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The map phase takes RDFs as its input. It creates the edges that will
eventually become part of the final Dgraph instance. Each RDF can correspond
to one or more edges. The additional edges are for indexing and reverse edge
traversal. Each edge is output along with the key of the posting list it will
eventually become part of (this combination of edge and posting list key is
referred to as a &lt;em&gt;map entry&lt;/em&gt;). Map entries are bundled up into reasonably sized
batches (e.g. 100MB), sorted, then written out to disk in &lt;em&gt;map files&lt;/em&gt;.
Sorting is only &lt;em&gt;local&lt;/em&gt; for each map file since edges can be split
between the map files in arbitrary ways. The sorting is important, and critical
to the speed of the shuffler.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The shuffle phase combines all map files into a single globally sorted stream
of map entries. Because each map file is sorted internally, a min heap data
structure can be used to quickly assemble the stream.  The stream is then
broken up into batches that are passed on to the reduce phase.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The reduce phase takes batches of sorted map entries from the shuffle phase.
It collects up groups of map entries with the same posting list key and then
builds the corresponding posting list. To do this, the reducer iterates through
the batch and generates a posting list whenever the posting list key changes.
The posting lists are then written directly to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;&amp;rsquo;s key-value
store.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are some additional complexities in the architecture that aren&amp;rsquo;t shown in
the diagram. These are all related to bottlenecks in the processing where all
data must flow through a single point or exclusive access to a single resource
is needed. The bottlenecks don&amp;rsquo;t show themselves when running on regular
quad-core machines but are must be removed in order to achieve full hardware
utilization on high-end machines (e.g. machines with 64 cores).&lt;/p&gt;

&lt;h3 id=&#34;sharded-uid-map&#34;&gt;Sharded UID Map&lt;/h3&gt;

&lt;p&gt;The first bottleneck is in the map phase. As part of this phase, blank nodes
must be mapped to 64-bit UIDs. The first time a particular blank node (a
string) is seen, a new UID must be assigned. When that blank node is seen again
in a subsequent RDF, the same UID must be used. Since the input RDF files can
be split up in any arbitrary way, the same blank node could be processed by two
different mappers that are running concurrently. Because of this, the management
of UID assignment must be shared between all mappers.&lt;/p&gt;

&lt;p&gt;The original design was to use a map (from &lt;code&gt;string&lt;/code&gt; to &lt;code&gt;uint64&lt;/code&gt;) protected by a
mutex. With many concurrent mappers (e.g. 64), profiling showed large amounts
of contention on the lock.&lt;/p&gt;

&lt;p&gt;We solved this problem by using a &lt;em&gt;sharded map&lt;/em&gt;. The idea is to break the map
into two levels. The first level is a fixed size array e.g. of length 256. A
hash of the key determines which entry in the array to use.  Each array element
is a mutex and a regular hash map, which stores the final &lt;code&gt;string&lt;/code&gt; to &lt;code&gt;uint64&lt;/code&gt;
mapping (i.e. a single &lt;em&gt;shard&lt;/em&gt; of the sharded map). Assuming the hash function
gives a reasonable key distribution, access is spread out evenly among the
different map shards, and contention is no longer a problem.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/bulkloader_map.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;more-shufflers&#34;&gt;More Shufflers&lt;/h3&gt;

&lt;p&gt;Another bottleneck in the program is the shuffling. The architecture diagram
above just shows a single shuffler for simplicity. This was the original
design and showed up as a bottleneck when running on a machine with 64
cores. All data has to flow through a single code path in a single thread in
order to get a globally sorted stream of map entries.&lt;/p&gt;

&lt;p&gt;The reason we wanted a globally sorted stream was so that the reducer could
quickly scan the stream and assemble posting lists from entries with the same
posting list key.&lt;/p&gt;

&lt;p&gt;The solution was to split up the entire &lt;a href=&#34;https://docs.dgraph.io/deploy/#dgraph-bulk-loader&#34;&gt;Bulkloader&lt;/a&gt; into shards, separated by
predicates. Since edges with different predicates can never appear in the same
posting list, this is safe to do. There are a separate set of map entry files
for each shard that can be picked up by multiple shufflers, 1 per shard. If
there are more predicates than the requested number of shards, then multiple
predicates are placed in each shard. Automatic predicate balancing results in
shards that are as evenly sized as possible.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/bulkloader_shards.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;multiple-badgers&#34;&gt;Multiple Badgers&lt;/h3&gt;

&lt;p&gt;For big datasets, users typically want to split up the data among multiple
servers. So splitting the output from multiple shufflers into multiple
Badgers allows us to produce multiple shards of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;; which a user can
use to run a Dgraph cluster.&lt;/p&gt;

&lt;p&gt;This also significantly improves the reduce phase, because multiple Badgers are
concurrently being written to. So many badgers!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/many_badgers.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;show-me-the-numbers&#34;&gt;Show me the numbers&lt;/h2&gt;

&lt;p&gt;We used &lt;a href=&#34;https://docs.dgraph.io/deploy/#dgraph-bulk-loader&#34;&gt;Bulkloader&lt;/a&gt; to load the entire &lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;Stack Overflow
dataset&lt;/a&gt; in just over 1 hour.&lt;/p&gt;

&lt;p&gt;Machine details:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;i3.16xlarge AWS machine.&lt;/li&gt;
&lt;li&gt;64 cores.&lt;/li&gt;
&lt;li&gt;488GB RAM.&lt;/li&gt;
&lt;li&gt;NVMe SSD.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bulkloader performance:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Total runtime: 1 hr and 4 min.&lt;/li&gt;
&lt;li&gt;RDF count: 1.950 billion.&lt;/li&gt;
&lt;li&gt;Edge count: 3.161 billion.&lt;/li&gt;
&lt;li&gt;Map phase speed: 1.767 million edges per second.&lt;/li&gt;
&lt;li&gt;Reduce phase speed: 1.525 million edges per second.&lt;/li&gt;
&lt;li&gt;Total speed: 0.818 million edges per second.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.dgraph.io/deploy/#dgraph-bulk-loader&#34;&gt;Bulkloader&lt;/a&gt; is super fast, and we recommend it as the way to do the initial
data loading for new &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; instances.&lt;/p&gt;

&lt;p&gt;It is available from Dgraph v0.8.3 onwards.&lt;/p&gt;

&lt;p&gt;There are lots of different knobs and dials that can be tweaked to get maximum
performance out of different hardware setups (look at the output when using the
&lt;code&gt;--help&lt;/code&gt; flag). You can have a look at the code for the bulkloader &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/cmd/dgraph-bulk-loader&#34;&gt;here&lt;/a&gt;.  Give it
a go and be amazed!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/sites/default/files/thumbnails/image/pia21438.jpg&#34;&gt;Cassini spacecraft near
Saturn.&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Concurrent ACID Transactions in Badger</title>
      <link>https://blog.dgraph.io/post/badger-txn/</link>
      <pubDate>Thu, 05 Oct 2017 13:30:16 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/badger-txn/</guid>
      <description>

&lt;p&gt;When we started working on &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, the aim was to keep things stupid simple. We needed to get rid of Cgo from Dgraph codebase, while also building something which can perform really well. We wanted to create it for ourselves and the broader Go community. Go has been a language of choice for many databases, and providing a performant native Go key-value store seemed like a win for everyone.&lt;/p&gt;

&lt;p&gt;As &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is gaining popularity, we see the limitations of our initial choices. The choice to not add transactions caused issues for many users. In fact, that&amp;rsquo;s something we are witnessing in Dgraph as well. So, we decided to support transactions in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (and successively in Dgraph).&lt;/p&gt;

&lt;p&gt;For a good design, we spent time reading through six popular papers on the subject. In particular, Yabandeh&amp;rsquo;s &lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2168853&#34;&gt;A Critique of Snapshot Isolation&lt;/a&gt; provided a sound basis for allowing execution of transactions concurrently, delivering &lt;a href=&#34;https://en.wikipedia.org/wiki/Snapshot_isolation&#34;&gt;serializable snapshot isolation&lt;/a&gt;, avoiding write-skews. While this paper is designed for distributed systems, its applicability extends to any single node system wanting to support concurrent transactional execution.&lt;/p&gt;

&lt;h2 id=&#34;acid-transactions&#34;&gt;ACID Transactions&lt;/h2&gt;

&lt;p&gt;Transactions in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; execute concurrently. When they start, they pick up a read timestamp from an in-memory &lt;code&gt;oracle&lt;/code&gt;.  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; now supports &lt;a href=&#34;https://en.wikipedia.org/wiki/Multiversion_concurrency_control&#34;&gt;MVCC&lt;/a&gt;, so all reads are done based on this timestamp. As reads are performed, we store a fingerprint of the key (fingerprint instead of the key to save space. In a very rare case, this can lead to a false negative conflict detection, aborting a transaction, requiring a retry).  In a read-only transaction, we avoid tracking reads altogether. This prevents a memory blowup if you are taking a snapshot or backup of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As writes are performed in the transaction, we maintain an internal cache of these writes within the transaction. Thus, any follow up reads on the same key by this transaction would see this write. But, other transactions won&amp;rsquo;t, providing &lt;strong&gt;Isolation and Consistency.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Finally, when &lt;code&gt;Commit&lt;/code&gt; is called, we send our read fingerprints to Oracle and ask for a commit timestamp. Oracle will check if the read rows have since been updated (&lt;code&gt;row commit ts &amp;gt; txn read ts&lt;/code&gt;). If so, it would return a conflict, and the transaction would abort. This is indicated by Commit method returning an &lt;code&gt;ErrConflict&lt;/code&gt; error.&lt;/p&gt;

&lt;p&gt;If no conflict were detected, Oracle would assign a new unique commit timestamp, and update a local in-memory commit map with all the written keys&amp;rsquo; fingerprints and this commit timestamp. Thus, any future commits would be checked against these updates for conflict detection. Note that even if the transaction fails later (due to a write to disk failure), having this commit record in memory doesn&amp;rsquo;t cause any logical issues.&lt;/p&gt;

&lt;p&gt;At this point, each key is suffixed with the commit timestamp, to provide &lt;a href=&#34;https://en.wikipedia.org/wiki/Multiversion_concurrency_control&#34;&gt;multiversion concurrency control&lt;/a&gt;. Thus, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; won&amp;rsquo;t overwrite any data.&lt;/p&gt;

&lt;p&gt;Once we have a commit timestamp, the writes from this and other transactions are queued in a channel, batched up, and written to value log. Once value log write is successful, we are assured of &lt;strong&gt;Durability.&lt;/strong&gt; In case of a crash, a value log replay would be able to pick up these transactions.&lt;/p&gt;

&lt;p&gt;Once written to value log, the LSM tree would be updated, making these writes visible to future transactions.  If writing to value log fails, however, the writes won&amp;rsquo;t make it to LSM tree, and the transaction is abandoned.  Because LSM tree wasn&amp;rsquo;t updated, the writes won&amp;rsquo;t be visible to any other transaction, thus ensuring &lt;strong&gt;Atomicity.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Oracle keeps track of commit-pending transactions in a min heap. Once the transaction is successfully committed, Oracle would advance its read timestamp.  Any new transactions would now start from this version.&lt;/p&gt;

&lt;p&gt;This particular strategy is different from Yabandeh&amp;rsquo;s paper, where typically locks are acquired upfront on the keys which are written. Given &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; isn&amp;rsquo;t a distributed database and isn&amp;rsquo;t marred by the unreliability of network, we could simplify the implementation considerably by using a min heap to update read timestamp.&lt;/p&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;To quickly benchmark the performance of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; writes, we wrote 1M key-value pairs, values being of different sizes. &lt;em&gt;We set synchronous writes to true.&lt;/em&gt; We ran this for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, Bolt, and LMDB.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/txnwrites.png&#34; alt=&#34;1M keys written benchmark&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In absolute numbers, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; wrote 1M keys with 128B and 1kB value in 10 and 16 seconds. For 16kB values, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; took 1m20s to write 1M keys.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s write throughput using ACID transactions was at least 2-5x faster than Bolt. Compared to LMDB, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; was 2x quicker in two of the three test cases.&lt;/p&gt;

&lt;p&gt;You can see the spreadsheet &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1LVbKvsFDzEvL7X0Ig35JkUCaQyqFFu1FuLO9OwTnN0E/edit?usp=sharing&#34;&gt;here&lt;/a&gt;, and the benchmark log &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/blob/master/write_benchmarks&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is a huge API change in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. In fact, we ripped up all the existing APIs from &lt;code&gt;KV struct&lt;/code&gt;, into the new &lt;code&gt;Txn struct&lt;/code&gt;. While doing so, we also got rid of certain APIs like &lt;code&gt;CompareAndSet&lt;/code&gt; and &lt;code&gt;SetIfAbsent&lt;/code&gt;, which are no longer required given transactions. At the same time, we&amp;rsquo;re renamed &lt;code&gt;Badger.KV&lt;/code&gt; to &lt;code&gt;Badger.DB&lt;/code&gt;, which at this point, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is. &lt;strong&gt;An ACID compliant database providing concurrent transactions and serializable snapshot isolation.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We hope you enjoy these changes and use &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; in your project!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/goddard/hubble-view-of-a-galaxy-resembling-an-atomic-nucleus&#34;&gt;Hubble View of a Galaxy Resembling an Atomic Nucleus&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>[Opinion] SQL is not beating NoSQL. NoSQL is evolving.</title>
      <link>https://blog.dgraph.io/post/sql-vs-nosql/</link>
      <pubDate>Tue, 03 Oct 2017 13:20:35 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/sql-vs-nosql/</guid>
      <description>&lt;p&gt;Ajay Kulkarni, the co-founder of Timescale DB wrote an article about “&lt;a href=&#34;https://blog.timescale.com/why-sql-beating-nosql-what-this-means-for-future-of-data-time-series-database-348b777b847a&#34;&gt;Why SQL is beating NoSQL&lt;/a&gt;,” which became an instant hit. He made a compelling case about how SQL is making a comeback, citing Google Spanner and CockroachDB.&lt;/p&gt;

&lt;p&gt;The analysis was mostly agreeable, except for one major flaw. It is not SQL which is making a comeback, its NoSQL which is morphing into providing a familiar interface.&lt;/p&gt;

&lt;p&gt;Bigtable and MapReduce were developed to deal with an enormous amount of data at Google. I was part of Google’s incremental indexing system, &lt;a href=&#34;https://googleblog.blogspot.com.au/2010/06/our-new-search-index-caffeine.html&#34;&gt;Caffeine&lt;/a&gt;. A single distributed Bigtable instance handled petabytes of web data with new information being added at the rate of hundreds of terabytes per day. A feat like this is unachievable by any SQL system popular even today.&lt;/p&gt;

&lt;p&gt;Typical SQL database has not changed. It is still a single instance, scaling which is pain and requires application side complexity. There’s a real need for scalable systems, something that traditional SQL systems still haven’t evolved to provide. We do not have a distributed MySQL or a distributed Postgres.&lt;/p&gt;

&lt;p&gt;A learning curve is commonly cited as a counter to new entrants to database world (also made by Kulkarni).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;“Each NoSQL database offered its own unique query language, which meant: more languages to learn”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;I do not buy it.&lt;/strong&gt; Most companies add new tech despite the unfamiliarity of their devs. Redis, Elastic Search, Memcache are (or at least recently were) all unfamiliar technologies that are commonly part of a typical tech stack.&lt;/p&gt;

&lt;p&gt;In fact, contradictory arguments are used in both ways. Devs like &lt;em&gt;“everything new and shiny,”&lt;/em&gt; and at the same time, &lt;em&gt;“learning curve limits adoption.”&lt;/em&gt; Both arguments were made by Kulkarni on why NoSQL became big and why it did not, respectively. Both fail to understand and explain the NoSQL movement.&lt;/p&gt;

&lt;p&gt;As I write this, MongoDB has &lt;a href=&#34;https://techcrunch.com/2017/09/21/database-provider-mongodb-has-filed-to-go-public/&#34;&gt;filed to go public&lt;/a&gt;. &lt;em&gt;This is a huge success for any database company!&lt;/em&gt; Developers use Mongo not just because it is new and shiny (well, it no longer is new), but because it solves real problems for them.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;So what has changed?&lt;/strong&gt; What changed is a result of lessons learned by NoSQL folks. Jeff Dean, the Google fellow behind MapReduce and Bigtable, said that not supporting distributed transactions in Bigtable &lt;a href=&#34;http://nosql.mypopescu.com/post/2082849662/distributed-transactions-matter-googles-jeff&#34;&gt;was a mistake&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In fact, many projects were using Megastore at Google despite poor write throughput, because it added transactions on top of Bigtable. Caffeine itself used transactions via &lt;a href=&#34;https://research.google.com/pubs/pub36726.html&#34;&gt;Percolator&lt;/a&gt;. So Spanner was an evolution of Bigtable to provide distributed transactions. Four of Bigtable authors worked on Spanner, including Jeff Dean and Sanjay Ghemawat.&lt;/p&gt;

&lt;p&gt;Once you evolve a NoSQL database into providing MVCC and transactions, then adding a SQL based query language is not hard. However, it could be any other interface. &lt;strong&gt;The interface does not matter.&lt;/strong&gt; What matters is the fact that scalability &lt;strong&gt;and&lt;/strong&gt; transactions are important. Bigtable traded off transactional access for scalability, something that Cassandra and MongoDB went on to copy. That and lack of joins is the primary cause of discontent among NoSQL developers.&lt;/p&gt;

&lt;p&gt;So, like Spanner is an evolution of Bigtable, CockroachDB is an evolution of MongoDB. SQL has not changed or made a comeback, or beaten NoSQL. NoSQL has morphed into something developers have come to expect from their databases, namely transactions and joins.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/phytoplankton-bloom-in-the-north-atlantic&#34;&gt;Phytoplankton Bloom in the North Atlantic&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Learn the basics of GraphQL&#43;-, now available on video</title>
      <link>https://blog.dgraph.io/post/basics-graphql/</link>
      <pubDate>Mon, 02 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/basics-graphql/</guid>
      <description>&lt;p&gt;Dgraph has its own custom query language based on GraphQL, called GraphQL+-. You can learn about the basics of GraphQL+- in our latest screencast that introduces you to writing queries in it, which can be found right below. The screencast will explore the content in the &lt;a href=&#34;https://tour.dgraph.io/basic/1/&#34;&gt;interactive tour it compliments&lt;/a&gt;, but in further depth. You can also &lt;a href=&#34;https://www.youtube.com/channel/UCghE41LR8nkKFlR3IFTRO4w?sub_confirmation=1&#34;&gt;subscribe to our YouTube channel&lt;/a&gt; if you would like to be posted when we release new videos.&lt;/p&gt;

&lt;p&gt;The screencast will cover topics such as:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Querying data&lt;/li&gt;
&lt;li&gt;Basic schema&lt;/li&gt;
&lt;li&gt;Multilingual support&lt;/li&gt;
&lt;li&gt;Functions and filtering&lt;/li&gt;
&lt;li&gt;Logical operators&lt;/li&gt;
&lt;li&gt;Sorting&lt;/li&gt;
&lt;li&gt;Directives like &lt;code&gt;@cascade&lt;/code&gt; and &lt;code&gt;@normalize&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/VM7METe3N3Q&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;If you’re hungry to learn more about Dgraph, you can check out the other tours here at &lt;a href=&#34;https://tour.dgraph.io/&#34;&gt;https://tour.dgraph.io/&lt;/a&gt; or find the full documentation at &lt;a href=&#34;https://docs.dgraph.io/&#34;&gt;https://docs.dgraph.io/&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/images/content/534909main_displayatlantisinspace.jpg&#34;&gt;Space shuttle Atlantis at the International Space Station during STS-132 via NASA&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Badger vs LMDB vs BoltDB: Benchmarking key-value databases in Go</title>
      <link>https://blog.dgraph.io/post/badger-lmdb-boltdb/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/badger-lmdb-boltdb/</guid>
      <description>

&lt;p&gt;If you have been following us, you may know that we &lt;a href=&#34;https://blog.dgraph.io/post/badger/&#34;&gt;released
Badger&lt;/a&gt; a few months ago. Badger is a simple, efficient, and
persistent key-value store, written in &lt;a href=&#34;http://n-gate.com/hackernews/2017/05/14/&#34;&gt;&lt;em&gt;a hipster language&lt;/em&gt;&lt;/a&gt;. Even though
it is not at v1.0 yet, we have already received a great response from the
community. As of writing, Badger has 2350 stars &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;on Github&lt;/a&gt;, and
there have been
&lt;a href=&#34;https://www.reddit.com/r/golang/comments/6b57aa/badger_a_faster_kv_store/&#34;&gt;lots&lt;/a&gt;
&lt;a href=&#34;https://www.reddit.com/r/golang/comments/6jm2db/badger_fastest_keyvalue_store_in_go/&#34;&gt;of&lt;/a&gt; &lt;a href=&#34;https://news.ycombinator.com/item?id=14335931&#34;&gt;discussions&lt;/a&gt; online
since the release announcement.&lt;/p&gt;

&lt;p&gt;Our &lt;a href=&#34;https://blog.dgraph.io/post/badger/&#34;&gt;launch post&lt;/a&gt; contained benchmarks evaluating Badger against &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;.
RocksDB was the store we were using before we decided to replace it and write
our own, so it made sense to benchmark against it. However, a lot of
people &lt;a href=&#34;https://twitter.com/tobym/status/882760757615759361&#34;&gt;have&lt;/a&gt; &lt;a href=&#34;https://www.reddit.com/r/golang/comments/6jm2db/badger_fastest_keyvalue_store_in_go/&#34;&gt;been&lt;/a&gt; &lt;a href=&#34;https://twitter.com/hyc_symas/status/884001285879599104&#34;&gt;curious&lt;/a&gt; about how Badger fares against stores like
&lt;a href=&#34;https://symas.com/lmdb/&#34;&gt;LMDB&lt;/a&gt; and &lt;a href=&#34;https://github.com/boltdb/bolt&#34;&gt;BoltDB&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the launch post, we had mentioned that recent improvements
to SSDs might make B+-trees a viable option for high write throughput.
Also, the reason B+ trees are considered good for reads is that they have low read
amplification. Badger&amp;rsquo;s design also provides for a significantly lower read
amplification compared to other LSM tree based key-value stores. So, we decided
it was worth benchmarking Badger against these stores.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;It will be helpful if you have read our &lt;a href=&#34;https://blog.dgraph.io/post/badger/&#34;&gt;earlier post&lt;/a&gt; from when
we launched Badger, but it is not required.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Based on our benchmarks,&lt;/strong&gt; Badger is at least 1.7✕-22.3✕ faster than LMDB and BoltDB
when doing random writes. Sorted range iteration is a bit slower when value
size is small, but as value sizes increase, Badger is 4✕-111✕ times faster. On
the flip side, Badger is currently up to 1.9✕ slower when doing random reads.&lt;/p&gt;

&lt;p&gt;Thus, Badger&amp;rsquo;s unique design significantly outperforms these stores on write
throughput and iteration latency, while being only slightly slower when it comes
to random reads.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;some-notes-about-architecture&#34;&gt;Some notes about architecture&lt;/h2&gt;

&lt;h3 id=&#34;lmdb-and-boltdb&#34;&gt;LMDB and BoltDB&lt;/h3&gt;

&lt;p&gt;BoltDB started out as a port of LMDB to Go but has somewhat diverged since then.
While LMDB heavily focuses on raw performance, Bolt has focused on simplicity
and ease of use. However, they both share the same design, so describing LMDB should
be sufficient.&lt;/p&gt;

&lt;p&gt;LMDB provides a key-value stored using &lt;a href=&#34;https://en.wikipedia.org/wiki/B%2B_tree&#34;&gt;B+ trees&lt;/a&gt;. It has ACID
semantics and support for transactions. It does not do any background work and
has a crash resilient design that uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Multiversion_concurrency_control&#34;&gt;MVCC&lt;/a&gt; instead of locking. This means readers
operate on an isolated snapshot of the database and don’t block. The codebase
is quite small and portable, so LMDB runs across multiple platforms including
Android, BSD, and Solaris. This &lt;a href=&#34;https://www.youtube.com/watch?v=tEa5sAh-kVk&amp;amp;t=10s&#34;&gt;talk by Howard Chu&lt;/a&gt; at Databaseology
2015 goes into much more details about LMDB’s design.&lt;/p&gt;

&lt;p&gt;It is generally understood that B+ tree based stores are ideal for workloads
which are read intensive.&lt;/p&gt;

&lt;h3 id=&#34;badger&#34;&gt;Badger&lt;/h3&gt;

&lt;p&gt;Badger belongs to a family of key-value stores that are characterized by a
design that uses a &lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;log-structured merge-tree&lt;/a&gt; (LSM tree). Popular
stores in this category include &lt;a href=&#34;https://github.com/google/leveldb&#34;&gt;LevelDB&lt;/a&gt; and &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;LSM tree based stores provide high write performance by sequentially writing
key-value pairs in memory in the foreground, and then arranging them in
multi-tiered levels on disk in the background. This approach is not without
tradeoffs though. Values are written multiple times when arranging them in the
tree (known as &lt;em&gt;write amplification&lt;/em&gt;) and a single read might need to read
multiple levels in the LSM tree before finding a value (known as &lt;em&gt;read
amplification&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Badger’s design is based on a paper titled &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;‘WiscKey: Separating Keys
from Values in SSD-conscious Storage’&lt;/a&gt; (referred to as the WISCKEY
paper from now on). Here is an excerpt from the paper touching on the key
design aspects:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“To realize an SSD-optimized key-value store,
WiscKey includes four critical ideas. First, WiscKey separates keys from
values, keeping only keys in the LSM-tree and the values in a separate log
file. Second, to deal with unsorted values (which necessitate random access
during range queries), WiscKey uses the parallel random-read characteristic of
SSD devices. Third, WiscKey utilizes unique crash-consistency and
garbage collection techniques to efficiently manage the value log. Finally,
WiscKey optimizes performance by removing the LSM-tree log without sacrificing
consistency, thus reducing system-call overhead from small writes.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;Badger&amp;rsquo;s design reduces both the read and write amplification&lt;/strong&gt; seen in other LSM
tree based stores. Keys tend to be much smaller in size than values, so by
separating keys from values and prefix-diffing the keys, Badger significantly
reduces the size of LSM tree.
Badger does not acquire any global mutex locks, allowing reads to happen
concurrently while writes are going on, to achieve a high read-write throughput.
It is very crash resilient, as we tested and explained in &lt;a href=&#34;https://blog.dgraph.io/post/alice/&#34;&gt;this blog
post&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While there are differences in implementation, design details are available
in &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;the paper&lt;/a&gt;. It also contains a good overview of LSM trees and databases
using them.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&#34;benchmarking&#34;&gt;Benchmarking&lt;/h2&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;The benchmarking setup was identical to the one we used when benchmarking
Badger &lt;a href=&#34;https://blog.dgraph.io/post/badger/&#34;&gt;against RocksDB&lt;/a&gt;. Therefore the numbers should be
comparable as well. We have made many optimizations, fixes, and improvements to
Badger since, which should reflect in the numbers below.&lt;/p&gt;

&lt;h3 id=&#34;methodology&#34;&gt;Methodology&lt;/h3&gt;

&lt;p&gt;To benchmark the stores, we measured 4 things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Data loading performance&lt;/strong&gt;:  Populating the database with a pre-specified
number of keys.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Output Size&lt;/strong&gt;: Size of the data set on disk.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Random Key Lookup Performance&lt;/strong&gt;: Generating a random key and reading its
value from the fully populated store (&lt;em&gt;this was done several million times
using Go benchmarking tools, and an average was taken&lt;/em&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sorted Range Iteration Performance&lt;/strong&gt;: Iterating through 2 million keys in
sorted order.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We performed benchmarks on 3 different data sets, varying the number of keys
and the value size (in bytes) associated with the keys.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Value Size (bytes)&lt;/th&gt;
&lt;th&gt;Num Keys (Each Key = 22 bytes)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Data Set 1&lt;/td&gt;
&lt;td&gt;128&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data Set 2&lt;/td&gt;
&lt;td&gt;1024 (1kb)&lt;/td&gt;
&lt;td&gt;75M&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data Set 3&lt;/td&gt;
&lt;td&gt;16384 (16kb)&lt;/td&gt;
&lt;td&gt;5M&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;hardware&#34;&gt;Hardware&lt;/h4&gt;

&lt;p&gt;All benchmarks were done on a dedicated AWS EC2 i3.large instance (us-east-2
region) running Ubuntu Server 16.04 LTS (HVM) with 16GB RAM. This instance
comes with a locally mounted 470GB SSD drive. The benchmarks were performed on
data stored on the local SSD, which provides 100K IOPS with 4KB block sizes.
Note that the root and home directories are mounted on EBS storage which has
very low IOPS.&lt;/p&gt;

&lt;p&gt;We deliberately chose an instance with RAM size (16GB) lesser than the data set
sizes. This provides a good setup for benchmarking and is representative of our
use-cases for Badger, where data sizes are several times the size of RAM
available.&lt;/p&gt;

&lt;h4 id=&#34;software&#34;&gt;Software&lt;/h4&gt;

&lt;h5 id=&#34;lmdb&#34;&gt;&lt;strong&gt;LMDB&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;We used the &lt;a href=&#34;https://github.com/bmatsuo/lmdb-go&#34;&gt;lmdb-go&lt;/a&gt; bindings to LMDB, which comes with its own embedded copy
of the lmdb C source code. It is the most up to date binding available in Go
and is &lt;a href=&#34;https://godoc.org/github.com/bmatsuo/lmdb-go/lmdb&#34;&gt;well documented&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thanks to Howard Chu&lt;/strong&gt; for looking at the benchmarking code for lmdb-go. He
helped us &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/pull/5&#34;&gt;tune the code&lt;/a&gt;, and also &lt;a href=&#34;https://github.com/bmatsuo/lmdb-go/issues/118#issuecomment-325449496&#34;&gt;pointed
out&lt;/a&gt; that we should be using &lt;code&gt;lmdb.NoReadahead&lt;/code&gt; flag
in our benchmarks when data size is larger than RAM.&lt;/p&gt;

&lt;p&gt;We ran into a couple of issues with LMDB APIs:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Several hours into populating data into LMDB for one of our benchmarks, we
suddenly saw a crash. After investigation, we realized that LMDB needs a
configuration value for the &lt;a href=&#34;https://godoc.org/github.com/bmatsuo/lmdb-go/lmdb#Env.SetMapSize&#34;&gt;maximum map size&lt;/a&gt; of the database.
This needs to be determined upfront while opening the database. LMDB will not expand
automatically as data size increases. To get around it, we set it to a
calculated large number and re-populated the data.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;During our initial benchmarking runs, the hit ratio (found vs. miss) and hence
read performance of LMDB was significantly affected by the value of
GOMAXPROCS. We could not figure out why this was happening. This issue got
compounded by an oversight in our code which was correctly handling error
inside the view transaction, but not outside it. A few days into this issue,
we fixed the error handling and realized that a large number of reads were
failing, because the maximum number of concurrent readers had to be set
explicitly, using the &lt;a href=&#34;https://godoc.org/github.com/bmatsuo/lmdb-go/lmdb#Env.SetMaxReaders&#34;&gt;&lt;code&gt;SetMaxReaders&lt;/code&gt;&lt;/a&gt; API function.  &lt;strong&gt;From a
Go perspective, this is strange.&lt;/strong&gt; This would require tracking how many
concurrent reads are going on at a given moment, and restrict them to a
pre-specified number. In a highly concurrent Go based system like Dgraph, this
would be a severe limitation. We got around the limitation by setting the
maximum number of readers to a number based on the benchmarks.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While none of these limitations are deal breakers, they do present unfamiliar
obstacles for a Go programmer using LMDB.  In comparison, BoltDB and Badger
do not require you to specify a maximum map size, or a maximum number of readers in
advance.&lt;/p&gt;

&lt;h5 id=&#34;bolt&#34;&gt;&lt;strong&gt;Bolt&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;We used the BoltDB source &lt;a href=&#34;https://github.com/boltdb/bolt&#34;&gt;hosted on Github&lt;/a&gt;. Note that there is a
fork of BoltDB, called &lt;a href=&#34;https://github.com/coreos/bbolt&#34;&gt;bbolt&lt;/a&gt; maintained by CoreOS. However, we decided to stick to
the original version which is considered complete by its maintainer. We did not
run into any issues when using BoltDB APIs. They are clean and well documented.&lt;/p&gt;

&lt;h5 id=&#34;badger-1&#34;&gt;&lt;strong&gt;Badger&lt;/strong&gt;&lt;/h5&gt;

&lt;p&gt;We ran the benchmarks against code in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger repo&lt;/a&gt; on Github, at
commit &lt;a href=&#34;https://github.com/dgraph-io/badger/tree/64df7f57d9ee20d7b28de4a3eea90bf8d7310a77&#34;&gt;64df7f5&lt;/a&gt;. This included a significant change in
the way we read the value log, where we switched from using standard file I/O
to memory-mapping the files before reading. We will cover this in more detail
in the sections below.&lt;/p&gt;

&lt;h4 id=&#34;code&#34;&gt;Code&lt;/h4&gt;

&lt;p&gt;All the benchmarking code and results are available on Github in the
&lt;a href=&#34;https://github.com/dgraph-io/badger-bench&#34;&gt;badger-bench&lt;/a&gt; repo. To make the benchmarks transparent and repeatable, we have
recorded all the steps in detail in our &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/blob/master/BENCH-lmdb-bolt.md&#34;&gt;benchmarking log&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;Numbers and charts can also be found in &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1Hz9XHk8v45qHhjr2DwXhblrhtg7pMim-GRLYNqRKCK0/edit?usp=sharing&#34;&gt;this spreadsheet&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;data-loading&#34;&gt;Data Loading&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/data-loading.png&#34;&gt;&lt;img src=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/data-loading.png&#34; alt=&#34;Data loading performance&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The results of this benchmark are pretty unequivocal. &lt;strong&gt;Badger is significantly
faster than both LMDB and BoltDB in loading data.&lt;/strong&gt; The factor of speedup ranges
from 1.7✕ to 22.3✕. Bolt DB degrades pretty badly in the 16kb data set with a
throughput of only 32000 key-value pairs a minute.&lt;/p&gt;

&lt;p&gt;B+ trees do not have very good write performance, and these benchmarks
support that claim. Writing KV pairs randomly to Bolt or LMDB leads to a lot
of random seeks on the disk. Badger, on the other hand, writes to an LSM tree where all writes are sequential. Moreover, the actual values are written in a log elsewhere using sequential writes. This leads to much better disk utilization and throughput.&lt;/p&gt;

&lt;p&gt;Some additional technical notes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Badger provides an API method called &lt;a href=&#34;https://godoc.org/github.com/dgraph-io/badger#KV.BatchSet&#34;&gt;&lt;code&gt;BatchSet&lt;/code&gt;&lt;/a&gt; which
batches up a series of writes to the value log. This can significantly speed
up bulk-loading. BoltDB and lmdb-go do not have an equivalent API.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;BoltDB provides an API method called &lt;a href=&#34;https://godoc.org/github.com/boltdb/bolt#DB.Batch&#34;&gt;&lt;code&gt;Batch()&lt;/code&gt;&lt;/a&gt;, which can be
used to achieve some concurrency while writing to it. The results
above are using this call, but we did not notice a very significant
difference for this specific benchmark.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;lmdb-go has a limitation in its API when it comes to writing to the
store using multiple goroutines. Here is what the &lt;a href=&#34;https://godoc.org/github.com/bmatsuo/lmdb-go/lmdb#hdr-Caveats&#34;&gt;API docs
say&lt;/a&gt;: &lt;em&gt;Write transactions (those created without the
&lt;code&gt;Readonly&lt;/code&gt; flag) must be created in a goroutine that has been locked to its
thread by calling the function &lt;code&gt;runtime.LockOSThread&lt;/code&gt;. Furthermore all
methods on such transactions must be called from the goroutine which created
them. This is a fundamental limitation of LMDB even when using the &lt;a href=&#34;https://godoc.org/github.com/bmatsuo/lmdb-go/lmdb#hdr-Environment&#34;&gt;NoTLS&lt;/a&gt;
flag (which the package always uses).&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;data-set-size&#34;&gt;Data Set Size&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/data-size.png&#34;&gt;&lt;img src=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/data-size.png&#34; alt=&#34;Data set size&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;We did not notice any patterns w.r.t. final data set sizes among the stores.
Bolt and LMDB store data in one large file and keys and values are stored
together. Badger stores data in two different kinds of files: one for LSM data
which contains keys and pointer to values, and value log files which contain the
actual values.&lt;/p&gt;

&lt;h4 id=&#34;random-key-lookup&#34;&gt;Random Key Lookup&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/random-lookup.png&#34;&gt;&lt;img src=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/random-lookup.png&#34; alt=&#34;Random Key Lookup latency&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;LMDB has the lowest read latencies&lt;/strong&gt; across all the data sets.
Badger goes neck-to-neck against LMDB in 1kB value, but in
other values are up to 2x slow.
BoltDB, on the other hand, has lower latencies than Badger for the 128B and 16kB
datasets but shows higher latency in the 1kB data set.&lt;/p&gt;

&lt;p&gt;We were pleasantly surprised by these results. &lt;strong&gt;Badger holds pretty well&lt;/strong&gt;
against both the stores, never performing particularly worse than others, and at
least in one instance, beating BoltDB. This is a particularly important feat
because random key lookup is the weakest spot for LSM based KV stores.  LSM-tree
suffers from read-amplification. It needs to look for the key in multiple places
before returning.&lt;/p&gt;

&lt;p&gt;Badger&amp;rsquo;s design handles read amplification in two ways. It first significantly
reduces the size of LSM tree by separating keys from values, and secondly,
minimizes the latency by keeping the (much smaller) LSM tree entirely in RAM.
This makes Badger much faster than other LSM-tree based key-value stores like
RocksDB and a lot more competitive with B+-trees.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note that LMDB was slower in our initial benchmarks before Howard Chu &lt;a href=&#34;https://github.com/bmatsuo/lmdb-go/issues/118#issuecomment-325449496&#34;&gt;pointed
out&lt;/a&gt; that we should be setting the
&lt;code&gt;lmdb.NoReadahead&lt;/code&gt; flag when opening the store. This got us thinking, and we
realized that this could apply to Badger as well. We already had a feature
request to memory-map the value log files. We decided to &lt;a href=&#34;https://github.com/dgraph-io/badger/commit/b9aae1b3895c41176770406d66d6614bf525f80f&#34;&gt;give that a
shot&lt;/a&gt;, and also disabled readahead using the &lt;code&gt;madvise&lt;/code&gt; system
call. When we ran the benchmarks for the 16kB dataset after this change, we
were able to reduce the latency from  22µs to 3.8µs.&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;sorted-range-iteration&#34;&gt;Sorted Range Iteration&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/range-iteration.png&#34;&gt;&lt;img src=&#34;https://blog.dgraph.io/images/lmdb-bolt-bench/range-iteration.png&#34; alt=&#34;Sorted range iteration&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For the data store with 128B value size, Badger is about 1.5✕-1.6✕ slower than
lmdb-go and BoltDB. However, Badger’s performance improves as value sizes get
bigger. &lt;strong&gt;Badger is anywhere between 4✕-111✕ times faster&lt;/strong&gt; when iterating over
data stores with 1kb and 16kb value size. Badger’s design allows it to prefetch
values in the background during iteration. This is controlled by an option and
is enabled by default. The &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WISCKEY paper&lt;/a&gt; touches upon this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;“To make range queries efficient, WiscKey leverages
the parallel I/O characteristic of SSD devices to prefetch
values from the vLog during range queries. The underlying
idea is that, with SSDs, only keys require special
attention for efficient retrieval. So long as keys are retrieved
efficiently, range queries can use parallel random
reads for efficiently retrieving values.”&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In our &lt;a href=&#34;https://blog.dgraph.io/post/badger/&#34;&gt;launch post&lt;/a&gt;, we mentioned that there were shortcomings with iteration in
Badger because we were unable to realize the high SSD IOPS via Go. After much
&lt;a href=&#34;https://groups.google.com/forum/#!topic/golang-nuts/jPb_h3TvlKE/discussion&#34;&gt;discussion and digging&lt;/a&gt;, we realized that setting
GOMAXPROCS to a high enough number (say 128), allows us to realize the high
IOPS, making Badger significantly faster for key-value iterations.&lt;/p&gt;

&lt;p&gt;Badger’s iterator API also allows what we call &lt;strong&gt;&lt;em&gt;key-only&lt;/em&gt; iteration.&lt;/strong&gt; In this
mode, we iterate only over the LSM tree and do not read the values in the value
log files at all. This means that most of the time, iterations do not touch the
disk and happen blazingly fast. This functionality is unique to Badger among
all the other key-value stores compared.&lt;/p&gt;

&lt;p&gt;Key-only iterations are very useful in various applications which only need to
iterate over keys, for splitting tablets or estimating data sizes based on key
prefixes. At Dgraph, we use them to estimate the size of tablets, run filters and only
retrieve values for a much smaller subset of keys.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;LMDB&lt;/strong&gt; implementation in Go outperformed both BoltDB and Badger in terms of
random read latency, but was significantly slower for sorted range iteration
and had several mind-boggling API limitations. If you have a random read
intensive workload, LMDB Go might be a suitable store for you.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;BoltDB&lt;/strong&gt; didn&amp;rsquo;t really stand apart in any of the four criteria. It was the
slowest in data loading, fell well behind Badger in sorted range iteration
(though outperformed LMDB), and gave conflicting results w.r.t. random key lookup.
However, it did have a clean and well-documented APIs and supports ACID
transactions.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;One of the big reasons&lt;/strong&gt; we wrote Badger was that we were having difficulty understanding the behavior of Cgo APIs accessing RocksDB
  from within Go. Using a store written in pure Go allows better visibility
  into what’s going on using Go’s profiling tools. It also allows more
  convenient control over concurrent operations using Go’s native support for
  goroutines. So BoltDB and Badger might be better choices over LMDB in this scenario.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Badger&lt;/strong&gt; significantly outperformed its competition in both write throughput and
sorted range iteration. It performed slightly worse in random key lookup but
did not deteriorate in performance as badly as competition did in other
categories.  For a workload which has a mix of reads and writes in any
proportion (even 90-10), Badger is a &lt;strong&gt;clear choice.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;further-work&#34;&gt;Further Work&lt;/h2&gt;

&lt;p&gt;At this point, the biggest aim for Badger is to stabilize the API and bring it
past v1.0. Various projects like &lt;a href=&#34;https://ipfs.io/&#34;&gt;IPFS&lt;/a&gt; use Badger, and there&amp;rsquo;s an outstanding
Github issue to integrate Badger with &lt;a href=&#34;https://github.com/blevesearch/bleve/issues/591&#34;&gt;Bleve&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Also, we are considering adding transactional support into Badger.
So, if you think it would be useful to you, &lt;a href=&#34;https://github.com/dgraph-io/badger/issues/230&#34;&gt;let us know&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;parting-thoughts&#34;&gt;Parting thoughts&lt;/h2&gt;

&lt;p&gt;In this post, we have done a comprehensive survey of how &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; compares
against two popular options for key-value stores in Go. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is still quite
new, and we are excited about what lies ahead for the project.&lt;/p&gt;

&lt;p&gt;We put months of effort into ensuring the benchmarks were impartial, correctly
set up and executed. Many a times this process was laborious and frustrating, but we
were excited about the possibility of learning a few things from other
key-value stores and improving Badger; &lt;em&gt;which we did&lt;/em&gt;.  These benchmarks make us
even more convinced of the effort that Dgraph team has put into building Badger
from scratch. We have built a solid offering not only to be used within Dgraph,
but for anyone looking for a key-value store in Go.&lt;/p&gt;

&lt;p&gt;We would love to hear from you regarding what you think we should be focusing
on in the future. If you have any comments or questions, please head to
&lt;a href=&#34;https://discuss.dgraph.io/t/badger-vs-lmdb-vs-boltdb-benchmarking-key-value-databases-in-go-dgraph-blog/1777&#34;&gt;discuss.dgraph.io&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/jpl/pia21778/jupiter-a-new-point-of-view&#34;&gt;Jupiter: A new point of view&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Making Badger Crash Resilient with ALICE</title>
      <link>https://blog.dgraph.io/post/alice/</link>
      <pubDate>Mon, 14 Aug 2017 13:21:25 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/alice/</guid>
      <description>

&lt;p&gt;Crashes can occur for many different reasons and can manifest themselves in
many different forms. A program can experience a segfault or uncaught
exception.  If it&amp;rsquo;s running on Linux, a kernel panic could occur.  If on
Windows, a STOP error could occur, displaying the infamous
&lt;a href=&#34;https://en.wikipedia.org/wiki/Blue_Screen_of_Death&#34;&gt;BSOD&lt;/a&gt;.  Even then, crashes
aren&amp;rsquo;t the only thing you have to worry about. The UPS could fail (or be
absent), or the power could go out.  Someone could be walking through the data
center and trip over a power cord.  In short, any program can terminate
prematurely and unexpectedly.&lt;/p&gt;

&lt;p&gt;When a database crashes, what happens to your data? If your database has a high
level of crash resilience, your data is safe. The database can be started up
again, and you&amp;rsquo;re pretty much good to go. You might have to rerun the last few
mutations you made before the crash, but for the most part, your data is still
intact. But what about databases with low levels of crash resilience? I &lt;em&gt;hope&lt;/em&gt;
you make regular backups, because your database might not even start up.&lt;/p&gt;

&lt;p&gt;At Dgraph Labs, current efforts are being spent ramping up towards a 1.0
version of our flagship product, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;.
&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; is already very stable, but we
want to go the extra mile and make it robust and rock solid, even under rare
and unlikely scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; relies on
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (our key value store) to persist
its data. This is an obvious place to look when it comes to making the whole
system resilient against crashes.  This blog post will explore the area of
crash resilience. It will look at a tool called ALICE, and how we used it to
improve the crash resilience of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; contains a write ahead value log,
which is replayed when &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up.
You can read more about the internals of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;
&lt;a href=&#34;https://open.dgraph.io/post/badger/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The design of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is based on a paper
titled &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WiscKey: Separating Keys from Values in SSD-conscious
Storage&lt;/a&gt;.
This paper discusses a property of modern file systems that aids in creating
crash resilient systems:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[There is] an interesting property of modern file systems (such as ext4,
btrfs, and xfs). &amp;hellip;  Consider a file that contains [a] sequence of bytes &amp;hellip;
and the user appends &amp;hellip; to it. If a crash happens, &amp;hellip; only some prefix of the
appended bytes will be added to the end of the file. &amp;hellip; It is not possible for
random bytes or a non-prefix subset of the appended bytes to be added to the
file.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We wanted to use this interesting file system property to improve
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.  Specifically, to increase the
crash resilience of the value log.&lt;/p&gt;

&lt;p&gt;We decided to add an entry checksum to each value log entry. The idea was that
this would enable us to detect short appends during log file replay so that we
could truncate the value log at the end of the last good entry and continue
with the normal start up procedure.&lt;/p&gt;

&lt;p&gt;This task was one of the &lt;a href=&#34;https://github.com/dgraph-io/badger/pull/148&#34;&gt;first things that I worked
on&lt;/a&gt; when I started at Dgraph Labs
a couple of weeks ago.&lt;/p&gt;

&lt;h2 id=&#34;enter-alice&#34;&gt;Enter ALICE&lt;/h2&gt;

&lt;p&gt;After adding checksums to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, I
started looking at papers from the same authors as the WiscKey paper. I came a
cross a paper titled &lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;All File Systems Are Not Created Equal&lt;/a&gt;: On the Complexity
of Crafting Crash-Consistent
Applications.
This paper describes a &lt;a href=&#34;https://github.com/madthanu/alice&#34;&gt;tool called ALICE&lt;/a&gt;
(Application-Level Intelligent Crash Explorer), written by the authors.  ALICE
discovers crash vulnerabilities in programs. A crash vulnerability is a bug in a
program that manifests itself when the program starts up after a system crash.
The main use of ALICE is to help programmers make their programs more robust and
resilient to crashes. ALICE will be explained in greater detail later in this
blog post.&lt;/p&gt;

&lt;p&gt;ALICE helped identify two different crash vulnerabilities in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; and even hinted towards how those
vulnerabilities could be fixed. Despite having minimal experience with the
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; code base, I was able to identify
and implement those fixes.  This is a testament to the usefulness of ALICE as a
tool (although the simplicity of the
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; codebase helped a lot here!).&lt;/p&gt;

&lt;p&gt;I learned a lot about file systems and Linux system calls while working with
ALICE. Some things I already intuitively knew, but other things were totally
surprising.&lt;/p&gt;

&lt;h2 id=&#34;what-could-go-wrong-when-you-modify-a-file&#34;&gt;What could go wrong when you modify a file?&lt;/h2&gt;

&lt;p&gt;Say you have a file named &lt;code&gt;f&lt;/code&gt; on disk. It contains the sequence of bytes &lt;code&gt;ABC&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You then have a C program that operates on the file. The intent of the file is
to change the content to &lt;code&gt;12345&lt;/code&gt;. The program isn&amp;rsquo;t crash resilient though;
under certain crash scenarios, the file could end up having content &lt;em&gt;other&lt;/em&gt;
than &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;f&amp;quot;, O_RDWR | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 close(fd);
# Boilerplate and error checking left out for brevity.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So if the program crashes part way through, what possible states could the file
&lt;code&gt;f&lt;/code&gt; be in? For each of the following possible states, think about whether the
state is possible or not.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;12345&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is now empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;123&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC$9&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Take a few seconds and think about the possible states before reading on.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Alright! Let&amp;rsquo;s go through the possibility of the states.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;States 1 and 2&lt;/strong&gt; are not only possible, they&amp;rsquo;re intended. They&amp;rsquo;re the only
allowable states if the program is to be 100% resilient to crashes. State 1 can
occur if the program crashes before opening the file. State 2 can occur if the
crash occurs after the close.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 3&lt;/strong&gt; is possible. It can occur if the program crashes after the call to
&lt;code&gt;open&lt;/code&gt; but before the &lt;code&gt;write&lt;/code&gt; call is persisted to disk. Note that the
&lt;code&gt;O_TRUNC&lt;/code&gt; flag truncates the file to zero length when the file is opened.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 4&lt;/strong&gt; is not possible. The file &lt;code&gt;f&lt;/code&gt; will always exist on disk in some form.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 5&lt;/strong&gt; is possible. Writes are not atomic and can be batched up in arbitrary
sized chunks (although the size is usually much larger than a few bytes).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 6&lt;/strong&gt; is a strange case, but surprisingly, possible! How does that
happen? It appears as though garbage data was appended to the file!&lt;/p&gt;

&lt;p&gt;This disk state is possible because writes are sometimes executed as two
parallel operations.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The data content is written.&lt;/li&gt;
&lt;li&gt;The size of the file is updated.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If a crash occurs at precisely the wrong time, the change to the file size may
be persisted to disk without the additional data being written.&lt;/p&gt;

&lt;p&gt;This even happens in modern file systems such as &lt;em&gt;ext4&lt;/em&gt; (although only in
writeback mode). So if you&amp;rsquo;re the author of a program that writes to files and
you care about crash resilience, this is something you should design your
program around.&lt;/p&gt;

&lt;p&gt;So how can we get around these problems? A common idiom is to create a
temporary file, write the new content to it, then rename it to the old file.
&lt;strong&gt;But&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-could-go-wrong-when-you-rename-a-file&#34;&gt;What could go wrong when you rename a file?&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 close(fd);
04 rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are some crash states where the
file &lt;code&gt;f&lt;/code&gt; contains content other than &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;. Below are the same set
crash states as before. Again, think about whether each crash
state is possible or not.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;12345&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is now empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;123&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC$9&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Pause for a moment to consider the possible states before reading on.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Okay! Let&amp;rsquo;s go through the different possibilities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;States 1 and 2&lt;/strong&gt; are still possible. That&amp;rsquo;s good, it means we don&amp;rsquo;t have a
regression.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 3&lt;/strong&gt; is still possible. It can occur when &lt;code&gt;rename&lt;/code&gt; on line 4 persists to
disk before the &lt;code&gt;write&lt;/code&gt; on line 2 (and the crash occurs before the write
persists). The calls to &lt;code&gt;write&lt;/code&gt; and &lt;code&gt;rename&lt;/code&gt; are not guaranteed to persist in
order.&lt;/p&gt;

&lt;p&gt;Notably, the &lt;code&gt;close&lt;/code&gt; &lt;em&gt;doesn&amp;rsquo;t force the file contents to be persisted to disk.&lt;/em&gt;
There is a common misconception among programmers that closing a file flushes
to disk, but this is not true.  This is the behaviour for C as well as some
higher level languages such as &lt;a href=&#34;https://golang.org/pkg/os/#File&#34;&gt;Go&lt;/a&gt; and
&lt;a href=&#34;https://docs.python.org/2/library/stdtypes.html#file-objects&#34;&gt;Python&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the &lt;a href=&#34;https://linux.die.net/man/2/close&#34;&gt;man page&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A successful close does not guarantee that the data has been successfully saved
to disk, as the kernel defers writes. It is not common for a file system to
flush the buffers when the stream is closed. If you need to be sure that the
data is physically stored use fsync(2). (It will depend on the disk hardware at
this point.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 4&lt;/strong&gt; is not possible. This is because &lt;code&gt;rename&lt;/code&gt; is atomic, so there will
never be a case where &lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 5&lt;/strong&gt; is possible; after crashing the file may contain only &lt;code&gt;123&lt;/code&gt;. The first
part of the &lt;code&gt;write&lt;/code&gt; on line 2 could persist, then the file could be renamed. If
the crash occurs before the final part of the &lt;code&gt;write&lt;/code&gt; persists, then &lt;code&gt;123&lt;/code&gt; would
be the result.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 6&lt;/strong&gt; could also occur. This is similar to state 5. The rename may be
persisted before the write. The write may only partially persist before the
crash, leaving the file size updated without the data being written.&lt;/p&gt;

&lt;p&gt;Notice that the set of bad crash states is the same as before&amp;hellip;  So in a
certain sense, the program has become more complicated but can still break in
the same ways. &lt;em&gt;Not to fear though,&lt;/em&gt; with one small tweak we can fix everything!&lt;/p&gt;

&lt;p&gt;We need one more system call to fix the program. Remember how &lt;code&gt;close&lt;/code&gt; doesn&amp;rsquo;t
flush the file content to disk? The man page gave an important hint, &lt;code&gt;fsync&lt;/code&gt;!&lt;/p&gt;

&lt;h2 id=&#34;sync-as-a-solution&#34;&gt;Sync as a solution&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;fsync&lt;/code&gt; flushes all pending &lt;code&gt;write&lt;/code&gt;s through any buffers and persists them to
physical disk. It&amp;rsquo;s a blocking call, and doesn&amp;rsquo;t return until the data is
completely persisted.  There are equivalents in higher level languages. In Go
it&amp;rsquo;s &lt;a href=&#34;https://golang.org/pkg/os/#File.Sync&#34;&gt;File.Sync&lt;/a&gt;, and in Python it&amp;rsquo;s
&lt;a href=&#34;https://golang.org/pkg/os/#File.Sync&#34;&gt;os.fsync&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So how does it help? Let&amp;rsquo;s alter the program again. It&amp;rsquo;s the same as before,
except that we use &lt;code&gt;fsync&lt;/code&gt; after the write.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 fsync(fd);
04 close(fd);
05 rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;re getting somewhere! The temp file is created and has &lt;code&gt;12345&lt;/code&gt; written
to it. The sync causes the data to be persisted to disk. Only then is the file
renamed. The file &lt;code&gt;f&lt;/code&gt; cannot end up empty since the &lt;code&gt;write&lt;/code&gt; now &lt;em&gt;has to&lt;/em&gt;
persist before the &lt;code&gt;rename&lt;/code&gt;. For the same reason, the file can&amp;rsquo;t end up with
&lt;code&gt;123&lt;/code&gt; or &lt;code&gt;ABC$9&lt;/code&gt;. No matter how the program crashes, &lt;code&gt;f&lt;/code&gt; will always either
contain &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;. Neat!&lt;/p&gt;

&lt;h2 id=&#34;back-to-alice&#34;&gt;Back to ALICE&lt;/h2&gt;

&lt;p&gt;In simple programs like the ones above, it&amp;rsquo;s &lt;em&gt;possible&lt;/em&gt; to identify and fix
crash resilience problems manually, &lt;em&gt;so long as you understand all of the
limitations and guarantees that file systems provide&lt;/em&gt;. For large programs like
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, it&amp;rsquo;s much more difficult.
Luckily, the process becomes easier with the aid of tooling.&lt;/p&gt;

&lt;p&gt;ALICE is one such tool that can help find crash vulnerabilities. You still need
to understand the limitations and guarantees of the file system to use the
tool, but it &lt;em&gt;does&lt;/em&gt; do most of the heavy lifting when it comes to the
identification of problems.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So how does it work?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ALICE works by executing a &lt;em&gt;workload&lt;/em&gt; (supplied by the user). This starts up
the application-under-test and makes it perform various operations.  ALICE
records the system calls made by the program, including the details of all file
system manipulations.  Using the record of those system calls, it is able to
create all of the possible crash states that could occur. To do this, it takes
into consideration all of the legal reorderings of the file system
manipulations made by the program-under-test. For each crash states,
ALICE runs a &lt;em&gt;checker&lt;/em&gt; (also supplied by the user).  The checker tests to see
if the crash state is permissible i.e. the program-under-test can start up,
recover from the crash, and continue from where it left off.&lt;/p&gt;

&lt;p&gt;So what does this look like for the &lt;code&gt;ABC&lt;/code&gt; -&amp;gt; &lt;code&gt;12345&lt;/code&gt; example?&lt;/p&gt;

&lt;p&gt;The workload is just the program that changes the content of the file (we start
with the &lt;em&gt;incorrect&lt;/em&gt; attempt at the program):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main()
{
    int fd = open(&amp;quot;f&amp;quot;, O_RDWR | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5);            // assert(ret == 5);
    ret = close(fd);                            // assert(ret == 0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What about the checker? It simply checks the consistency constraints that we
expect the program to maintain. It can be written in any language, e.g. Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
import sys

crashed_state_directory = sys.argv[1]
os.chdir(crashed_state_directory)
assert open(&#39;f&#39;).read() in [&#39;ABC&#39;, &#39;12345&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When ALICE is run, its output indicates that there are some crash
vulnerabilities:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_before_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The output indicates that there is a problem if the file is truncated, but
&lt;em&gt;not&lt;/em&gt; appended to.&lt;/p&gt;

&lt;p&gt;When we run the second version of the program, we get a different report from
ALICE.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main() {
    int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5); // assert(ret == 5);
    ret = close(fd);                 // assert(ret == 0);
    ret = rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);        // assert(ret == 0);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_intermediate_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This time, ALICE indicates that the ordering of system calls is not guaranteed.
Specifically, the rename may persist before the append.&lt;/p&gt;

&lt;p&gt;Once the problem with the program is fixed (the &lt;code&gt;fsync&lt;/code&gt; call added), ALICE
reports that there are no errors:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main() {
    int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5); // assert(ret == 5);
    ret = fsync(fd);                 // assert(ret == 0);
    ret = close(fd);                 // assert(ret == 0);
    ret = rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);        // assert(ret == 0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_final_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Excellent! The program is now free of crash vulnerabilities.&lt;/p&gt;

&lt;p&gt;As part of their
&lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;research&lt;/a&gt;, the
authors of ALICE checked various key value stores and databases for crash
vulnerabilities. We decided to put
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; through the same paces. There
were two main motivations for this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To see how &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; stacks up against
other existing key value stores.&lt;/li&gt;
&lt;li&gt;To find (&lt;em&gt;and fix!&lt;/em&gt;) any crash vulnerabilities in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;testing-badger-with-alice&#34;&gt;Testing Badger with ALICE&lt;/h2&gt;

&lt;p&gt;The
&lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/workload/workload.go&#34;&gt;workload&lt;/a&gt;
and
&lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/checker/checker.go&#34;&gt;checker&lt;/a&gt;
are a little bit more complicated for
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. The workload inserts some
key/value pairs, then updates them several times. The checker then ensures that
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can start up after the simulated
crash.&lt;/p&gt;

&lt;p&gt;In order to test as many code paths in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; as possible, we needed the
workload to trigger both &lt;em&gt;LSM tree compaction&lt;/em&gt; and a &lt;em&gt;value log garbage
collection&lt;/em&gt;. LSM tree compactions are necessary to allow the high write
throughput possible with the design. Value log garbage collection rewrites
value log files to reclaim disk space, discarding stale entries in the process.&lt;/p&gt;

&lt;p&gt;In order to coax &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; into performing
both of the above, Badger&amp;rsquo;s parameters &lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/util/util.go#L14-L26&#34;&gt;are set
up&lt;/a&gt;
so that it will aggressively trigger them, even for small data writes.&lt;/p&gt;

&lt;p&gt;When ALICE was first run over &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;,
the output indicated quite a few problems:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering value log garbage collection:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_before_badger.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering LSM tree compaction:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_lsm_compaction_before.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The long list of problems from the output only corresponds to two different
vulnerabilities, which are discussed in detail in the next sections.&lt;/p&gt;

&lt;p&gt;To put &lt;em&gt;two crash vulnerabilities&lt;/em&gt; into perspective, we can compare to the
number of vulnerabilities that were found by the ALICE authors in other
programs, as documented
&lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;in the paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/crash_vulnerability_comparison.png&#34; alt=&#34;comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; does considerably better than
some other database style applications, even those that are backed by large
organisations, e.g.:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google&amp;rsquo;s Leveldb: 6 crash vulnerabilities.&lt;/li&gt;
&lt;li&gt;GNU&amp;rsquo;s GDBM: 5 crash vulnerabilities.&lt;/li&gt;
&lt;li&gt;HSQLDB: 10 crash vulnerabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another thing to note is that at Dgraph Labs, we&amp;rsquo;re actively seeking out
resources to make our products the best that they can be. When you&amp;rsquo;re writing
world class software, behaving reactively and waiting for the bug reports to
roll in, just isn&amp;rsquo;t an option!&lt;/p&gt;

&lt;p&gt;So what does the ALICE output mean, and how does it translate into actual crash
vulnerabilities?&lt;/p&gt;

&lt;h2 id=&#34;crash-vulnerability-1-garbage-writes&#34;&gt;Crash Vulnerability #1 - Garbage Writes&lt;/h2&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; appends to a value log file,
it just does a normal appending &lt;code&gt;write&lt;/code&gt;. As seen previously, a crash during or
shortly after an append can result in the file containing some garbage data.&lt;/p&gt;

&lt;p&gt;In the ALICE output:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul1_trace.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul1_vulns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ALICE is able to generate crash states containing garbage by artificially
injecting garbage bytes into the ends of the recorded writes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a little bit confusing though.&lt;/em&gt; Recall that this was a known problem
that was previously &amp;lsquo;solved&amp;rsquo; by adding a checksum to the end of each value log
entry. While replaying a value log, if an entry&amp;rsquo;s checksum doesn&amp;rsquo;t match up, we
assume that the value log is corrupted and truncate it. So why are garbage
writes causing crashes in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;? They
should just be discarded.&lt;/p&gt;

&lt;p&gt;Unfortunately, ALICE doesn&amp;rsquo;t give any clues. It doesn&amp;rsquo;t show the output of the
checker, it just indicates that it failed.  I had to hack the ALICE source code
to leave the crash states on disk, rather than cleaning them up at the end of
its execution. I could then iterate over the crash states myself, manually
checking how &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; reacts when it starts up.&lt;/p&gt;

&lt;p&gt;Once I did this, it was obvious what the problem was. For some crash states,
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; terminated with an out of memory
error. The stack traces indicated the problem was occurring in the value log
replay code.&lt;/p&gt;

&lt;h4 id=&#34;vulnerability&#34;&gt;Vulnerability&lt;/h4&gt;

&lt;p&gt;The vulnerability occurs when the key and value lengths in a value log entry
header contain garbage data. These lengths are used to figure out how to read
the key and value. A 4-byte integer&amp;rsquo;s largest value is ~4
billion, causing a worst case memory allocation of 8GB (4GB for each of the key
and value). This can cause the process to go out of memory, resulting in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; refusing to start.&lt;/p&gt;

&lt;h4 id=&#34;solution&#34;&gt;Solution&lt;/h4&gt;

&lt;p&gt;Since we expect that keys will always be smaller than 1MB and values will
always be smaller than 1GB (these are generous bounds), we can simply cap the
allowable size of keys and values. If the header indicates that the key or
value is bigger than its bound, we know the entry is corrupt (and avoid a
memory allocation based on bad data). But what if the header is corrupt but
the key and value lengths are within their bounds? In that case, we can still
detect the corruption using the checksum.&lt;/p&gt;

&lt;p&gt;Once a corrupt entry is detected, we can truncate the value log at that point.&lt;/p&gt;

&lt;p&gt;The relevant pull request is
&lt;a href=&#34;https://github.com/dgraph-io/badger/pull/158&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;crash-vulnerability-2&#34;&gt;Crash Vulnerability #2&lt;/h2&gt;

&lt;p&gt;The value log is actually made up of many smaller &lt;em&gt;value log files&lt;/em&gt;.  When an
individual value log file gets too big, a new one is created. The value log
(conceptually the concatenation of all of the value log files) then continues
in the new value log file. Meanwhile,
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; maintains a head pointer,
corresponding to the offset in value log, uptil which everything has been
persisted to disk on the LSM tree.&lt;/p&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up, it picks the
latest value of head from the persisted portion of the LSM tree, and replays
the entries from value log from that offset onwards to bring them back into LSM
tree (for more details about how this works, see &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;the original
paper&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The ALICE output indicates that there is a problem around the transition from
one value log file (&lt;code&gt;*.vlog&lt;/code&gt;) to the next:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul2_trace.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul2_vulns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;vulnerability-1&#34;&gt;Vulnerability&lt;/h5&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up, all of the
&lt;code&gt;*vlog&lt;/code&gt; are first opened:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The latest &lt;code&gt;vlog&lt;/code&gt; file is opened in read/write mode. This is the &lt;code&gt;vlog&lt;/code&gt; file
that will be appended to when the key value store is mutated.&lt;/li&gt;
&lt;li&gt;All previous &lt;code&gt;vlog&lt;/code&gt; files are opened in read-only mode. They are only used
for value lookups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The value log is then replayed from the head persisted in the LSM tree.  When a
corrupt entry in a &lt;code&gt;vlog&lt;/code&gt; file is found during replay, that file is truncated
so that it contains only good entries. This is normally fine, because the
corrupt file is expected to be the latest one (since it would have been
appended to last before the crash).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This isn&amp;rsquo;t always the case though&amp;hellip;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The problem occurs when the content of &lt;code&gt;000001.vlog&lt;/code&gt; is persisted to disk
before the content of &lt;code&gt;000000.vlog&lt;/code&gt;. &lt;code&gt;000001.vlog&lt;/code&gt; will be the latest value log
file (opened as read/write), but &lt;code&gt;000000.vlog&lt;/code&gt; (opened as read-only) may have
corrupt entries. The result is that we try to truncate a file that is opened in
read-only mode.&lt;/p&gt;

&lt;p&gt;This vulnerability only occurs when
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is configured with
&lt;code&gt;SyncWrites=false&lt;/code&gt;. This is a mode that trades off increased write performance
for the chance that if &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; crashes,
some small amount of recently written data may be lost. However, the
vulnerability &lt;em&gt;does&lt;/em&gt; leave &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; unable
to restart which is unacceptable.&lt;/p&gt;

&lt;h5 id=&#34;solution-1&#34;&gt;Solution&lt;/h5&gt;

&lt;p&gt;There are a few different possible fixes here. We went for a simple fix: always
&lt;a href=&#34;https://github.com/dgraph-io/badger/pull/157&#34;&gt;sync the current &lt;code&gt;vlog&lt;/code&gt; file before starting a new
one&lt;/a&gt;. That way, the nth value log
file is always persisted completely before the n+1th is written.&lt;/p&gt;

&lt;h2 id=&#34;concluding-thoughts&#34;&gt;Concluding thoughts&lt;/h2&gt;

&lt;p&gt;After we fixed the problems that ALICE reported, running ALICE again shows no
crash vulnerabilities for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. Awesome!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering value log garbage collection:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_after_badger.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering LSM tree compaction:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_lsm_compaction_after.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Here at Dgraph Labs, we really care about making our products as robust as
possible,&lt;/strong&gt; even under unlikely and rare scenarios such as system crashes.
We want to stay ahead of the curve when it comes to rock solid
stability. Proactively finding and fixing bugs before they are reported in
production is a major part of that.&lt;/p&gt;

&lt;p&gt;If you own and maintain software that interacts directly with files, we
recommend that you give ALICE a try. Also, if you need a rock solid and
performant key-value store, you know &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;where to
look&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/jumping_badger.jpg&#34; alt=&#34;Happy Badger&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://fineartamerica.com/featured/galileo-spacecraft-burning-up-in-jupiter-christian-darkin.html&#34;&gt;Galileo Spacecraft Burning Up In
Jupiter&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scale the shit out of this!</title>
      <link>https://blog.dgraph.io/post/scaling-dgraph/</link>
      <pubDate>Tue, 08 Aug 2017 17:23:51 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/scaling-dgraph/</guid>
      <description>

&lt;p&gt;Starting v0.8, we have aimed to focus purely on the stability and performance of &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;. Our feature set is at this point good enough for most users &amp;ndash; so we&amp;rsquo;ve decided to freeze it until we reach v1.0.&lt;/p&gt;

&lt;p&gt;Part of ensuring stability and performance led us to try and load the entire Stack Overflow on &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;; around 2 billion edges. With full-text search, reverses and other indices, this jumps between &lt;strong&gt;6-8 billion edges&lt;/strong&gt;; which poses unique challenges.&lt;/p&gt;

&lt;p&gt;Trying to load up this data has been an interesting journey in problem-solving.  Every step of the way we made our best judgment to come up with a good solution &amp;ndash; sometimes they stuck, other times they didn&amp;rsquo;t, only to be replaced by another solution.&lt;/p&gt;

&lt;p&gt;To give you an idea of how we store data, we convert all outgoing edges from a node, sharing the same predicate into a single key-value pair. The value is typically a sorted list of integers, what we refer to as posting list. Computer Science graduates familiar with Information Retrieval problem would instantly recognize this as &lt;a href=&#34;https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html&#34;&gt;an inverted index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/posting list.png&#34; alt=&#34;Inverted Index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;While typical search engines have the luxury to create these posting lists once using a map-reduce; in &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;, we need to update these in real time as mutations flow.  But for every new mutation to this posting list, we don&amp;rsquo;t rewrite this posting list. That&amp;rsquo;d be computationally expensive. Instead, we store these mutations in a layer above the list; and on some trigger, we merge this layer and regenerate the sorted integer list.&lt;/p&gt;

&lt;p&gt;If a posting list has a mutation, we consider it &lt;em&gt;dirty&lt;/em&gt;. We have a dirty channel, which we push the corresponding key to, after every successful mutation. A few goroutines would pick keys from this channel and &lt;em&gt;sync them to disk&lt;/em&gt;. This sync step includes regenerating the posting list, followed by a write to the underlying key-value store.&lt;/p&gt;

&lt;h2 id=&#34;stuck-write-throughput&#34;&gt;Stuck write throughput&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/houston-we-have-a-problem.jpg&#34; alt=&#34;Houston, we have a problem&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The problem we hit&lt;/strong&gt; was during loading. When we started loading the data, we saw our write throughput was getting stuck on around 50-60K updates per second. The system was definitely capable of doing more than that.&lt;/p&gt;

&lt;p&gt;After debugging, we realized that we were waiting too long for posting lists.&lt;/p&gt;

&lt;p&gt;See, when you do a sync to disk, you need to block access to this posting list: you regenerate the value (which could be expensive), then write it to disk, and then delete the value from memory. Then, when someone accesses this PL again, they fetch the value from the key-value store.&lt;/p&gt;

&lt;p&gt;The pre-mature optimization behind delete was to save memory, but clearly, it could be avoided. We still wrote to disk, but stopped deleting the value from memory; so the next guy has it ready for more operations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Things got better.&lt;/strong&gt; But, we were still waiting too long on popular posting lists. After some head scratching, the culprit turned out to be the dirty channel.  For every mutation, we were pushing this key to the dirty channel. And then these goroutines would trigger a sync to disk. For popular lists, we were doing this too frequently. Every mutation would in effect trigger a sync to disk, via the dirty channel. This was not good.&lt;/p&gt;

&lt;p&gt;We needed a way to delay the push to dirty channel. So, we introduced a goroutine and a local channel. This goroutine would listen on this channel, and we&amp;rsquo;ll push to this channel on every successful mutation. When the goroutine receives something on the channel, it will sleep for five seconds. On awake, it would check if there was something new on the channel. If so, it would repeat the loop of sleeping. If not, it would push to the global dirty channel.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This was a nifty idea but crumbled as soon as we ran it.&lt;/strong&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/mars-explosion.jpg&#34; alt=&#34;The Martian Movie - Explosion - Twentieth Century Fox/YouTube&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The memory usage spiked, and &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; quickly went OOM. For a while, we couldn&amp;rsquo;t figure out why.  The heap seemed normal. We debugged the cache; it seemed to be of normal size.  The mutations weren&amp;rsquo;t consuming too much either. Nothing in the system looked like it was out of place.&lt;/p&gt;

&lt;h2 id=&#34;the-stack&#34;&gt;The Stack&lt;/h2&gt;

&lt;p&gt;Then almost accidentally, we saw the stack size. We always tracked Go heap size but had never tracked the stack.  We just happened to print the entire Go memory stack and noticed that the stack size was totally out of whack.&lt;/p&gt;

&lt;p&gt;We quickly noticed the number of goroutines. We had millions of them running, one per key. Each goroutine consumes at least 4KB in the stack (in practice, more). &lt;strong&gt;10 million of them would consume at least 40GB!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Learning a new lesson about the cost of cheap goroutines, we changed our solution.  Note that when we pick something from the dirty channel, we don&amp;rsquo;t immediately work on it. We store it in a local dirty map. We then pick &lt;code&gt;X%&lt;/code&gt; of total entries in the dirty map and trigger sync to disk on them.&lt;/p&gt;

&lt;p&gt;Previously, we were just storing &lt;code&gt;struct{}&lt;/code&gt; in the map value. We changed that to store a timestamp. We removed the local goroutines per posting list and switched back to pushing to dirty chan on every mutation. But, when it reached the local dirty map, we&amp;rsquo;d just update the timestamp.&lt;/p&gt;

&lt;p&gt;When picking the &lt;code&gt;X%&lt;/code&gt; entries from the dirty map, we&amp;rsquo;d check if the timestamp was within five seconds. If not, we&amp;rsquo;ll just skip that list. &lt;strong&gt;This gave us the delay factor.&lt;/strong&gt; We just had to add a small break condition to avoid looping over the entire dirty map.&lt;/p&gt;

&lt;p&gt;Now, this worked. We saw a jump in our mutations per second, from 50-60K to close to 100K. At least initially.&lt;/p&gt;

&lt;h2 id=&#34;range-anxiety&#34;&gt;Range Anxiety&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/range anxiety.jpg&#34; alt=&#34;The Martian Movie - Range Anxiety&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The write throughput would start above 100K, but after a few minutes of running, the throughput would drop down to 70K, then 50K, then lower. We tried to figure out what was causing this drop. Turns out, some of our frequently written posting lists were taking longer and longer to add mutations.&lt;/p&gt;

&lt;p&gt;Remember, how we have a mutable layer above the immutable layer. For a small number of frequently updated posting lists, the time delay would almost never trigger. Within the 5 second period, at least some mutation would touch it, which caused its mutable layer to grow unbounded. And this layer is slower to access compared to the immutable layer. So, new additions were being slow.&lt;/p&gt;

&lt;p&gt;Along with the time delay, we added a heuristic that for every 1000 writes; these layers would be merged. This let the loading run for longer at higher throughputs. Another day, another fix!&lt;/p&gt;

&lt;p&gt;Now that write throughput was OK, &lt;strong&gt;we had a new problem.&lt;/strong&gt; After an hour or so of running, &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; would be killed by OOM.&lt;/p&gt;

&lt;p&gt;We tried various things, over many days. We enabled swap space. We used all the &lt;code&gt;sync.Pools&lt;/code&gt; in every critical path. We evicted things more aggressively. But, all we were able to do was to push it from one hour to three hours, before it would OOM.&lt;/p&gt;

&lt;p&gt;See, every time we read a posting list, we would store it in memory in case something else needed it. &lt;em&gt;That’s our version of cache.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We used a sharded map to store these posting lists in memory. We’d have 64 shards, to allow fast concurrent access by multi core machines. The thing is, this cache would grow as you access more and more lists.&lt;/p&gt;

&lt;p&gt;We had a mechanism in place to manage memory. We have a goroutine which periodically checks memory usage by our program. If that memory exceeds a certain specified value by the user, we will evict one shard. That is, we’d go over all the keys in one shard and just delete them. During our various attempts, we also added some heuristic to increase that number to 3 shards, if memory usage grew beyond some higher limit.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In theory, this works OK.&lt;/strong&gt; You go over memory, you discard a chunk of items, and let Go and hence the OS reclaim the memory. Now, Go is slow in releasing memory to the OS, so we’d trigger &lt;code&gt;debug.FreeOSMemory()&lt;/code&gt; method, to avoid the OS killing the process with an OOM.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In practice, it sunk fast!&lt;/strong&gt; First, Go might still not release memory despite calls to &lt;code&gt;debug.FreeOSMemory()&lt;/code&gt;. &lt;em&gt;It’s suggestion, not a command.&lt;/em&gt; It might hold tens of GBs of memory, while the OS is close to killing the process.  Second, we didn’t account for an interesting behavior.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/out-of-memory.jpg&#34; alt=&#34;Out of memory&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Every time the goroutine would check our memory usage is greater than the threshold, it would trigger an &lt;code&gt;EvictShard()&lt;/code&gt;. What happened was, memory usage would sort of stay above the limit for a while, causing many evict shards.  Eventually, almost the entire cache would be evicted; and the memory usage would go below the threshold (but not too much, because Go holds memory).&lt;/p&gt;

&lt;p&gt;A memory having gone to normal state, the system would accept requests again and start loading the data. But the requests have been retrying for a while, so they’d reload too many posting lists all at once (plus, almost zero caches). The memory usage would suddenly spike, and before the goroutine could trigger another evict shard, the program would OOM.&lt;/p&gt;

&lt;p&gt;The lesson learned here was not only to avoid the program from going above the normal limit (which is what we were doing) but to &lt;strong&gt;avoid evicting big chunks of cache all at once.&lt;/strong&gt; Because when it comes back, it comes back with a &lt;em&gt;vengeance&lt;/em&gt;!&lt;/p&gt;

&lt;p&gt;So, we switched to a single shard LRU cache, which would release memory consistently over time (&lt;em&gt;well, we should have had that in the first place, but it was slower compared to sharded map; so it was a pending investigative TODO item for over a year&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Also, we couldn’t rely upon the goroutine doing Go memory monitoring to tell us how much to release — because of its unreliability. So, we just set the size of the LRU cache upfront, and then maintain that over time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;That fixed our OOM issue. Almost surprisingly!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;getting-back-to-your-perf-review&#34;&gt;Getting back to your perf review&lt;/h1&gt;

&lt;p&gt;Now that memory issue was solved, it was time to load the entire 2B edges and play with it. &lt;em&gt;Almost!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;After some hours of loading data, we realized we had some huge posting lists, containing millions of integers. These were the frequently updating ones, which have a very &lt;strong&gt;high fan-out.&lt;/strong&gt; That is, one node has millions of edges going outwards.&lt;/p&gt;

&lt;p&gt;This particularly troubled us in indices. For, e.g., &lt;code&gt;Type&lt;/code&gt; index, which points from a certain type to all the instances of that type. If you have 100s of millions of comments, all these comments would be referenced in one posting list. Another good example is full-text search, where certain common terms can cause high fan-out nodes.&lt;/p&gt;

&lt;p&gt;As the list size grows, re-encoding the list after every 1000 mutations was getting slower and slower. This would cause all writes waiting on this list to slow down considerably; which in turn slows down the data loading.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is where we are right now! And we have ideas to solve this problem.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;One is to split the posting list into smaller and smaller shards, to create essentially &lt;em&gt;sharded posting lists&lt;/em&gt;.  Each shard holding a contiguous portion of the sorted list. This way, the mutations could be applied to these lists concurrently, and each of these could be re-encoded easily.&lt;/p&gt;

&lt;p&gt;The problem with this approach is that when iterating or intersecting these posting lists, all the shards of the posting list would have to be brought into memory. &lt;strong&gt;This is bad for two reasons.&lt;/strong&gt; One, bringing the whole thing into memory is still a problem. And two, more disk reads are now required to read the posting list.&lt;/p&gt;

&lt;p&gt;Without going into details, the other option is based on research, which is to encode the posting list smartly.&lt;/p&gt;

&lt;p&gt;We initially worked on the first approach, but after writing it quickly rejected it in favor of the second approach.&lt;/p&gt;

&lt;p&gt;Posting list encoding change is currently being implemented and tested. We’ll know soon how effective this is, and what new issues we encounter along the path to scaling &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; to billions of edges. Stay tuned!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. To see the commits corresponding to this blog post, &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commits/master?author=janardhan1993&#34;&gt;see recent activity here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; We&amp;rsquo;ve gone on to produce a new tool for offline bulk loading, with
&lt;a href=&#34;https://blog.dgraph.io/post/bulkloader/&#34;&gt;significantly improved loading speed&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Images: Stills from &lt;a href=&#34;http://www.foxmovies.com/movies/the-martian&#34;&gt;The Martian&lt;/a&gt;
and &lt;a href=&#34;https://www.uphe.com/movies/apollo-13&#34;&gt;Apollo 13&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Stack Overflow Clone with Dgraph, and React</title>
      <link>https://blog.dgraph.io/post/building-graphoverflow/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/building-graphoverflow/</guid>
      <description>&lt;p&gt;I have recently built a Stack Overflow clone with Dgraph and React. I was delightfully surprised by the pleasant developer experience and the performance of my application. In this post, I would like to tell the story of how I built &lt;em&gt;Graphoverflow&lt;/em&gt; and share the best practices I learned for using Dgraph to build a modern web application.
&lt;/p&gt;

&lt;p&gt;As you can see in the &lt;a href=&#34;https://graphoverflow.dgraph.io&#34;&gt;live demo&lt;/a&gt;, &lt;em&gt;Graphoverflow&lt;/em&gt; implements all core functionalities of Stack Overflow. Through the web interface, you can create, read, update, and delete questions, answers, comments. You can also cast upvotes and downvotes. In addition, it is smart enough to recommend you questions to read based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Collaborative_filtering&#34;&gt;collaborative filtering&lt;/a&gt;. In many ways, &lt;em&gt;Graphoverflow&lt;/em&gt; successfully embodies many important features that most modern web applications depend on: CRUD operations, and user authentication and authorization. As &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;the source code&lt;/a&gt; shows, all this is achieved by using Dgraph as the primary and only data storage.&lt;/p&gt;

&lt;p&gt;Looking back the past three weeks of building &lt;em&gt;Graphoverflow&lt;/em&gt;, I feel that the journey was unexpectedly simple and straightforward. I have never built anything using a graph database in my entire life. Therefore when I started building this application I knew I was set out for a bumpy ride. However, the intuitive query language of Dgraph did the heavy lifting out of the box, and I did not have to struggle too much. &lt;em&gt;Graphoverflow&lt;/em&gt; is not a simple application by any means, as it needs to retrieve and render a large amount of data with complex relationships, and has a built-in recommendation system. However, a quick analysis of the code base reveals that I only had to write 700 LOC (18%) on the server side, and 3300 LOC (82%) on the client side to ship it, excluding&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Server side
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
JavaScript                       7             94             21            654
JSON                             1              0              0             39
-------------------------------------------------------------------------------
SUM:                             8             94             21            693
-------------------------------------------------------------------------------


# Client side
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
JavaScript                      62            391             74           2880
Sass                            17             91              1            461
-------------------------------------------------------------------------------
SUM:                            79            482             75           3341
-------------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The simplicity of the code base clearly demonstrates that, with Dgraph, you can end up with a lot less complex application code for your non-trivial requirements.&lt;/p&gt;

&lt;h2 id=&#34;the-query-language-was-the-key&#34;&gt;The Query Language Was The Key&lt;/h2&gt;

&lt;p&gt;I believe that &lt;em&gt;Graphoverflow&lt;/em&gt; owes its simple code base and the fast iteration cycle to Dgraph&amp;rsquo;s homebred query language, &lt;a href=&#34;https://docs.dgraph.io/query-language/&#34;&gt;&lt;em&gt;Graphql+-&lt;/em&gt;&lt;/a&gt;. To me, the biggest benefit of the query language was that I was able to retrieve complex data by writing a single, and intuitive tree-like structure. I could spend less time worrying about what tables to create or join together to store and fetch the data that the frontend required. Instead, I could simply focus on polishing my front-end components, while relying on Dgraph&amp;rsquo;s flexible schema system and its powerful query language.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/graphoverflow-question.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The inner workings of the question page shown above can shed lights on Dgraph&amp;rsquo;s ability to retrieve complex data in a straightforward way. In order to render this page on the front-end, I needed to fetch &lt;code&gt;question&lt;/code&gt;, and all of its &lt;code&gt;answers&lt;/code&gt;. For all of them, I needed to fetch the total number of &lt;code&gt;upvotes&lt;/code&gt; and &lt;code&gt;downvotes&lt;/code&gt;, &lt;code&gt;viewCounts&lt;/code&gt;, its &lt;code&gt;history&lt;/code&gt;, &lt;code&gt;comments&lt;/code&gt;, and those comments&amp;rsquo; respective &lt;code&gt;scores&lt;/code&gt;. Not only that but also I needed to fetch 30 &lt;code&gt;related questions&lt;/code&gt; based on the tags attached to the displayed question. These data have complex schemas and interdependent relationships with one another. The queries I wrote, on the other hand, felt very straightforward to me.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    Title {
      Text
    }
    Body {
      Text
    }
    ViewCount
    UpvoteCount: count(Upvote)
    DownvoteCount: count(Downvote)

    Comment {
      ...
    }

    Has.Answer {
      Comment {
        ...
      }
      ...
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above is the query responsible for fetching the &lt;code&gt;question&lt;/code&gt;, its &lt;code&gt;answers&lt;/code&gt;, and their relevant properties and children such as &lt;code&gt;comments&lt;/code&gt;. GraphQL+- is comprised of the root node and its nested blocks, and when executed it returns a result in a subgraph format. A query can have multiple root nodes, and you can see the whole query &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow/blob/master/app/client/src/queries/Question.js#L131&#34;&gt;here on GitHub&lt;/a&gt;. In short, the above query returns a result shaped like the following code block. We can see that starting from the root node, &lt;code&gt;question&lt;/code&gt;, Dgraph finds and returns all the children nodes represented by nested blocks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;{
  &amp;quot;question&amp;quot;: [
    {
      &amp;quot;Timestamp&amp;quot;: &amp;quot;2015-10-06T15:34:33.75Z&amp;quot;,
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I keep my cat off my keyboard?&amp;quot;
        }
      ]
      &amp;quot;Body&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;...&amp;quot;
        }
      ],
      &amp;quot;ViewCount&amp;quot;: 21767,
      &amp;quot;UpvoteCount&amp;quot;: 169,
      &amp;quot;DownvoteCount&amp;quot;: 2,
      &amp;quot;Comment&amp;quot;: [ { ... }, ... ],
      &amp;quot;Has.Answer&amp;quot;: [
        {
          &amp;quot;Comment&amp;quot;: [ { ... }, ... ],
          ...
        },
        ...
      ],
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-in-react&#34;&gt;Using in React&lt;/h2&gt;

&lt;p&gt;To query Dgraph and use the result in a React application, we can use the component lifecycle method provided by React. When a component responsible for displaying the question mounts to the DOM, &lt;em&gt;Graphoverflow&lt;/em&gt; sends a query to Dgraph and displays a loading screen for a short while until the result arrives. Therefore, it handles the data fetching in the &lt;a href=&#34;https://facebook.github.io/react/docs/react-component.html#componentdidmount&#34;&gt;&lt;code&gt;compnentDidMount&lt;/code&gt;&lt;/a&gt; lifecycle method which is invoked immediately after a component mounts. The simplified code looks like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import React from &#39;react&#39;;
import { runQuery } from &amp;quot;../lib/helpers&amp;quot;;
import { getQuestionQuery } from &amp;quot;../queries/Question&amp;quot;;

class Question extends React.Component {
  constructor(props) {
    super(props);

    this.state = {
      questionLoaded: false,
      question: {}
    };
  }

  componentDidMount() {
    const questionUID = this.props.match.params.uid;
    const query = getQuestionQuery(questionUID);

    runQuery(query).then(res =&amp;gt; {
      const question = res.question[0];
      this.setState({ question, questionsLoaded: true });
    })
  }

  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three things need to happen in &lt;code&gt;componentDidMount&lt;/code&gt;: constructing a query for the question, sending the query to the server, storing the result so that it can be rendered. Let us look at this simple process step-by-step.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Since we need to fetch a question with a specific &lt;code&gt;_uid_&lt;/code&gt;, we need to dynamically make a query string by interpolating string. &lt;code&gt;getQuestionQuery&lt;/code&gt; is a factory that takes a &lt;code&gt;questionUID&lt;/code&gt; and returns a string representing the query.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;  function getQuestionQuery(questionUID) {
    return `
      question(func: uid(${questionUID})) {
        ...
      }
    `;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Once we have the query, simply make an HTTP &lt;code&gt;POST&lt;/code&gt; request to Dgraph server. &lt;code&gt;runQuery&lt;/code&gt; is a helper method that returns a promise that resolves with the JSON response from Dgraph server. It uses &lt;a href=&#34;https://github.com/visionmedia/superagent&#34;&gt;superagent&lt;/a&gt;, but you can surely use other solutions such as &lt;a href=&#34;https://github.com/github/fetch&#34;&gt;fetch&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import request from &amp;quot;superagent&amp;quot;;

function runQuery(queryText) {
  const endpointBaseURL = &#39;http://localhost:3030&#39;;

  return request.post(`${endpointBaseURL}/query`).send(queryText).then(res =&amp;gt; {
    return JSON.parse(res.text);
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;When we get the response, we store it in an application state so that the data can be rendered in the browser. &lt;em&gt;Graphoverflow&lt;/em&gt; persists the data in component&amp;rsquo;s state to keep the demonstration simple. However, you can easily integrate state management libraries such as &lt;a href=&#34;https://github.com/reactjs/redux&#34;&gt;Redux&lt;/a&gt; or &lt;a href=&#34;https://github.com/mobxjs/mobx&#34;&gt;MobX&lt;/a&gt; to this step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Having completed the above process in &lt;code&gt;componentDidMount&lt;/code&gt;, now we can render the question page. Here is what &lt;code&gt;render&lt;/code&gt; method of &lt;code&gt;Question&lt;/code&gt; component looks like in a simplified way.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;render() {
  const {
    question,
    questionLoaded,
  } = this.state;

  if (!questionLoaded) {
    return &amp;lt;Loading /&amp;gt;;
  }

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;QuestionLayout question={question} /&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once I got the hang of the query language, it felt very natural using Dgraph with React simply because there was nothing new or paradigm-shifting. The process described above is exactly how I would use PostgreSQL or MongoDB in a purely client-side rendered Single Page Application.&lt;/p&gt;

&lt;p&gt;The mechanism described here can be adapted to support more advanced use cases such as server-side rendering; we can move the whole process into a static method of the component that returns a promise, and call it on the server side and delay the render until a response is fetched and promise resolved. We can even integrate Redux with ease so that the app state can be rehydrated on the client side.&lt;/p&gt;

&lt;h2 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h2&gt;

&lt;p&gt;Through building &lt;em&gt;Graphoverflow&lt;/em&gt;, I have come up with some practices that I believe will help keep your code base maintainable and save time. Those are based on my collective lessons from numerous trial, errors, and redesign attempts. Often a lack of documented practices is the biggest barrier hindering us from dipping our unfamiliar technologies and cultivating their benefits. The following practices will help you instantly get started with building fast modern web applications with Dgraph and React.&lt;/p&gt;

&lt;h3 id=&#34;organize-your-queries-along-with-your-components&#34;&gt;Organize Your Queries Along With Your Components&lt;/h3&gt;

&lt;p&gt;It is a good idea to couple together a component and all queries that component relies on for data. The reason is that you need to know the shape of JSON response from Dgraph server in order to render your components. And the shape of the response can vary for mainly two reasons. Names of predicates can change because a query can use an &lt;a href=&#34;https://docs.dgraph.io/query-language/#alias&#34;&gt;alias&lt;/a&gt;. Alternatively, a nested block in a query might be omitted either by need or an error. Those situations can suddenly take away fields that your React component assumes are present. If you have a chain of attribute getters and one of those attributes is missing, you will end up chaining a getter on an &lt;code&gt;undefined&lt;/code&gt;. Prior to React 16, such scenario can &lt;a href=&#34;https://facebook.github.io/react/blog/2017/07/26/error-handling-in-react-16.html#behavior-in-react-15-and-earlier&#34;&gt;lead to cryptic error messages&lt;/a&gt; that are hard to debug.&lt;/p&gt;

&lt;p&gt;Here is an example of how a change in Dgraph response can cause an error in your React application. The query for the question page includes the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    Title {
      Text
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the &lt;code&gt;Question&lt;/code&gt; component, &lt;em&gt;Graphoverflow&lt;/em&gt; renders the title while assuming the result has the shape of &lt;code&gt;{ question: { title: [ { text } ], ... } }&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Question extends React.Component {
  ...
  render() {
    ...

    return (
      ...
      &amp;lt;h1 className=&amp;quot;post-title&amp;quot;&amp;gt;{post.Title[0].Text}&amp;lt;/h1&amp;gt;
      ...
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we change the query to the following, the component will not work anymore because &lt;code&gt;post.Title&lt;/code&gt; will be &lt;code&gt;undefined&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    question_title as Title {
      Text
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your queries will evolve as your requirements change. Iterating on your query can be error-prone if the queries are scattered in a random manner without a formal structure. Therefore I recommend the following directory structure in your project to mitigate such issue and keep your code base maintainable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;your_project
├── components
│   ├── EditPost.js
│   ├── Home.js
│   └── Question.js
├── queries
│   ├── EditPost.js
│   ├── Home.js
│   └── Question.js
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Within your component, import needed queries from the corresponding query file. This way, we can easily iterate on queries for your components in a reliable manner. It is clean and reassuring to have a separate, go-to file to see all the queries that your component is relying on. It keeps possible errors in check and makes debugging feasible in case of an error.&lt;/p&gt;

&lt;h3 id=&#34;use-functions-to-dynamically-construct-queries&#34;&gt;Use Functions to Dynamically Construct Queries&lt;/h3&gt;

&lt;p&gt;When your query needs to be built dynamically, write a function that takes values and returns a query string using those values. In other words, make a factory to dynamically generate queries rather than doing string interpolation directly in your component. Previously we have seen an example of such function that generates a query for a specific question:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;function getQuestionQuery(questionUID) {
  return `
    question(func: uid(${questionUID})) {
      ...
    }
  `;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Many occasions will arise in which you need to generate a query dynamically. Most common cases are fetching a single resource by its unique identifier, or posting information while performing &lt;a href=&#34;https://docs.dgraph.io/query-language/#mutations&#34;&gt;mutations&lt;/a&gt;. In such occasions, simply export functions like the example above from the appropriate query file that you have established following the previous best practice. Doing so allows you to keep all the queries in a single file in a clean way.&lt;/p&gt;

&lt;h3 id=&#34;use-fragments-for-repeated-structures&#34;&gt;Use Fragments for Repeated Structures&lt;/h3&gt;

&lt;p&gt;If queries for one of your components exhibits repeated structures, consider extracting them as fragments that can be reused. Doing so will allow us to avoid the mismatch between the shape of Dgraph response and your React component&amp;rsquo;s expectation of it, a common pitfall that we already identified above.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/graphoverflow-node-cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see from the picture, the &lt;code&gt;Home&lt;/code&gt; component of &lt;em&gt;Graphoverflow&lt;/em&gt; can fetch questions according to three different criteria: &amp;lsquo;Recommended&amp;rsquo;, &amp;lsquo;Most Recent&amp;rsquo;, and &amp;lsquo;Hot&amp;rsquo;. While these criteria fetch questions of different ilks, the returned fields for the questions must be consistent because a single React component is responsible for rendering a question item, no matter what criteria is used to fetch them.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import React from &amp;quot;react&amp;quot;;

const QuestionItem = ({ question, history }) =&amp;gt; {
  return (
    &amp;lt;li&amp;gt;
      ...
      {question.AnswerCount}
      ...
      {question.ViewCount}
      ...
      &amp;lt;Link to={questionLink} className=&amp;quot;question-title&amp;quot;&amp;gt;
        {JSON.stringify(question.Title[0].Text)}
      &amp;lt;/Link&amp;gt;
    &amp;lt;/li&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are three different queries in &lt;code&gt;queries/Home.js&lt;/code&gt;, all fetching data required for rendering &lt;code&gt;QuestionItem&lt;/code&gt; while following different criteria.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const recommendedQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
export const hotQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
export const recentQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we happen to under-fetch a field for &lt;code&gt;questions&lt;/code&gt; in one of these queries, the data for our React component will be incomplete, causing run-time errors. Therefore, it is much more sensible to abstract out the common parts as a &amp;lsquo;fragment.&amp;rsquo; Doing so can eliminate the chance of errors in the future iterations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const questionFragment = `
_uid_
Title {
  Text
}
...
`;
export const recommendedQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
export const hotQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
export const recentQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Building an application with Dgraph left me with a strange aftertaste. Usually, a new technology inevitably leaves a feeling of ennui, after the excitement of trying out something new eventually subsides. Yet this time, I felt something quite different. Perhaps it was a taste of delight, a hint at something exciting in the making.&lt;/p&gt;

&lt;p&gt;As a young developer, I often find myself in a vain pursuit of the newest and the shiniest piece of technology. In that hedonistic treadmill, I time and again stumbled upon many burgeoning technologies proclaiming to be the fastest, the newest, the most game-changing. Perhaps all those claims are justified in their own unique ways, but for the most part, it feels that they are merely clamoring for attention. In contrast, Dgraph seems to make a persuasive case with its well-designed query language alone.&lt;/p&gt;

&lt;p&gt;Dgraph has proven to work seamlessly with React, and its rich and intuitive query language allowed me to make and ship a Stack Overflow clone in a matter of weeks without a previous experience. The ease of iteration, coupled with the performance, indicates that Dgraph is a valuable addition to our tool belts for building modern web applications.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;You can try Graphoverflow on &lt;a href=&#34;https://graphoverflow.dgraph.io&#34;&gt;https://graphoverflow.dgraph.io&lt;/a&gt; and view its source code on &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;https://github.com/dgraph-io/graphoverflow&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://images.nasa.gov/#/details-iss042e021664.html&#34;&gt;International Space Station Night Europe&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Orchestrating signal and wait in Go</title>
      <link>https://blog.dgraph.io/post/signal-and-wait/</link>
      <pubDate>Wed, 19 Jul 2017 15:24:00 -0700</pubDate>
      
      <guid>https://blog.dgraph.io/post/signal-and-wait/</guid>
      <description>&lt;p&gt;One of the common use case in Go is to start a few goroutines to do some
work. These goroutines block listening in on a channel, waiting for more work to
arrive. At some point, you want to signal these goroutines to stop accepting
more work and exit, so you can cleanly shut down the program.
&lt;/p&gt;

&lt;p&gt;This is how the code might look:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWork(chanWork chan *work) {
  for w := range chanWork {
    do(w)
  }
}

func main() {
  chanWork := make(chan *work, 100)
  for i := 0; i &amp;lt; N; i++ {
    go doWork(chanWork)
  }

  // Push work to chanWork.
  chanWork &amp;lt;- w

  // All work is done, now stop.
  close(chanWork)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code looks reasonable, &lt;strong&gt;with one caveat.&lt;/strong&gt; Once you close the chanWork
channel, the main exits immediately. Closing the channel only acts as a
signal. You want the program to wait as well.&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;sync.WaitGroup&lt;/code&gt; allows the goroutines to cleanly exit before exiting the main
program, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWork(chanWork chan *work, wg *sync.WaitGroup) {
  defer wg.Done()
  ...
}

func main() {
  var wg sync.WaitGroup
  chanWork := make(chan *work, 100)
  for i := 0; i &amp;lt; N; i++ {
    wg.Add(1)
    go doWork(chanWork, &amp;amp;wg)
  }

  // Push work to chanWork.
  chanWork &amp;lt;- w

  // All work is done, now stop.
  close(chanWork)

  // Now wait.
  wg.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a Go programmer, this is pretty basic so far. And that&amp;rsquo;s because we had
access to the channel, which controls when the goroutine should exit.&lt;/p&gt;

&lt;p&gt;What happens in case we don&amp;rsquo;t have access to this channel? For, e.g., if we want to run
some execution periodically, we&amp;rsquo;ll have this situation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(wg *sync.WaitGroup) {
  defer wg.Done()
  timeChan := time.Tick(time.Second)

  for _ := range timeChan {
    do()  // some work
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case, we need a way to signal the goroutine to stop doing the work.
Say we use a signal channel like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(wg *sync.WaitGroup, signal chan struct{}) {
  defer wg.Done()
  timeChan := time.Tick(time.Second)

  for {
    select {
      case &amp;lt;- timeChan:
        do() // some work
      case &amp;lt;- signal:
        return
    }
  }
}

func main() {
  signal := make(chan struct{}, 1)

  ...

  signal &amp;lt;- struct{}{}  // To signal the goroutine to stop.
  wg.Wait() // Wait for goroutine to exit.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code above would indicate to the goroutine to stop doing the work. And also
wait for it so &lt;code&gt;main&lt;/code&gt; can exit cleanly.&lt;/p&gt;

&lt;p&gt;All nice and good so far. Now, &lt;strong&gt;what if we have multiple different such goroutines, and
we need to signal and wait on them in some order.&lt;/strong&gt; For, e.g., we might have a
pipeline of sorts, with multiple stages, each dependent on the previous &lt;code&gt;A -&amp;gt; B
-&amp;gt; C&lt;/code&gt;. In this case, we need to signal and wait on &lt;code&gt;A&lt;/code&gt;, before we do that for
&lt;code&gt;B&lt;/code&gt; and then &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;With the above code, this would be cumbersome. You&amp;rsquo;d need multiple signal
channels, one for each stage; and similarly, multiple waits, one for each stage.
Would be nice to encapsulate this in a class. That&amp;rsquo;s what we have done in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type LevelCloser struct {
    Name    string
    running int32
    nomore  int32
    closed  chan struct{}
    waiting sync.WaitGroup
}

func (lc *LevelCloser) Signal() {
    if !atomic.CompareAndSwapInt32(&amp;amp;lc.nomore, 0, 1) {
        // fmt.Printf(&amp;quot;Level %q already got signal\n&amp;quot;, lc.Name)
        return
    }
    running := int(atomic.LoadInt32(&amp;amp;lc.running))
    // fmt.Printf(&amp;quot;Sending signal to %d registered with name %q\n&amp;quot;,
                  running, lc.Name)
    for i := 0; i &amp;lt; running; i++ {
        lc.closed &amp;lt;- struct{}{}
    }
}

func (lc *LevelCloser) HasBeenClosed() &amp;lt;-chan struct{} {
	return lc.closed
}

func (lc *LevelCloser) Done() {
    if atomic.LoadInt32(&amp;amp;lc.running) &amp;lt;= 0 {
        return
    }

    running := atomic.AddInt32(&amp;amp;lc.running, -1)
    if running == 0 {
        lc.waiting.Done()
    }
}

func (lc *LevelCloser) Wait() {
    lc.waiting.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s a simple class with some basic APIs. The way you&amp;rsquo;d use it is like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(lc *LevelCloser) {
  defer lc.Done()
  timeChan := time.Tick(time.Second)

  for {
    select {
      case &amp;lt;- timeChan:
        do() // some work
      case &amp;lt;- lc.HasBeenClosed():
        return
    }
  }
}

func main() {
  lc := &amp;amp;LevelCloser{
    Name: name,
    closed: make(chan struct{}, 10),
    running: 1,
  }
  lc.waiting.Add(1)

  doWorkPeriodically(lc)

  lc.Signal()
  lc.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, to make it work for multiple stages, dependent or not, we wrap it up
into one &lt;code&gt;Closer&lt;/code&gt; class.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Closer struct {
    sync.RWMutex
    levels map[string]*LevelCloser
}

func NewCloser() *Closer {
    return &amp;amp;Closer{
        levels: make(map[string]*LevelCloser),
    }
}

func (c *Closer) Register(name string) *LevelCloser {
    c.Lock()
    defer c.Unlock()

    lc, has := c.levels[name]
    if !has {
        lc = &amp;amp;LevelCloser{Name: name, closed: make(chan struct{}, 10)}
        lc.waiting.Add(1)
        c.levels[name] = lc
    }

    AssertTruef(atomic.LoadInt32(&amp;amp;lc.nomore) == 0, &amp;quot;Can&#39;t register with closer after signal.&amp;quot;)
    atomic.AddInt32(&amp;amp;lc.running, 1)
    return lc
}

func (c *Closer) Get(name string) *LevelCloser {
    c.RLock()
    defer c.RUnlock()

    lc, has := c.levels[name]
    if !has {
        log.Fatalf(&amp;quot;%q not present in Closer&amp;quot;, name)
        return nil
    }
    return lc
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this wrapper class, you can just create one &lt;code&gt;Closer&lt;/code&gt; object, and use that
to create and maintain all &lt;code&gt;LevelCloser&lt;/code&gt;s. This way, you can retrieve, and signal all
the &lt;code&gt;LevelCloser&lt;/code&gt;s individually in order, or just have &lt;code&gt;Closer&lt;/code&gt; signal all of
them, and then wait for all of them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Closer) SignalAll() {
    c.RLock()
    defer c.RUnlock()

    for _, l := range c.levels {
        l.Signal()
    }
}

func (c *Closer) WaitForAll() {
    c.RLock()
    defer c.RUnlock()

    for _, l := range c.levels {
        l.Wait()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is how you&amp;rsquo;d use this class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func stageA(lc *LevelCloser) {
  defer lc.Done()
  for {
    select {
      case &amp;lt;- someChan:
      case &amp;lt;- lc.HasBeenClosed():
        return
    }
  }
}

func stageB(lc *LevelCloser) {
  ...
}

func main() {
  closer := NewCloser()
  lc := closer.Register(&amp;quot;stage-a&amp;quot;)
  go stageA(lc)

  lc := closer.Register(&amp;quot;stage-b&amp;quot;)
  go stageB(lc)

  ...

  lc = closer.Get(&amp;quot;stage-b&amp;quot;)
  lc.SignalAndWait()

  closer.SignalAll()
  closer.WaitAll()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This class is being used by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, and
it significantly simplifies the various asynchronous activities going on
internally. We can ensure that our writes are all committed before in-memory
tables are flushed, before we close value log, and so on.&lt;/p&gt;

&lt;p&gt;You can see the entire &lt;a href=&#34;https://github.com/dgraph-io/badger/blob/master/y/y.go#L67-L170&#34;&gt;code
here&lt;/a&gt;. The code
is under &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2.0&lt;/a&gt; license, so
feel free to copy the code and use it in your project. You can see the class in
&lt;a href=&#34;https://github.com/dgraph-io/badger/blob/master/kv.go#L253-L315&#34;&gt;action here&lt;/a&gt;. Look
for &lt;code&gt;closer.Register&lt;/code&gt; and &lt;code&gt;closer.Get&lt;/code&gt; to track how we create multiple such
&lt;code&gt;LevelCloser&lt;/code&gt;s and use them to maintain a strict opening and closing order
between the various stages.&lt;/p&gt;

&lt;p&gt;Hope you found this useful! Check out other posts to see how
&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; and
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can add value to your projects.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: Various stages of a &lt;a href=&#34;http://www.spacex.com/news/2015/06/24/why-and-how-landing-rockets&#34;&gt;SpaceX rocket launch&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running Stack Overflow on Dgraph</title>
      <link>https://blog.dgraph.io/post/sql-vs-dgraph/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/sql-vs-dgraph/</guid>
      <description>

&lt;p&gt;We have been taught, conditioned, trained to use SQL all our lives as engineers.
It was there in schools, there when we went to college. It was being used at the
company that we joined. It was such a common interview question that it no
longer is. We don&amp;rsquo;t have just one, but an array of SQL databases to choose from.
MySQL was released 22 years ago, in 1995 (youngest engineer at Dgraph was born the
same year). PostgreSQL was released one year later. In contrast, MariaDB was
released in 2009.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s amazing about SQL is its sheer simplicity. &lt;em&gt;Select something where
something, order by something, limit by some number.&lt;/em&gt; This query probably
represents most DB queries run on the planet. You can achieve the same thing
with a single bash command over CSV files. &lt;em&gt;I joke that SQL DBs are a sort of
glorified CSV file servers.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But, that&amp;rsquo;s also where lies its weakness. Its sheer simplicity. &lt;strong&gt;Because SQL
does fewer things, application developers need to write more logic.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-alternative&#34;&gt;The alternative&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Dgraph does joins.&lt;/strong&gt; Being a graph database, join is a &lt;em&gt;first-class&lt;/em&gt; citizen
in Dgraph. It&amp;rsquo;s optimized for expanding, intersecting and combining results from
multiple entity types &lt;em&gt;very fast&lt;/em&gt;. In fact, the internal mechanisms are exactly
how search engines work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph does recursions.&lt;/strong&gt; Recursion is essentially an edge traversal.
Traversing edges is very integral to Dgraph. Expanding out from a node is an
O(1) time complexity operation, a look up in hash map, or a single
read from disk.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph supports flexible schema.&lt;/strong&gt; Dgraph separates storage layer from schema
layer. A developer can choose how much schema enforcement they want. Modifying
data types do not require data rewrite; and because (the equivalent of)
&lt;em&gt;tables&lt;/em&gt; are sparse in a graph database, one does not need to fit everything
into predefined columns, or deal with &lt;code&gt;NULL&lt;/code&gt;s.&lt;/p&gt;

&lt;h3 id=&#34;stack-overflow&#34;&gt;Stack Overflow&lt;/h3&gt;

&lt;p&gt;To put something concrete up for discussion, we&amp;rsquo;ll see how data gets arranged in
SQL and compare that with how it would be arranged in Dgraph. Folks at Stack
Exchange generously provide &lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;dumps of their
data&lt;/a&gt;, and &lt;a href=&#34;https://ia800500.us.archive.org/22/items/stackexchange/readme.txt&#34;&gt;the
schema&lt;/a&gt; that
they use run the site over SQL.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll pick the schema that they use to store and
serve the data that millions of developers browse through every day, and compare
that against how it would be if Dgraph were the underlying database instead of
SQL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s start with the User schema,&lt;/strong&gt; and see how SQL would compare with Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;User&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Reputation&lt;/td&gt;
&lt;td&gt;Reputation&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DisplayName&lt;/td&gt;
&lt;td&gt;DisplayName&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastAccessDate&lt;/td&gt;
&lt;td&gt;LastAccessDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Location&lt;/td&gt;
&lt;td&gt;Location&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AboutMe&lt;/td&gt;
&lt;td&gt;AboutMe&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Views&lt;/td&gt;
&lt;td&gt;Views&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;UpVotes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DownVotes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here we have user&amp;rsquo;s reputation, creation date, display name, last access date,
location, about, age (&lt;em&gt;not date of birth?&lt;/em&gt;) and views (not tracking every single
page access, just a counter). All those are base data, i.e. new and unique data
that we must store.&lt;/p&gt;

&lt;p&gt;Then, the table has counts of upvotes and downvotes. But, those are being stored
elsewhere in &lt;code&gt;Vote&lt;/code&gt; table. These fields here are pre-computed counts to avoid
doing joins with &lt;code&gt;Vote&lt;/code&gt; table when querying for a user.&lt;/p&gt;

&lt;p&gt;Dgraph doesn&amp;rsquo;t need to store these. It can do counts and sorts on them via
queries efficiently.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s look at the Versioning and Post table,&lt;/strong&gt; where most of the action happens.
These tables store the questions, answers, tags, ownership, and authorship
information.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TypeId&lt;/td&gt;
&lt;td&gt;Type&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PostId&lt;/td&gt;
&lt;td&gt;Post (point to Post)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Post&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TypeId&lt;/td&gt;
&lt;td&gt;Type&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ParentId&lt;/td&gt;
&lt;td&gt;Has.Answer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AcceptedAnswerId&lt;/td&gt;
&lt;td&gt;Chosen.Answer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Title (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Title (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Body  (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Body  (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Tags  (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Tags  (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;OwnerUserId&lt;/td&gt;
&lt;td&gt;Owner (point to User)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Score&lt;/td&gt;
&lt;td&gt;Score&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastEditorUserId&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastEditDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastActivityDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CommentCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AnswerCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FavoriteCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Version table is pretty straightforward. It stores type, post id, creation date,
author, and text. Instead of storing ids, Dgraph creates a relationship
from Version to Post.&lt;/p&gt;

&lt;p&gt;Post table is the interesting one, and &lt;em&gt;shows how much data duplication needed
to happen to avoid joins.&lt;/em&gt; We have the text of title, body, and tags from the latest
version stored in this table. In fact, the latest version isn&amp;rsquo;t even written.
Version only gets created when a user modifies the title, body or tags. And
because of this requirement to proxy for Version table, Post table stores last
editor, last edit date, which would become the author and creation date
respectively when moved to Version table.&lt;/p&gt;

&lt;p&gt;All these fields are unnecessary in Dgraph. Dgraph can directly store an edge to
the Version node which contains the text of title and body. We chose to store
tags differently. For each tag, we create a node and create an edge between the
post and the tag. This allows us to run aggregations over tags, and find the
most popular and most related tags easily.&lt;/p&gt;

&lt;p&gt;Then, we have pre-computed counts of comments, answers, and favorites. Dgraph can
generate all this at query time efficiently; using them to do sorting as well.
So, they don&amp;rsquo;t need to be pre-computed in Dgraph.&lt;/p&gt;

&lt;p&gt;CreationDate and LastActivityDate are both redundant information, that can be
deduced by doing recursion. They form good candidates for optimization later on,
but are not needed and hence are not present in Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Comment, Vote&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PostId (Vote/Comment -&amp;gt; Post)&lt;/td&gt;
&lt;td&gt;(New edge from Post -&amp;gt; Vote/Comment)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Timestamp&lt;/td&gt;
&lt;td&gt;Timestamp&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;VoteType (for Vote)&lt;/td&gt;
&lt;td&gt;Score (for both Vote and Comment)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Text     (for Comment)&lt;/td&gt;
&lt;td&gt;Text  (for Comment)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Finally, we have the comment and vote tables.&lt;/strong&gt; Because SQL doesn&amp;rsquo;t store
lists of things in a single row, you must create another table and point it back
to the original row.  A post contains comments. But in SQL, it&amp;rsquo;s the reverse. A
comment table row points to the post.  This is such a common hack that it&amp;rsquo;s no
longer considered one.&lt;/p&gt;

&lt;p&gt;In Dgraph, a Post has an edge to the vote or comment, not the other way round.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is how the final Dgraph schema looks.&lt;/strong&gt; It&amp;rsquo;s a lot simpler than SQL.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/schema.png&#34; alt=&#34;Dgraph Schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In fact, SQL schema complexity increases rapidly as the relationships among
data increase.&lt;/em&gt; Each relationship would inadvertently require joins, which would
then need to be avoided by duplicating more information across tables. All this
adds a significant amount of application logic to deal with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conversely, in a graph database like Dgraph, schema is a pretty close
representation of your mind map.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;queries&#34;&gt;Queries&lt;/h3&gt;

&lt;p&gt;In the previous section, we saw that Dgraph schema is a lot simpler than the
equivalent SQL schema. In this section, we&amp;rsquo;ll see why that is the case, and how
Dgraph&amp;rsquo;s GraphQL inspired query language makes it easy to render various
Stack Overflow (referred to as SO) components.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: While reading the queries, note that these queries are just our
approximations of how SO works. We don&amp;rsquo;t work there, and thence, certain things
like ranking formulas are just put together to represent the power of the query
language. It&amp;rsquo;s not what SO uses.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s start with the home page.&lt;/strong&gt; We want to render 100 questions, and
all the associated meta information that SO shows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question Div&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the corresponding query fragment to retrieve the data to render one question div.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-question.png&#34; alt=&#34;Home page question&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_uid_  # Unique identifier

UpvoteCount: count(Upvote)      # Counts the number of Upvote edges.
DownvoteCount: count(Downvote)  # Counts the number of Downvote edges.
AnswerCount: count(Has.Answer)  # Counts the number of Answer edges.

ViewCount  # Retrieves the ViewCount property stored.

Title { # Title points to Version node.
  Text  # Retrieves the text of the title.
}

Owner { # Owner of the question, points to the User node.
  DisplayName  # User&#39;s display name, reputation, and identifier.
  Reputation
  _uid_
}

Tag {  # Points to multiple Tag nodes.
  TagName: Tag.Text  # Retrieves the text of the tag.
}

Has.Answer(orderdesc: Timestamp, first: 1) {  # Picks the most recent answer.
  Timestamp  # Retrieves Timestamp of the Answer.
  Owner {    # Retrieves the Owner of that Answer.
    DisplayName  # Retrieves display name, reputation, and identifier.
    Reputation
    _uid_
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have the question fragment let&amp;rsquo;s see how to retrieve a list of
questions depending upon the various tabs that SO shows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Latest 100 questions&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# All nodes of type question, in descending order by Timestamp, limit by 100.
questions(func: eq(Type, &amp;quot;Question&amp;quot;), orderdesc: Timestamp, first: 100) {
  ${questionFragment}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Top 100 hot questions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-hot-questions.png&#34; alt=&#34;Home page hot questions&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Get the latest 1000 questions.
var(func: eq(Type, &amp;quot;Question&amp;quot;), orderdesc: Timestamp, first: 1000) {
  Has.Answer {            # Get their answers
    uv as count(Upvote)   # Count the Upvote edges.
    dv as count(Downvote) # Count the number of Downvote edges.
  }
  ac as count(Has.Answer) # Count the number of Answers.
  cc as count(Comment)    # Count the number of Comments.

  uv1 as sum(var(uv))     # Sum up all Upvotes across all Answers.
  dv1 as sum(var(dv))     # Sum up all Downvotes across all Answers.

  # Put together a rough formula to calculate a final score per question.
  score as math(0.7 + ac * 0.2  + (uv1 - dv1) * 0.4 + (cc) * 0.4)
}

# Order the 1000 questions in descending order of score, pick the first 100.
questions(id: var(score), orderdesc: var(score), first: 100) {
  ${questionFragment}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Top Tags&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-toptags.png&#34; alt=&#34;Top tags&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To get the most frequently used tags, we can run this query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;t as var(func: eq(Type, &amp;quot;Tag&amp;quot;)) {  # Retrieve all tags. Assign it to variable t.
  c as count(~Tag)  # For each tag, count the number of incoming edges.
                    # This gives us the number of times each tag is used.
}

# For all tags in t, order them by count c and pick the first 10.
# This gives us the ten most popular tags.
topTags(id: var(t), orderdesc: var(c), first: 10) {
  _uid_
  TagName: Tag.Text      # Retrieve the text of the tag.
  QuestionCount: var(c)  # Reusing variable c, retrieve the number of times tag is used.
      # Note that only questions have tags. Hence we use QuestionCount alias.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Depending upon the number of tags, this query might be a tad slow. The most
popular tags don&amp;rsquo;t change that often. So, this is a good candidate for caching
in application. But, even so, the amount of application code that needs to go in
to generate the list of most popular tags is very little (run the query, cache
the results).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/question.png&#34; alt=&#34;Question&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Now let&amp;rsquo;s see how to render the question page.&lt;/strong&gt; This is one complex page, with
many components, touching almost all the tables in SQL. We&amp;rsquo;ll see how we can get
all the information in a single query to Dgraph.&lt;/p&gt;

&lt;p&gt;Before we dig into the question query, let&amp;rsquo;s create a bunch of reusable
fragments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Version Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Author {       # Retrieve Author node.
  DisplayName  # Retrieve their display name, reputation, and identifier.
  Reputation
  _uid_
}
Type  # Retrieve type, text and timestamp of Version.
Text
Timestamp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Comment Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_uid_
Author {       # Retrive Author node.
  _uid_        # Retrieve their display name and identifier.
  DisplayName
}
Text  # Retrieve Text, Score and Timestamp of Comment (no versioning here).
Score
Timestamp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Answer Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Answer is represented as a Post node.
_uid_

Body {  # Retieve body Version node.
  Text  # Retrieve text of Body.
}

# This is used for &amp;quot;answered x time ago.&amp;quot;
Owner {        # Retrieve owner User node.
  DisplayName  # Retrieve their display name, reputation, and identifier.
  Reputation
  _uid_
}

Timestamp  # Retrieve timestamp and type of Post.
Type

UpvoteCount: count(Upvote)     # Count the number of Upvote and Downvote edges.
DownvoteCount: count(Downvote)

# Post edge takes us from Version -&amp;gt; Post. ~Post is the reverse of that, taking us from Post -&amp;gt; Version. We order the Version nodes in desc order of Timestamp and pick the first 1. In other words, pick the latest Version of Answer.
# This is used for &amp;quot;edited x time ago.&amp;quot;
History: ~Post(orderdesc: Timestamp, first: 1) {
  ${VersionFragment}
}

# These are comments on answer. Question also have comments which are retrieved in the query below.
Comment {             # Get the Comment nodes.
  ${CommentFragment}  # Retrieve further details per Comment using fragment above.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var (id: ${questionUID}) {  # Retrieve the question node.
    Has.Answer {              # Retrieve the answers.
      uv as count(Upvote)     # Count the number of Upvote and Downvote edges.
      dv as count(Downvote)
      answer_score as math(uv - dv)  # Calculate an score per answer based on votes.
    }
  }

  question(id: ${questionUID}) {  # Retrieve the question node.
    _uid_
    Title {  # Retrieve the title Version node.
      Text   # Retrieve the text of the title.
    }
    Body {   # Retrieve the body Version node.
      Text   # Retrieve the text of the body.
    }
    Owner {        # Retrieve the owner of the question.
      DisplayName  # Retrieve their display name, reputation, and identifier.
      Reputation
      _uid_
    }

    ViewCount  # Retrieve some question properties.
    Timestamp
    Type

    UpvoteCount: count(Upvote)  # Count the number of Upvote and Downvote edges on question.
    DownvoteCount: count(Downvote)

    questionTags as Tag {  # Retrieve the question Tag nodes.
      TagName: Tag.Text    # Retrieve their text.
    }

    AnswerCount: count(Has.Answer)  # Count the number of answers.

    Has.Answer(orderdesc: var(answer_score)) {  # Retrieve the Answer nodes, and order them by the score calculated above.
      ${AnswerFragment}  # Retrieve answer details using fragment above.
    }

    Comment {  # Retrieve Comment nodes.
      ${CommentFragment}  # Retrieve comment details using fragment above.
    }

    History: ~Post(orderdesc: Timestamp, first: 1) {  # Just like in Answer, retrieve the latest Version of question.
      ${VersionFragment}  # Retrieve Version details using fragment above.
    }
  }

  # In the following query block, we use the tags of this question, to get related questions, and some minimal details about them; essentially title and vote counts.
  tags(id: var(questionTags)) {
    relatedQuestions: ~Tag(first: 10) {
      _uid_
      Title {
        Text
      }
      UpvoteCount: count(Upvote)
      DownvoteCount: count(Downvote)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the query above looks complex, don&amp;rsquo;t worry about it. Just read the comments, and get a sense for how we retrieve each piece of data that we need to render on the page. SO question page as mentioned before is pretty complex requiring recursions to retrieve all details of questions, comments, votes, owner, last editor. Similarly, we need answers, their comments, votes, owner, last editor. On top of that, we can sort the answers displayed by a score generated from vote counts. We can even limit the number of comments displayed if required.&lt;/p&gt;

&lt;p&gt;With SQL DB, all of this logic would have needed to be baked into the application. But, with Dgraph, the query language is so powerful that it can all be generated right within the database: doing recursions, computing counts, putting them to generate scores and then sort by these scores. This cuts down heavily on the application code, letting a developer focus on the feature set and the best way to render the data. And &lt;strong&gt;that&amp;rsquo;s powerful!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Full Text Search&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Dgraph also supports regular expression and full-text search in many languages.
You can create an index on string edges, to achieve this. In this case, we
created a full-text index on the &lt;code&gt;Text&lt;/code&gt; edge.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Text: string @index(fulltext) .&lt;/code&gt; line from schema.txt.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: anyoftext(Text, &amp;quot;${searchQuery}&amp;quot;)) @cascade {
  # All Version nodes which have any of the text in search query.
    p as Post {  # Retrieve their Post, assign it to variable p.

      # Pick the latest Version of the Post and check that it does have the search query. This is a bit of a shuffle and can be avoided by having a direct link from Post to its latest version.
      ~Post(orderdesc: Timestamp, first: 1) @filter(anyoftext(Text, &amp;quot;${searchQuery}&amp;quot;))
    }
  }

  # Pick the first 25 such posts.
  posts(id: var(p), first: 25) {
    _uid_

    Type

    question: ~Has.Answer {  # If this post is an answer, retrieve the question by traversing the Has.Answer edge in reverse.
      _uid_
      Title {
        Text
      }
    }

    Title { # Title Version would be present if this Post if Question.
      Text
    }
    Body {  # Body Version would be present if this Post is Answer.
      Text
    }

    # The rest of the fields are as explained before, and are from the perspective of the question Post node.
    Owner {
      DisplayName
      Reputation
      _uid_
    }
    Tag {
      TagName: Tag.Text
    }
    Chosen.Answer {
      Owner {
        DisplayName
        Reputation
        _uid_
      }
      Timestamp
    }
    UpvoteCount: count(Upvote)
    DownvoteCount: count(Downvote)
    AnswerCount: count(Has.Answer)
    ViewCount
    Timestamp
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;In this post, we showed you how a SQL schema compares against the equivalent
schema in Dgraph, basing our analysis on Stack Overflow data. We then picked
pages from Stack Overflow and showed you queries to retrieve all the data
necessary to render those pages.&lt;/p&gt;

&lt;p&gt;As you can see, Dgraph schema is significantly simpler than SQL, utilizing zero
or little schema hacks, pre-computation or duplication of data. Also,
Dgraph query language is way more powerful than SQL, handling most of the
complexity of recursive data retrieval, ranking and sorting within the database,
allowing the application to focus solely on the feature set and rendering of
data.&lt;/p&gt;

&lt;p&gt;Dgraph being a graph database provides sparsely populated fields and easy schema
manipulation, which allows developers to modify data types as they iterate over
their application, removing the need to do complex &lt;em&gt;upgrades&lt;/em&gt; of the entire system.&lt;/p&gt;

&lt;p&gt;Not only that, Dgraph makes it a lot faster for developers to iterate.
Modifying Dgraph queries is a lot cheaper operation for a developer,
than modifying the backend code; and Dgraph provides a nice UI to allow for
this.&lt;/p&gt;

&lt;p&gt;Finally, Dgraph supports regular expressions, term matching, full-text search
and equality matching for string types. All Dgraph edges are unidirectional, but
Dgraph allows you to specify creating reverses automatically, to aid in data
retrieval. It also supports indexing various other data types, like int, float,
datetime, etc.; very useful to build applications today.&lt;/p&gt;

&lt;p&gt;Overall, this post sheds light on why we think a graph database like Dgraph is a
better choice for developers today. It simplifies the data model,
significantly cuts down on the backend code, and allows faster iteration.&lt;/p&gt;

&lt;h3 id=&#34;links&#34;&gt;Links&lt;/h3&gt;

&lt;p&gt;All the data generation, querying and rendering code is located at &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;Dgraph&amp;rsquo;s Graph Overflow repository&lt;/a&gt;. Dgraph query language spec is &lt;a href=&#34;https://docs.dgraph.io/query-language/&#34;&gt;located here&lt;/a&gt;. Graph overflow site is still a work in progress, and we&amp;rsquo;ll put it up at dgraph.io soon.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/dragon&#34;&gt;Dragon&lt;/a&gt; is a next-generation spacecraft designed to take humans to Mars.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a Realtime Recommendation Engine: Part 2</title>
      <link>https://blog.dgraph.io/post/recommendation2/</link>
      <pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/recommendation2/</guid>
      <description>

&lt;p&gt;&lt;em&gt;This is part 2 of a two-part series on recommendations using Dgraph.  Check our &lt;a href=&#34;https://blog.dgraph.io/post/recommendation/&#34;&gt;part 1 here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the last post, we looked at how many applications and web apps no longer present static data, but rather generate interesting recommendations to users.  There&amp;rsquo;s a whole field of theory and practice in recommendation engines that we touched on, talking about &lt;strong&gt;content-based&lt;/strong&gt; (based on properties of objects) and &lt;strong&gt;collaborative&lt;/strong&gt; (based on similar users) filtering techniques based on a chapter from Stanford MOOC &lt;a href=&#34;https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about&#34;&gt;Minning Massive Datasets&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We dug deeper into content-based filtering and showed how &lt;em&gt;Jaccard&lt;/em&gt; distance and &lt;em&gt;Cosine&lt;/em&gt; distance can be encoded directly in Dgraph queries using Dgraph&amp;rsquo;s variables and math functions.&lt;/p&gt;

&lt;p&gt;This time we&amp;rsquo;ll look into collaborative filtering and hybrid recommendations in Dgraph queries.  Then we&amp;rsquo;ll look at how to build a real-time scalable recommendation engine for big graphs.&lt;/p&gt;

&lt;p&gt;To start with, we&amp;rsquo;ll continue with our &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;movie data&lt;/a&gt; from last time and then start looking at recommendations over Stack Exchange data.  We&amp;rsquo;ll keep it small in this post and use &lt;a href=&#34;https://lifehacks.stackexchange.com/&#34;&gt;Lifehacks&lt;/a&gt; data, but watch out for upcoming posts on loading all of Stack Overflow (2 Billion edges) into Dgraph and running the website and a recommendation engine with Dgraph as the backend.&lt;/p&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;h2 id=&#34;collaborative-filtering&#34;&gt;Collaborative filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering measures the similarity of objects based on their properties.
&lt;strong&gt;Rather than trying to find similar items, collaborative filtering works by finding similar users and then recommending items that similar users have rated highly.&lt;/strong&gt;  In the movie example from &lt;a href=&#34;https://blog.dgraph.io/post/recommendation/&#34;&gt;part 1&lt;/a&gt;, for a given user we first find the set of users that are similar, find movies those users rated highly and recommend some that our user hasn&amp;rsquo;t seen.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s say we are trying to recommend movies to Bob.&lt;/em&gt; If Bob and Alice have rated a movie highly and they
do this repeatedly for many movies, they are similar. The more movies they have in common this way,
the more similar Bob and Alice are. Once we have more similar users like Alice, we need to find those movies that
these users have rated highly. We then remove the movies that Bob has seen, leaving movies we should recommend to Bob.&lt;/p&gt;

&lt;p&gt;If we represent the movies that user $U_i$ and user $U_j$ have in common as&lt;/p&gt;

&lt;p&gt;$$M_{(u_i,u_j)}$$&lt;/p&gt;

&lt;p&gt;and write $R_{U_i}$ for a user&amp;rsquo;s rating function, then we can represent a distance (or similarity) score between two users as an average of their scores for the movies they both rated.&lt;/p&gt;

&lt;!--$$\frac{\sum{R_{U_i}(M_{(u_i,u_j)})} + \sum{R_{U_j}(M_{(u_i,u_j)})}}{|M_{(u_i,u_j)}|}$$--&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/collab_diff1.png&#34; alt=&#34;collaborative distance 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is how the query would look in Dgraph.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {                             # 1
    a as math(1)
    seen as rated @facets(r as rating) {  # 2
      ~rated @facets(sr as rating) {      # 3
        user_score as math((sr + r)/a)    # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) {  # 5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) {           # 6
      fscore as math(ur/norm)                                      # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note that this query is slightly different from the
formula in MOOC chapter, because although we can write cosine distance for content-based filtering
directly in the query language, the language does not yet support cosine distance when it
involves more than 1 traversal. However, this can be tackled by retrieving the subgraph from Dgraph,
doing the computation and writing the similarity scores back to Dgraph for further processing.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let us look at what different parts of the query do.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with a user whose id is 2 (our Bob)&lt;/li&gt;
&lt;li&gt;Get all the movies that this user has rated and their ratings&lt;/li&gt;
&lt;li&gt;Get all the users who have rated these movies and the corresponding ratings given by them (the Alices)&lt;/li&gt;
&lt;li&gt;Calculate the similarity to those users according to our metric&lt;/li&gt;
&lt;li&gt;Take the top 10 users based on the score calculated in the last step (the similar users)&lt;/li&gt;
&lt;li&gt;Get the ratings by the similar users for movies not seen by the user 2&lt;/li&gt;
&lt;li&gt;Normalize the rating as sum of all the ratings divided by number of ratings&lt;/li&gt;
&lt;li&gt;Get the top 10 movies based on the score calculated in the last step&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Recommendation&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;Hercules (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;How to Be a Player (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Othello (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;U Turn (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Edge, The (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Arrival, The (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Outlaw, The (1943)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Con Air (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;From Dusk Till Dawn (1996)&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;collaborative-filtering-only-with-high-scores&#34;&gt;Collaborative filtering, only with high scores&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s make an improvement.&lt;/em&gt; Consider the case when user A rated &lt;code&gt;movie-a&lt;/code&gt; 1, user B rated &lt;code&gt;movie-a&lt;/code&gt; 5, user A rated &lt;code&gt;movie-b&lt;/code&gt; 3 and user C rated &lt;code&gt;movie-b&lt;/code&gt; 3. Based on the average score for common movies, both user B and C will have a score of 3. But intuitively, we can say that user C is more similar to A than B. One way to avoid this would be by considering only the &lt;em&gt;good&lt;/em&gt; ratings which we can define as &amp;gt;= 3.&lt;/p&gt;

&lt;p&gt;So we can add a filter when we&amp;rsquo;re getting the ratings as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Collaborative filtering
{
  var(func: uid(2)) {  # 1
    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {     # 3
        user_score as math((sr + r)/a) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { # 5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) {          # 6
      fscore as math(ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Recommendation&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;Thinner (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Tales from the Hood (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Michael (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Hour of the Pig, The (1993)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Basic Instinct (1992)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Wild Bunch, The (1969)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Bound (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Richard III (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Spitfire Grill, The (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try and test how well this is working.  We don&amp;rsquo;t have any live users to test on, but one measure can be how well it predicts the known data.  &lt;em&gt;We removed the following 5 movies that user 2 rated as 5 and ran the query
to predict the ratings.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e5d&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e6e&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e77&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e79&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e7c&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The predicted ratings are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
          &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 5
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 3
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 5
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 3.833333
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 4.666667
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So 2 of the movies got 5 rating, one got 4.66, one 3.83, and one 3. &lt;em&gt;Not bad for a single query!&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;collaborative-filtering-with-penalty&#34;&gt;Collaborative filtering, with penalty&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s tweak it some more.&lt;/em&gt;  If the ratings by two users vary too, much they might not be as similar. For example, taking a straight average, ratings of 3 and 3 by the two users look the same as 5 and 1.  So lets penalize each user by the difference in rating &amp;mdash; as the rating difference grows the penalty increases.&lt;/p&gt;

&lt;p&gt;In the query below we multiply the average by:&lt;/p&gt;

&lt;p&gt;$$1 - {(\frac{sr-r}{5*a})}^2$$&lt;/p&gt;

&lt;p&gt;If the difference between ratings is small, the multiple will be closer to 1.  If the difference is larger, the multiple will be closer to 0, reducing the user&amp;rsquo;s similarity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {  # 1
    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {     # 3
        user_score as math(
        (sr + r)/a *
        (1 -  pow((sr-r)/(5*a),
        2))) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { #5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) { # 6
      fscore as math(ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    val(fscore)
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Predicated ratings for the ones that were removed from the dataset are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
            &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 5.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 2.75
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 5.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 4.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 4.666667
        },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The scores got closer to the removed actual scores, probably indicating that we removed some users from the similar users who didn&amp;rsquo;t vote highly for this movie.  &amp;ldquo;L.A. Confidential&amp;rdquo; was a bit of an outlier, going back slightly, indicating that we removed some users who enjoyed this one.&lt;/p&gt;

&lt;h2 id=&#34;hybrid-filtering&#34;&gt;Hybrid filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering found similar movies, based on a given movie.  Collaborative filtering found similar users and gave a recommendation of movies the similar users rated highly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hybrid filtering is when we combine the collaborative and content-based approaches into a single recommendation algorithm.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For our hybrid filtering, we&amp;rsquo;ll assign a score to each genre as the number of movies watched by user 2 in that genre. Then, after we&amp;rsquo;ve found the similar users, we&amp;rsquo;ll give a boost to the ratings of movies based on the genres that user 2 watches most.  That&amp;rsquo;s collaborative filtering to get the similar users and the movies they enjoy, and then content-based filtering to help order those movies based on genres.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {  # 1
    rated @groupby(genre) {
      gc as count(_uid_)
    }

    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {   # 3
        user_score as math((sr + r)/a) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { #5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) { # 6
      genre {
        q as math(gc)   # 6.1
      }
      x as sum(val(q))  # 6.2
      fscore as math((1+(x/100))*ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    val(fscore)
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This time, at step &lt;code&gt;#1&lt;/code&gt; the query gets a count of how many times our user has rated movies in each genre using Dgraph&amp;rsquo;s &lt;code&gt;groupby&lt;/code&gt;, so &lt;code&gt;gc&lt;/code&gt; will relate genres to number of movies rated in that genre.  Then, before calculating the score for each movie at step &lt;code&gt;#7&lt;/code&gt;, the query gives each genre in the movie a score, step &lt;code&gt;6.1&lt;/code&gt;, and sums a total score, step &lt;code&gt;6.2&lt;/code&gt;.  At step &lt;code&gt;#7&lt;/code&gt; each movie&amp;rsquo;s average score is multiplied by $1+\frac{x}{100}$.&lt;/p&gt;

&lt;p&gt;If a movie contains genres our user doesn&amp;rsquo;t watch so much, $\frac{x}{100}$ will be small and the movie won&amp;rsquo;t get much of a boost.  If it contains genres our user often rates movies of, then $x$ will be larger and thus $1+\frac{x}{100}$ will give a bigger bonus.&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;Recommendation&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Bound (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 8.15
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.75
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Kiss the Girls (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.45
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Legends of the Fall (1994)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.4
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Jane Eyre (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Crying Game, The (1992)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.065
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;To Catch a Thief (1955)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.95
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;American President, The (1995)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.857143
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Sirens (1994)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.813333
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.813333
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the collaborative filtering queries, the scores for the test movies were high, but so were many other movies that the similar users enjoyed.  The hybrid approach skews the result back more towards the genres that our user watches most. In the results, two of the 5-star rated movies (&lt;code&gt;Wings of the Dove, The (1997)&lt;/code&gt; and &lt;code&gt;As Good As It Gets (1997)&lt;/code&gt;) showed up in the top 10.&lt;/p&gt;

&lt;h2 id=&#34;scaling-recommendations&#34;&gt;Scaling recommendations&lt;/h2&gt;

&lt;p&gt;If you look carefully at the last query, you can see that the graph size explodes very easily.
Say you rated 50 movies and those movies were rated by 20000 other people on average, you touch 1M nodes every time
you want to run this recommendation query.  If we are running many of these queries for different users or as the graph grows, this could get too much.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s look at how we can make this efficient by storing intermediate results back. In general,
people rate a movie less frequently than they view recommendations. Thus, the frequency of rating
updates is less than the frequency of generating recommendations.  So if we can calculate the
similarity scores only when a user rates a movie, and store it back to Dgraph; we can retrieve the
recommended movies cheaply by using this stored similarity score between users.&lt;/p&gt;

&lt;p&gt;For this, we can run the first part of the query, which calculates the similar users and store the top scores in an edge connecting
the users. Now, when we want to do recommendation, we can directly get the top similar users and then just have to do the 2nd part
of the query which is getting the average ratings for the movies that these similar users rated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/newedge.png&#34; alt=&#34;Edge creation with score&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that this would require some extra code in the application which creates these edges when an
update happens but can make the recommendation query highly performant even for extremely large
datasets.  Typically user similarity scores are generated as a batch process. With this approach, we
can generate these scores incrementally, triggered by user actions; which would also improve the
freshness of the recommendations.&lt;/p&gt;

&lt;h2 id=&#34;stack-overflow&#34;&gt;Stack Overflow&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s look at a different kind of dataset which has users, posts (questions, answers, comments),
upvotes, downvotes, etc. This has around 450k triples in it and was obtained from Lifehacks Stack Exchange forum.&lt;/p&gt;

&lt;p&gt;Say we want to recommend what a user should read based on their upvotes. This is similar to the
collaborative filtering we saw in the last section.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find similar users who have upvoted the same content.&lt;/li&gt;
&lt;li&gt;Then find the content similar users have upvoted but the given user has not interacted with.&lt;/li&gt;
&lt;li&gt;Then, to order the content we can see how many of the similar users have upvoted the content.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First, let&amp;rsquo;s take a look at the schema for a part of the data that is of interest to us.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/soSchema.png&#34; alt=&#34;Stack Overflow schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The query to do collaborative filtering on this dataset is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Recommend similar questions to read based on upvote.
{
  user as var(func: eq(DisplayName, &amp;quot;Mooseman&amp;quot;)) { # 1
    a as math(1)
    ~Author { # 2
      seen as ~Upvote { # 3
        Upvote {    # 4
          Author {  # 5
            sc as math(a)
          }
        }
      }
    }
  }

  var(func: uid(sc), orderdesc: val(sc), first: 50) @filter(not uid(user)) {  # 6
    b as math(1)
    ~Author { # 7
      ~Upvote @filter(not uid(seen) and eq(Type, &amp;quot;Question&amp;quot;)) { # 8
        fsc as math(b)
      }
    }
  }

  topQ(func: uid(fsc), orderdesc: val(fsc), first: 10) {  # 9
    Title {
      Text
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at what the numbered lines in the query represent:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with a user whose name is &lt;code&gt;Mooseman&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;~Author&lt;/code&gt; edge which leads to the votes he has created&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;~Upvote&lt;/code&gt; edge which leads us to the posts he has upvoted&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;Upvote&lt;/code&gt; edge to get all the upvotes on these posts&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;Author&lt;/code&gt; edge to get the users who created these upvotes and store the number of paths between the starting user and this user in a variable &lt;code&gt;sc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Pick the top 50 users by the score we calculated&lt;/li&gt;
&lt;li&gt;Get the upvotes created by these users&lt;/li&gt;
&lt;li&gt;Get the posts which are of type question not seen by &lt;code&gt;Mooseman&lt;/code&gt; and assign them a score which is the number of upvotes by these top (similar) users. This score is store in variable &lt;code&gt;fsc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use the score we calculated in &lt;code&gt;fsc&lt;/code&gt; to get the top 10 questions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;topQ&amp;quot;: [
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I keep my cat off my keyboard?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How do I stop my earphones from getting tangled&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Ηow can I keep my jeans&#39; zippers from unzipping on their own?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I work out my girlfriend&#39;s ring size, without asking her or using a ring?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I improvise a magnifying glass?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Sleeping in a noisy environment&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I black out a bright bedroom at night?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How do I stop cars from tailgating?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Driving into garage where there is little room for error?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I boost my wifi range?&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make this recommendation scalable, we can create an edge between the most similar users
when an update (in this case, an upvote) happens. Then, when a user logs in, we can cheaply compute
their recommendations using these edges directly.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With that, we conclude this post.&lt;/em&gt; In this post, we showed how collaborative filtering based on similar users can be encoded in Dgraph queries.  We showed a couple of approaches so you can get a flavour of the kind of flexibility Dgraph allows. We also combined content-based and collaborative approaches into a hybrid recommendation system that found similar users and then ranked movies with genres our user enjoyed.&lt;/p&gt;

&lt;p&gt;Content-based filtering can be useful when recommending to users who have rated few movies. This is how websites bootstrap recommendation when you join, for example, by asking for your 5 favourite movies and then showing movies that are similar to them. Then, as you start rating movies, a switch to collaborative filtering utilizes user similarity and starts to improve recommendations further.&lt;/p&gt;

&lt;p&gt;We can&amp;rsquo;t tell you what metrics will work best in your case &amp;mdash; that&amp;rsquo;ll be based on your data and users and a fair amount of thinking and experimenting.  But what we&amp;rsquo;ve done here is to show you how you can translate your ideas into reality using Dgraph. &lt;em&gt;Hope this gets you started on the path to adding a recommendation system in your application.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;coming-up&#34;&gt;Coming up&lt;/h3&gt;

&lt;p&gt;Watch out for an upcoming series of posts where we explore how typical web apps can benefit from Dgraph.  We&amp;rsquo;ll show how we loaded all the data from the &lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;Stack Overflow data dumps&lt;/a&gt;, which is more than 2 billion edges, into Dgraph and run Stack Overflow with Dgraph as the sole backend DB.  We&amp;rsquo;ll explore the tradeoffs that are made in doing this in SQL vs a graph database and we&amp;rsquo;ll look at the recommendation engine we&amp;rsquo;re building on top of all that Stack Overflow data.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/2017/1-amazingspace.jpg&#34;&gt;A stunning view of the Falcon 9 rocket just before landing on a barge&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a Realtime Recommendation Engine: Part 1</title>
      <link>https://blog.dgraph.io/post/recommendation/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/recommendation/</guid>
      <description>

&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;

&lt;p&gt;In today&amp;rsquo;s world, user experience is paramount. It&amp;rsquo;s no longer about basic CRUD, just serving user
data; it&amp;rsquo;s about mining the data to generate interesting predictions and suggesting actions to the
user.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the field of recommendations. They&amp;rsquo;re everywhere. In fact, they happen so frequently that you
don&amp;rsquo;t even realize them.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You wake up and open Facebook,&lt;/em&gt; which shows you a feed of articles that it
has chosen for you based on your viewing history.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to buy something?&lt;/em&gt; Amazon would recommend
you things to purchase based on what you&amp;rsquo;ve viewed in the recent past.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to relax and unwind with a movie?&lt;/em&gt; Netflix would recommend you what to watch based on your
interests.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;No time to watch a full movie?&lt;/em&gt; YouTube would recommend you smaller chunk videos.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to listen to music instead?&lt;/em&gt; Spotify would generate a weekly discovery list of songs just for
you.&lt;/p&gt;

&lt;p&gt;All this makes you wonder: &lt;strong&gt;Should recommendations be part of your application?&lt;/strong&gt; While competing
against Netflix might be hard, in this two-part series, we&amp;rsquo;ll explain the basics of a recommendation
engine. We&amp;rsquo;ll show how you can build recommendations via two approaches: Content-based filtering and
Collaborative filtering. And, how you can use Dgraph to bring recommendations to your app without breaking a
sweat.&lt;/p&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;For this, we&amp;rsquo;ll make use of Dgraph&amp;rsquo;s query variables. To learn more about variables, head over to
&lt;a href=&#34;https://tour.dgraph.io/blocksvars/1/&#34;&gt;Dgraph tour&lt;/a&gt; &amp;mdash; &lt;em&gt;if you are new to Dgraph variables, you
really should check them out first before diving in here.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first check out how recommendation systems work, and then we&amp;rsquo;ll look at the support Dgraph queries offer.  We&amp;rsquo;ll use two sample datasets.  One about movies and ratings (&lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;Movielens&lt;/a&gt;) and the other is part of &lt;a href=&#34;https://archive.org/download/stackexchange/lifehacks.stackexchange.com.7z&#34;&gt;Stack Exchange&amp;rsquo;s data archive&lt;/a&gt; &amp;mdash; we&amp;rsquo;ll just use the Lifehacks dataset here, but watch out for a coming series of posts where we show how to load all of Stack Overflow into Dgraph and run the entire website completely off Dgraph.&lt;/p&gt;

&lt;h2 id=&#34;recommendation-systems&#34;&gt;Recommendation Systems&lt;/h2&gt;

&lt;p&gt;Making Recommendations is a subtle art.  There are a number of approaches and a production worthy recommendation system might depend on data, weighting of various features, global user behaviour and maybe recent behaviour of the user we are recommending for.&lt;/p&gt;

&lt;p&gt;Rather than just inventing recommendation queries, let&amp;rsquo;s start somewhere more grounded.  For this post, we started with the Stanford University MOOC &lt;a href=&#34;https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about&#34;&gt;Minning Massive Datasets&lt;/a&gt;.  Part of the course is on recommender systems.  We&amp;rsquo;ll show how the theory in the &lt;em&gt;&amp;ldquo;Recommendation Systems&amp;rdquo;&lt;/em&gt; chapter of the &lt;a href=&#34;http://www.mmds.org&#34;&gt;text&lt;/a&gt; can be translated into practice using Dgraph. We&amp;rsquo;ll also talk about other approaches and how to run one at scale.&lt;/p&gt;

&lt;h3 id=&#34;making-recommendations&#34;&gt;Making Recommendations&lt;/h3&gt;

&lt;p&gt;Making recommendations is about taking past benaviour and preferences and trying to predict a preference for some unknown.  For example, later in the post, we&amp;rsquo;ll talk about movie recommendations.  For this, we know what a user has watched and how they rated movies; how then can we predict what unwatched movies they&amp;rsquo;ll enjoy.&lt;/p&gt;

&lt;p&gt;As briefly mentioned before, broadly speaking, there are two basic approaches:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Content-based:&lt;/strong&gt; Such systems base a recommendation on the properties of an item. Two items that have similar properties are deemed similar; the more properties shared, the more similar. For example, if a user likes movies with certain actors or directors, we can
recommend other movies involving the same people.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Collaborative filtering:&lt;/strong&gt; Such systems base recommendations on the relationship between users and items, and similarity to other users. Users are similar if they have relationships to items in common; the more items in common, the more similar.  For example, if many similar users enjoyed a particular movie, that might be a good one to recommend.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are also classification algorithms based on machine learning.  We&amp;rsquo;ll focus here on how far we can get with Dgraph queries alone.  Machine learning or other algorithms could also be run over the Dgraph output.&lt;/p&gt;

&lt;h3 id=&#34;interpreting-the-data-for-recommendations&#34;&gt;Interpreting the Data for Recommendations&lt;/h3&gt;

&lt;p&gt;Our Stanford reference text represents data as a sparse matrix.  So for our movie data set, we might think of the user&amp;rsquo;s ratings of movies as:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;th&gt;The Matrix&lt;/th&gt;
&lt;th&gt;Toy Story&lt;/th&gt;
&lt;th&gt;Jurassic Park&lt;/th&gt;
&lt;th&gt;Forrest Gump&lt;/th&gt;
&lt;th&gt;Braveheart&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The movies also have other properties such as genres, not shown here.  We&amp;rsquo;ve stored it all as a graph, which in itself is a nice way to store a sparse matrix.&lt;/p&gt;

&lt;p&gt;The matrix (that&amp;rsquo;s the matrix above, not &lt;em&gt;&amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/The_Matrix&#34;&gt;The Matrix&lt;/a&gt;&amp;ldquo;&lt;/em&gt;) is missing values because users haven&amp;rsquo;t seen all movies &amp;mdash; in fact, for the real dataset it&amp;rsquo;s much sparser because users have each only rated a tiny percentage of the movies.&lt;/p&gt;

&lt;p&gt;The challenge of recommendation is to predict values for the missing ratings.  Will user A enjoy Braveheart because it&amp;rsquo;s an action movie and thus similar to movies they enjoyed? (content based filtering)&lt;/p&gt;

&lt;p&gt;But maybe they won&amp;rsquo;t enjoy it because they might have something in common with user B who seems to share similar ratings (collaborative filtering).&lt;/p&gt;

&lt;p&gt;Maybe user A just gives high ratings and isn&amp;rsquo;t very discriminating &amp;mdash; sometimes benaviour rather than rating can be a better predictor. We&amp;rsquo;ll need to combine a number of approaches.&lt;/p&gt;

&lt;p&gt;The theory boils down to finding functions that serve as measures of similarity or distance.  For example, in content-based filtering, the function would take two movies and output a score (the distance or similarity).  If we start with a movie and apply the function repeatedly to it and all other movies, we can find the most similar movies.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll look at some distance measures below as we apply them in queries, but for any of them we&amp;rsquo;ll need to propagate values through our query, so let&amp;rsquo;s look at how that works in Dgraph and then try out some recommendation queries.&lt;/p&gt;

&lt;h2 id=&#34;variable-propagation&#34;&gt;Variable Propagation&lt;/h2&gt;

&lt;p&gt;A Dgraph &lt;a href=&#34;https://docs.dgraph.io/query-language/#value-variables&#34;&gt;value variable&lt;/a&gt; is a mapping from graph nodes to values that have been computed for the nodes during the query.  Value variables can be passed around the query, aggregated etc.  Value variables also sum over paths as we move deeper into a query tree.&lt;/p&gt;

&lt;p&gt;Within a query tree, a value variable defined at one level, propagates such that in a nested level, the variable is the sum of all paths from the definition.&lt;/p&gt;

&lt;p&gt;We call this &lt;strong&gt;variable propagation.&lt;/strong&gt;  Note that the queries in this post we built for our master branch for the upcoming v0.8 release.&lt;/p&gt;

&lt;p&gt;Say you had a query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(&amp;lt;...P...&amp;gt;)) {
    myscore as math(1)          # A
    friends {                   # B
      friends {                 # C
        fscore as math(myscore)
      }
    }
  }

  closeFriends(func: uid(fscore), orderdesc: val(fscore)) {
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At line A, nodes are assigned a score of &lt;code&gt;1&lt;/code&gt; (which in this case we&amp;rsquo;ll assume is the single node &lt;code&gt;P&lt;/code&gt;).
Traversing the &lt;code&gt;friend&lt;/code&gt; edge twice reaches the friends of friends.  The variable &lt;code&gt;myscore&lt;/code&gt; gets
propagated, such that the value inside the block marked C is the sum of values from all paths from A to C.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s how that propagation looks in a graph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/vartransform.png&#34; alt=&#34;Variable propagation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In short, the value that a node receives is equal to the sum of values of all its parent nodes.&lt;/strong&gt;
This propagation is useful when we want to normalize a sum across users, find the number of paths
between some nodes or accumulate a sum as we move through the graph.&lt;/p&gt;

&lt;h2 id=&#34;movielens&#34;&gt;Movielens&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with the &lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;ML-100k&lt;/a&gt; dataset of
100,000 ratings from 1000 users on 1700 movies. We converted the dataset to RDF (the dataset and
script can be found at
&lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;github&lt;/a&gt;) and loaded it into
Dgraph.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s about users and movies and user&amp;rsquo;s ratings of movies.  So a user (a node in the graph) has a name and a gender and a &lt;code&gt;rated&lt;/code&gt; edge to a movie.  The &lt;code&gt;rated&lt;/code&gt; edge has a facet &lt;code&gt;rating&lt;/code&gt; that tells us the users numeric 0&amp;ndash;5 rating of the movie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/movilensschema.png&#34; alt=&#34;Movielens schema&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;content-based-filtering&#34;&gt;Content-based filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering ranks items as similar or not based on their properties.  There are a number of measures we could use.  Our reference text from Stanford talks about &lt;strong&gt;Jaccard&lt;/strong&gt; and &lt;strong&gt;Cosine&lt;/strong&gt; distances.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance&#34;&gt;Jaccard Distance&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try some measure functions based on Jaccard distance.  For two sets A and B the Jaccard distance is given by&lt;/p&gt;

&lt;p&gt;$$1-\frac{|A\cap B|}{| A\cup B |}$$&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the ratio of the size of the set intersection to the size of the union.  So if items have many properties in common (compared to how many properties each has) then the items are similar.  For our movie example, let&amp;rsquo;s take $A$ and $B$ as the genre sets for each movie.  We can then express our difference function as:&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = 1-\frac{|M_1.\mathcal{genres} \cap M_2.\mathcal{genres}|}{| M_1.\mathcal{genres}\cup M_2.\mathcal{genres} |}$$&lt;/p&gt;

&lt;p&gt;The closer the result is to 0, the closer the movies &amp;mdash; if the number of genres in common is more, the second term is close to 1, if movies have few genres in common, the second term is closer to 0.&lt;/p&gt;

&lt;p&gt;For movie a $M_1$, we picked &amp;ldquo;The Shawshank Redemption&amp;rdquo; with unique ID &lt;code&gt;0x30d80&lt;/code&gt;, and translated Jaccard distance to this query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Count the genres for every movie that has been rated
  var(func: has(~rated)) {
    M2_num_genres as count(genre)
  }


  # Calculate a Jaccard distance score for every movie that shares
  # at least 1 genre with the given movie.
  var(func: uid(0x30d80)) {    # M1
    norm as math(1)               # 1
    M1_num_genres as count(genre) # 2
    M1genres as genre {           # 3
      ~genre {
        # M2 -- movies reached here share a genre with the initial movie
        # normalize the count to account for multiple paths
        M1_num_genres_norm as math(M1_num_genres / norm)      # 4
        num_genres as count(genre @filter(uid(M1genres))) # 5
        distance as math( 1 - ( num_genres / (M1_num_genres_norm + M2_num_genres - num_genres) )) # 6
      }
    }
  }

  # Sort and return closest movies.
  similarMovies(func: uid(distance), orderasc: val(distance), first: 10) { # 7
    name
    val(distance)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Count the number of genres for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the count of genres set at &lt;code&gt;# 2&lt;/code&gt; would have accumulated for each path, so normalize back to the original count.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the Jaccard distance formula &amp;mdash; &lt;code&gt;distance&lt;/code&gt; is thus a map for each $M_2$ to the Jaccard distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had lowest distance)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here&amp;rsquo;s the results we got for &amp;ldquo;The Shawshank Redemption&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Miracle on 34th Street (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Postman, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Mat&#39; i syn (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Winter Guest, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Chamber, The (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Picnic (1955)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Nell (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Dead Man Walking (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Blue Angel, The (Blaue Engel, Der) (1930)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ouch, there&amp;rsquo;s a bunch of movies with distance 0.  That means all those movies share exactly the same genre set with &amp;ldquo;The Shawshank Redemption&amp;rdquo;, so we can&amp;rsquo;t discriminate between them.  Let&amp;rsquo;s test another movie.  With &amp;ldquo;Toy Story&amp;rdquo; we get.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin and the King of Thieves (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Toy Story (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin (1992)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Goofy Movie, A (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Flintstones, The (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.333333
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s better.  At least similar movies have similar genres. But still, the Jaccard distance function isn&amp;rsquo;t good enough because it can&amp;rsquo;t discriminate a difference between many movies.  Our reference text suggests the same distance function but for data that also has actors and directors, which we don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;As it stands, the Jaccard distance might not be so appropriate because the only items we have to compare are the genres, since the Jaccard distance doesn&amp;rsquo;t take into account the magnitude of the ratings.  So let&amp;rsquo;s play around with it and see how some variations come out.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance-variation&#34;&gt;Jaccard Distance Variation&lt;/h3&gt;

&lt;p&gt;The size of the intersection of the genres seems a reasonable start, but how to bring the magnitude of the ratings into it?  If we are to use the ratings, then the average rating might be appropriate.  Let&amp;rsquo;s try the number of genres in common plus an average rating.  Given a movie $M_1$ we&amp;rsquo;ll find the similarity to all other movies $M_2$ as&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = |M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_2.\overline{\mathcal{rating}}$$&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the Dgraph query for movie $M_1$ having unique ID &lt;code&gt;0x30d72&lt;/code&gt;, that&amp;rsquo;s &amp;ldquo;Star Wars&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # M1 -- Star Wars by its unique ID
  var(func: uid(0x30d72)) {
    g as genre
  }

  # Calculate the average rating for every movie
  var(func: has(rated)) {
    allmovies as rated @facets(a as rating) {
      c as count(~rated)
      avg as math(a / c)
    }
  }

  # Give every movie a score
  var(func: uid(allmovies)) {
    x as count(genre @filter(uid(g)))
    score as math(avg + x)
  }

  # Return the top 10 movies
  fin(func: uid(score), orderdesc: val(score), first: 10) {
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;In terms of variable propagation, the important part is the calculation of average rating.&lt;/strong&gt;  If an edge has a facet and we assign the facet to a variable, we calculate the average. Then for each node reached by the block the variable is the sum of the facets of all such edges reaching the node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/facetsumming.png&#34; alt=&#34;Facet summing&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running the query we get the following results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;fin&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Wars (1977)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.358491
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Empire Strikes Back, The (1980)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.20436
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Return of the Jedi (1983)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.00789
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;African Queen, The (1951)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 8.184211
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Starship Troopers (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.232227
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Princess Bride, The (1987)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.17284
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Kid (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aliens (1986)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.947183
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Trek: The Wrath of Khan (1982)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.815574
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Men in Black (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.745875
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note that we didn&amp;rsquo;t filter out &amp;ldquo;Star Wars&amp;rdquo; and thankfully it came back as the first result.&lt;/em&gt;  Looks like a pretty good distance function, especially given the top three results, but it&amp;rsquo;s probably biased.  &amp;ldquo;Star Wars&amp;rdquo; is highly rated on average, and so we got back other highly rated movies with intersecting genres.  If we searched for a movie that wasn&amp;rsquo;t highly rated on average, the measure would still prefer highly rated movies with intersecting genres.&lt;/p&gt;

&lt;p&gt;That might be fine.  If a user likes certain genres, then maybe highly rated movie in those genres are good recommendations. Maybe it&amp;rsquo;s better to normalize the result so that two movies come out as more similar if they have genres in common and similar average ratings.  That&amp;rsquo;s what cosine distance does.&lt;/p&gt;

&lt;h3 id=&#34;cosine-distance&#34;&gt;Cosine Distance&lt;/h3&gt;

&lt;p&gt;Cosine distance treats our movies as vectors in an n-dimensional space.  The similarity of the movies is then a measure of the difference in angle between the vectors.  The smaller the angle between two vectors, the more similar the movies.  For our movie example, we can express that as follows.&lt;/p&gt;

&lt;p&gt;If we treat our movies as vectors&lt;/p&gt;

&lt;p&gt;$$x_1 &amp;hellip; x_n$$ and $$y_1 &amp;hellip; y_n$$&lt;/p&gt;

&lt;p&gt;the cosine difference between them is computed by calculating the vector dot product divided by the multiple of the distances from the origin.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/cosine_diff.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!--
what&#39;s wrong with this???
$$\frac{\sum_{i=1}^n{x_iy_i}}{\sqrt{\sum_{i=1}^n{x_i^2}}\cdot \sqrt{\sum_{i=1}^n{x_i^2}}}$$
If I paste it into http://www.hostmath.com/ I get what I want
--&gt;

&lt;p&gt;In our case the $x$&amp;rsquo;s up to $x_{n-1}$ will represent the genres, with 1 for genre present and 0 for not present.  While the last term is the average rating.  So for our movie example we can express the cosine difference as.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/cosine_diff_movies.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!-- d(M_1,M_2) = \frac{|M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_1.\overline{\mathcal{rating}} \cdot M_2.\overline{\mathcal{rating}}}{\sqrt{|M_1.\mathcal{genres}| + {M_1.\overline{\mathcal{rating}}}^2}\cdot \sqrt{|M_2.\mathcal{genres}| + {M_2.\overline{\mathcal{rating}}}^2}} --&gt;

&lt;p&gt;That factors in both the intersecting genres as well as the similarity of the average ratings.&lt;/p&gt;

&lt;p&gt;As a single Dgraph query, that looks like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Calculate the average rating of every movie
  var(func: has(rated)) {
    rated @facets(r as rating) {
      c as count(~rated)
      M2_avg_rating as math(r / c)
      M2_num_gen as count(genre)
    }
  }

  # Calculate a cosine difference score for every movie that shares
  # at least 1 genre with M1
  var(func: uid(0x30d80)) {    # movie M1
    norm as math(1)     # 1

    # Find the average rating for M1
    M1_num_ratings as count(~rated)
    ~rated @facets(B as rating)
    M1_ratings_sum as sum(val(B))
    M1_avg_rating as math(M1_ratings_sum / M1_num_ratings) # 2
    M1_num_gen as count(genre)                             # 3

    M1_genres as genre {
      ~genre { # 4
        # M2 -- movies reached here share a genre with the initial movie

        # normalize the M1 count and average to account for multiple paths
        M1_norm_avg as math(M1_avg_rating / norm)
        num_genN as math(M1_num_gen/norm)              # 5
        genint as count(genre @filter(uid(M1_genres))) # 6

        score as math((genint + (M1_norm_avg * M2_avg_rating)) /
          (sqrt(num_genN + (M1_norm_avg*M1_norm_avg)) *
          sqrt(M2_num_gen + (M2_avg_rating*M2_avg_rating))))    # 7

      }
    }
  }

  similarMovies(func: uid(score), first:20, orderdesc: val(score)) { # 8
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Find the average rating for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Count the genres for $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the values from &lt;code&gt;# 2&lt;/code&gt; and &lt;code&gt;# 3&lt;/code&gt; would have accumulated for each path, so normalize back to the originals.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the cosine distance formula &amp;mdash; &lt;code&gt;score&lt;/code&gt; is thus a map for each $M_2$ to the cosine distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had cosine closer to 1, and thus lowest angle)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We searched again for the &amp;ldquo;The Shawshank Redemption&amp;rdquo; and got these results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shawshank Redemption, The (1994)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 1.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Anna (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Some Mother&#39;s Son (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;12 Angry Men (1957)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999988
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Bitter Sugar (Azucar Amargo) (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999985
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Citizen Kane (1941)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;To Kill a Mockingbird (1962)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;One Flew Over the Cuckoo&#39;s Nest (1975)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Pather Panchali (1955)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999965
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Good Will Hunting (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999958
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We didn&amp;rsquo;t filter out &amp;ldquo;The Shawshank Redemption&amp;rdquo; and thus it comes back as the top result &amp;mdash; it has an angle of 0 with itself.  Following that the query returns the results that cosine difference calculates as most similar.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With that, we conclude this post.&lt;/em&gt; In this post, we showcased Jaccard distance, a variation of Jaccard, and finally Cosine
distance. That&amp;rsquo;s three content-based filtering distance metrics and queries for them in Dgraph.  The variables and math function in Dgraph allow us to encode the metrics directly in the query.&lt;/p&gt;

&lt;p&gt;In the next post, we&amp;rsquo;ll take a look at collaborative filtering.  We&amp;rsquo;ll also look at making recommendations for Stack Overflow and how to build a scalable recommendation engine for big graphs.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/media-gallery/detail/149441/9516&#34;&gt;FALCON 9 FIRST STAGE LANDING&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>go get github.com/dgraph-io/dgraph/...</title>
      <link>https://blog.dgraph.io/post/goget/</link>
      <pubDate>Mon, 29 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/goget/</guid>
      <description>&lt;p&gt;Thank you Go community for all the love that you showered on Badger. Within 8 hours of announcing
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, the blog post &lt;a href=&#34;https://news.ycombinator.com/item?id=14335931&#34;&gt;made it to the first
page&lt;/a&gt; of Hacker News. And within three days, the
Github repo received 1250 stars, having crossed 1500 by the time of this post. We have already
merged &lt;a href=&#34;https://github.com/dgraph-io/badger/graphs/contributors&#34;&gt;contributions&lt;/a&gt; and received
&lt;a href=&#34;https://github.com/dgraph-io/badger/issues&#34;&gt;feedback&lt;/a&gt; that we need to work on.&lt;/p&gt;

&lt;p&gt;All this goes to show how much people enjoy Go native libraries. They
make things easier. Any tool, library or system written in Go can now just run &lt;code&gt;go get
github.com/dgraph-io/badger&lt;/code&gt;, and they have a fast, efficient key-value store to use.&lt;/p&gt;

&lt;p&gt;Dgraph users have been asking us about embeddable and go gettable Dgraph for a while. After
hearing from many different users independently, I decided to &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/673&#34;&gt;create a Github
issue&lt;/a&gt; to track it.&lt;/p&gt;

&lt;p&gt;We had two dependencies on Cgo which prevented &lt;code&gt;go get&lt;/code&gt;able Dgraph in the past:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ICU library to do tokenization and full-text search.&lt;/li&gt;
&lt;li&gt;RocksDB as the key-value store.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Back in Q1 2017, we got rid of C based ICU library and switched to using parts of Bleve. Bleve simplified our code base, at the cost of losing &lt;a href=&#34;http://www.blevesearch.com/&#34;&gt;CJK support&lt;/a&gt;. But, we thought that&amp;rsquo;s a trade-off we can live with for the time being.&lt;/p&gt;

&lt;p&gt;The second step of replacing RocksDB was a lot harder, and a lot more interesting journey,
culminating in the release of Badger.&lt;/p&gt;

&lt;p&gt;Today, we &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commit/ed048d5d59248875c55ff5fbf14025e67f1a164c&#34;&gt;pushed a
change&lt;/a&gt; to
Dgraph master branch to switch to Badger. That single change resulted in 450K deleted lines and made Dgraph
&lt;code&gt;go get&lt;/code&gt;able. &lt;strong&gt;This is an exciting day for the Dgraph team, as it simplifies our lives as
developers hugely.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not only would we have simpler, faster builds and releases; we&amp;rsquo;d also have profiles going all the way down to
the disk, and all the way out to the RAM. Every aspect of Dgraph system can now be tweaked for
performance. No hard language boundaries, and that&amp;rsquo;s powerful.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I adore changes which delete more code than they add, while also gaining simplicity and functionality. This change is one of those.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/remove-badger-pr.png&#34; alt=&#34;Dgraph PR to replace Badger&#34; /&gt;
&lt;a href=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5.png&#34; alt=&#34;asciicast&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Happy go getting!&lt;/strong&gt; It needs a bit more work before Dgraph can be embedded in your Go code, but
that is coming soon to master. It would be part of the v0.8 release.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: Dgraph in master branch contains latest changes and isn&amp;rsquo;t thoroughly tested. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://apod.nasa.gov/apod/ap060522.html&#34;&gt;Canadarm aboard the ISS&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Badger: A fast key-value store written purely in Go</title>
      <link>https://blog.dgraph.io/post/badger/</link>
      <pubDate>Sun, 14 May 2017 20:18:15 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/badger/</guid>
      <description>

&lt;p&gt;We have built an efficient and persistent log structured merge (LSM) tree based key-value store,
purely in Go language.  It is based upon &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WiscKey paper included in USENIX FAST
2016&lt;/a&gt;. This design is
highly SSD-optimized and separates keys from values to minimize I/O amplification; leveraging both
the sequential and the random performance of SSDs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We call it &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/strong&gt; Based on benchmarks, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is at least &lt;strong&gt;3.5x faster than RocksDB&lt;/strong&gt; when
doing random reads.  For value sizes between 128B to 16KB, data loading is 0.86x - 14x faster
compared to RocksDB, with &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; gaining significant ground as value size increases. On the flip
side, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower for range key-value iteration, but that has a lot of room for
optimization.&lt;/p&gt;

&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;

&lt;h3 id=&#34;word-about-rocksdb&#34;&gt;Word about RocksDB&lt;/h3&gt;

&lt;p&gt;RocksDB is the most popular and probably the most efficient key-value store in the market. It originated
in Google as SSTable which formed the basis for Bigtable, then got released as LevelDB. Facebook
then improved LevelDB to add concurrency and optimizations for SSDs and released that as
RocksDB. Work on RocksDB has been continuously going on for many years now, and it&amp;rsquo;s used in
production at Facebook and many other companies.&lt;/p&gt;

&lt;p&gt;So naturally, if you need a key-value store, you&amp;rsquo;d gravitate towards RocksDB. It&amp;rsquo;s a
solid piece of technology, and it works. The biggest issue with using RocksDB is that it is written in &lt;code&gt;C++&lt;/code&gt;;
requiring the use of Cgo to be called via Go.&lt;/p&gt;

&lt;h3 id=&#34;cgo-the-necessary-evil&#34;&gt;Cgo: The necessary evil&lt;/h3&gt;

&lt;p&gt;At Dgraph, we have been using RocksDB via Cgo since we started. And we&amp;rsquo;ve faced many issues over
time due to this dependency. &lt;a href=&#34;https://dave.cheney.net/2016/01/18/cgo-is-not-go&#34;&gt;Cgo is not Go&lt;/a&gt;, but
when there are better libraries in C++ than Go, Cgo is a necessary evil.&lt;/p&gt;

&lt;p&gt;The problem is, Go CPU profiler doesn&amp;rsquo;t see beyond Cgo calls. Go memory profiler takes it one step
further. Forget about giving you memory usage breakdown in Cgo space, Go memory profiler fails to
even notice the presence of Cgo code. Any memory used by Cgo would not even make it to the memory
profiler. Other tools like Go race detector, don&amp;rsquo;t work either.&lt;/p&gt;

&lt;p&gt;Cgo has caused us &lt;code&gt;pthread_create&lt;/code&gt; issues in Go1.4, and then again in Go1.5, due to a bug
regression. Lightweight goroutines become expensive pthreads when Cgo is involved, and we had to
modify how we were writing data to RocksDB to avoid assigning too many goroutines.&lt;/p&gt;

&lt;p&gt;Cgo has caused us memory leaks. Who owns and manages memory when making calls is just not clear.
Go, and C are at the opposite spectrums. &lt;strong&gt;One doesn&amp;rsquo;t let you free memory, the other
requires it.&lt;/strong&gt; So, you make a Go call, but then forget to &lt;code&gt;Free()&lt;/code&gt;, and nothing breaks. &lt;em&gt;Except much later.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Cgo has given us a unmaintainable code. Cgo makes code ugly. The Cgo layer between RocksDB was the one piece of code no one in the team wanted to touch.&lt;/p&gt;

&lt;p&gt;Surely, we fixed the memory leaks in our API usage over time. In fact, I &lt;em&gt;think&lt;/em&gt; we have fixed them
all by now, but I can&amp;rsquo;t be sure. Go memory profiler would never tell you. And every time someone
complains about Dgraph taking up more memory or crashing due to OOM, it makes me nervous that this
is a memory leak issue.&lt;/p&gt;

&lt;h3 id=&#34;huge-undertaking&#34;&gt;Huge undertaking&lt;/h3&gt;

&lt;p&gt;Everyone I told about our woes with Cgo, told me that we should just work on fixing those issues.
Writing a key-value store which can provide the same performance as RocksDB is a huge undertaking, not
worth our effort. Even my team wasn&amp;rsquo;t sure. I had my doubts as well.&lt;/p&gt;

&lt;p&gt;I have great respect for any piece of technology which has been iterated upon by the smartest
engineers on the face of the planet for years. RocksDB is that. And if I was writing Dgraph in C++,
I&amp;rsquo;d happily use it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But, I just hate ugly code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I hate recurring bugs. No amount of effort would have ensured that we would no longer have any
more issues with using RocksDB via Cgo. I wanted a clean slate, and my profiler tools back. Building
a key-value store in Go from scratch was the only way to achieve it.&lt;/p&gt;

&lt;p&gt;I looked around. The existing key-value stores written in Go didn&amp;rsquo;t even come close to RocksDB&amp;rsquo;s
performance. And that&amp;rsquo;s a deal breaker. &lt;strong&gt;You don&amp;rsquo;t trade performance for cleanliness. You demand
both.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, I decided we will replace our dependency on RocksDB, but given this isn&amp;rsquo;t a priority for Dgraph,
none of the team members should work on it. This would be a side project that only I will
undertake. I started reading up about B+ and LSM trees, recent improvements to their design, and
came across WiscKey paper. It had great promising ideas. I decided to spend a month away from core
Dgraph, building &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;That&amp;rsquo;s not how it went.&lt;/em&gt; I couldn&amp;rsquo;t spend a month away from Dgraph. Between all the founder duties,
I couldn&amp;rsquo;t fully dedicate time to coding either.  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; developed during my spurts of coding
activity, and one of the team members&amp;rsquo; part-time contributions. Work started end January, and now I
think it&amp;rsquo;s in a good state to be trialed by the Go community.&lt;/p&gt;

&lt;h2 id=&#34;lsm-trees&#34;&gt;LSM trees&lt;/h2&gt;

&lt;p&gt;Before we delve into &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, let&amp;rsquo;s understand key-value store
designs. They play an important role in data-intensive applications including databases. Key-value
stores allow efficient updates, point lookups and range queries.&lt;/p&gt;

&lt;p&gt;There are two popular types of implementations: Log-structured merge (LSM) tree based, and B+ tree
based. The main advantage LSM trees have is that all the foreground writes happen in memory, and all
background writes maintain sequential access patterns. Thus they achieve a very high write
thoughput. On the other hand, small updates on B+-trees involve repeated random disk writes, and
hence are unable to maintain high throughput write workload&lt;sup&gt;1&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;To deliver high write performance, LSM-trees batch key-value pairs and write them sequentially.
Then, to enable efficient lookups, LSM-trees continuously read, sort and write key-value pairs in
the background. This is known as a &lt;code&gt;compaction&lt;/code&gt;. LSM-trees do this over many levels, each level
holding a factor more data than the previous, typically &lt;code&gt;size of Li+1 = 10 x size of Li&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Within a single
level, the key-values get written into files of fixed size, in a sorted order. Except level zero,
all other levels have zero overlaps between keys stored in files at the same level.&lt;/p&gt;

&lt;p&gt;Each level has a maximum capacity. As a level &lt;code&gt;Li&lt;/code&gt; fills up, its data gets merged with data from
lower level &lt;code&gt;Li+1&lt;/code&gt; and files in &lt;code&gt;Li&lt;/code&gt; deleted to make space for more incoming data. As data flows
from level zero to level one, two, and so on, the same data is re-written multiple times throughout
its lifetime. Each key update causes many writes until data eventually settles.
This constitutes &lt;em&gt;write amplification&lt;/em&gt;. For a 7 level LSM tree, with 10x size increase factor, this
can be 60; 10 for each transition from L1-&amp;gt;L2, L2-&amp;gt;L3, and so on, ignoring L0 due to special
handling.&lt;/p&gt;

&lt;p&gt;Conversely, to read a key from LSM tree, all the levels need to be checked. If present in multiple
levels, the version of key at level closer to zero is picked (this version is more up to date).
Thus, a single key lookup causes many reads over files, this constitutes &lt;em&gt;read amplification&lt;/em&gt;. WiscKey
paper estimates this to be 336 for a 1-KB key-value pair.&lt;/p&gt;

&lt;p&gt;LSMs were designed around hard drives. In HDDs, random I/Os are over 100x slower than sequential
ones. Thus, running compactions to continually sort keys and enable efficient lookups is an
excellent trade-off.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/nvme-ssd-960pro.jpg&#34; alt=&#34;NVMe SSD Samsung 960 pro&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, SSDs are fundamentally different from HDDs. The difference between their sequential and
random reads are not nearly as large as HDDs. In fact, top of the line SSDs like &lt;a href=&#34;http://www.anandtech.com/show/10754/samsung-960-pro-ssd-review&#34;&gt;Samsung 960
Pro&lt;/a&gt; can provide 440K random read
operations per second, with 4KB block size. Thus, an LSM-tree that performs a large number of
sequential writes to reduce later random reads is wasting bandwidth needlessly.&lt;/p&gt;

&lt;h2 id=&#34;badger&#34;&gt;Badger&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is a simple, efficient, and persistent key-value store.&lt;/strong&gt;  Inspired by the simplicity of
LevelDB, it provides &lt;code&gt;Get&lt;/code&gt;, &lt;code&gt;Set&lt;/code&gt;, &lt;code&gt;Delete&lt;/code&gt;, and &lt;code&gt;Iterate&lt;/code&gt; functions. On top of it, it adds
&lt;code&gt;CompareAndSet&lt;/code&gt; and &lt;code&gt;CompareAndDelete&lt;/code&gt; atomic operations (&lt;a href=&#34;https://godoc.org/github.com/dgraph-io/badger&#34;&gt;see GoDoc&lt;/a&gt;). It does not aim to be a database and hence
does not provide transactions, versioning or snapshots.  Those things can be easily built on top of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; separates keys from values. The keys are stored in LSM tree, while the values are stored in a
write-ahead log called the &lt;em&gt;value log&lt;/em&gt;. Keys tend to be smaller than values. Thus this set up produces
much smaller LSM trees. When required, the values are directly read from the log stored on SSD,
utilizing its vastly superior random read performance.&lt;/p&gt;

&lt;h3 id=&#34;guiding-principles&#34;&gt;Guiding principles&lt;/h3&gt;

&lt;p&gt;These are the guiding principles that decide the design, what goes in and what doesn&amp;rsquo;t in Badger.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write it purely in Go language.&lt;/li&gt;
&lt;li&gt;Use the latest research to build the fastest key-value store.&lt;/li&gt;
&lt;li&gt;Keep it simple, stupid.&lt;/li&gt;
&lt;li&gt;SSD-centric design.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;key-value-separation&#34;&gt;Key-Value separation&lt;/h3&gt;

&lt;p&gt;The major performance cost of LSM-trees is the compaction process. During compactions, multiple
files are read into memory, sorted, and written back. Sorting is essential for efficient retrieval,
for both key lookups and range iterations. With sorting, the key lookups would only require accessing at most one file per level (excluding level zero, where we&amp;rsquo;d need to check all the files).
Iterations would result in sequential access to multiple files.&lt;/p&gt;

&lt;p&gt;Each file is of fixed size, to enhance caching. Values tend to be larger than keys. When you store
values along with the keys, the amount of data that needs to be compacted grows significantly.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, only a pointer to the value in the value log is stored alongside the key. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; employs
&lt;em&gt;delta encoding&lt;/em&gt; for keys to reduce the effective size even further. Assuming 16 bytes per key
and 16 bytes per value pointer, &lt;strong&gt;a single 64MB file can store two million key-value pairs.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;write-amplification&#34;&gt;Write Amplification&lt;/h3&gt;

&lt;p&gt;Thus, the LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller than
that of RocksDB. This smaller LSM-tree reduces the number of levels, and hence number of compactions
required to achieve stability. Also, values are not moved along with keys, because they&amp;rsquo;re elsewhere
in value log. Assuming 1KB value and 16 byte keys, the effective write amplification per level is &lt;code&gt;(10*16 +
1024)/(16 + 1024) ~ 1.14&lt;/code&gt;, a much smaller fraction.&lt;/p&gt;

&lt;p&gt;You can see the performance gains of this approach compared to RocksDB as the value size increases;
where loading data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; takes factors less time (see Benchmarks below).&lt;/p&gt;

&lt;h3 id=&#34;read-amplification&#34;&gt;Read Amplification&lt;/h3&gt;

&lt;p&gt;As mentioned above, the size of LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller. Each file at each
level stores lots more keys than typical LSM trees. Thus, for the same amount of data, fewer levels
get filled up. A typical key lookup requires reading all files in level zero, and one file per level
from level one and onwards. With &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, filling fewer levels means, fewer files need to be read to
lookup a key. Once key (along with value pointer) is fetched, the value can be fetched by doing
random read in value log stored on SSD.&lt;/p&gt;

&lt;p&gt;Furthermore, during benchmarking, we found that &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree is so small, it can easily fit in RAM. For 1KB values and 75 million 22 byte keys, the raw size
of the entire dataset is 72 GB. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree size for
this setup is a mere 1.7G, which can easily fit into RAM.  This is what causes
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s random key lookup performance to be at least 3.5x
faster, and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration to be blazingly
faster than RocksDB.&lt;/p&gt;

&lt;h3 id=&#34;crash-resilience&#34;&gt;Crash resilience&lt;/h3&gt;

&lt;p&gt;LSM trees write all the updates in memory first in memtables. Once they fill up, memtables get
swapped over to immutable memtables, which eventually get written out to files in level zero on
disk.&lt;/p&gt;

&lt;p&gt;In the case of a crash, all the recent updates still in memory tables would be lost.
Key-value stores deal with this issue, by first writing all the updates in a write-ahead log. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;
has a write-ahead log, it&amp;rsquo;s called value log.&lt;/p&gt;

&lt;p&gt;Just like a typical write-ahead log, before any update is applied to LSM tree, it gets written to
value log first. In the case of a crash, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; would iterate over the recent updates in value log, and
apply them back to the LSM tree.&lt;/p&gt;

&lt;p&gt;Instead of iterating over the entire value log, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; puts a pointer to the latest value in each
memtable. Effectively, the latest memtable which made its way to disk would have a value pointer,
before which all the updates have already made their way to disk. Thus, we can replay from this
pointer onwards, and reapply all the updates to LSM tree to get all our updates back.&lt;/p&gt;

&lt;h3 id=&#34;overall-size&#34;&gt;Overall size&lt;/h3&gt;

&lt;p&gt;RocksDB applies block compression to reduce the size of LSM tree. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is much smaller in
comparison and can be stored in RAM entirely, so it doesn&amp;rsquo;t need to do any compression on the tree. However,
the size of value log can grow quite quickly.  Each update is a new entry in the value log, and
therefore multiple updates for the same key take up space multiple times.&lt;/p&gt;

&lt;p&gt;To deal with this, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; does two things. It allows compressing values in value log. Instead of
compressing multiple key-values together, we only compress each key-value individually. This
provides the best possible random read performance. The client can set it so compression is
only done if the key-value size is over an adjustable threshold, set by default to 1KB.&lt;/p&gt;

&lt;p&gt;Secondly, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; runs value garbage collection. This runs periodically and samples a 100MB size of a
randomly selected value log file. It checks if at least a significant chunk of it should be
discarded, due to newer updates in later logs. If so, the valid key-value pairs would be appended to
the log, the older file discarded, and the value pointers updated in the LSM tree. The downside is,
this adds more work for LSM tree; so shouldn&amp;rsquo;t be run when loading a huge data set. More work is
required to only trigger this garbage collection to run during periods of little client
activity.&lt;/p&gt;

&lt;h3 id=&#34;hardware-costs&#34;&gt;Hardware Costs&lt;/h3&gt;

&lt;p&gt;But, given the fact that SSDs are getting cheaper and cheaper, using extra space in SSD is
almost nothing compared to having to store and serve a major chunk of LSM tree from memory. Consider this:&lt;/p&gt;

&lt;p&gt;For 1KB values, 75 million 16 byte keys, RocksDB&amp;rsquo;s LSM tree is 50GB in size. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s value log is
74GB (without value compression), and LSM tree is 1.7GB. Extrapolating it three times, we get 225 million
keys, RocksDB size of 150GB and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; size of 222GB value log, and 5.1GB LSM tree.&lt;/p&gt;

&lt;p&gt;Using Amazon AWS US East (Ohio) datacenter:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To achieve a random read performance equivalent of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (at least 3.5x faster), RocksDB would need to
be run on an &lt;code&gt;r3.4xlarge&lt;/code&gt; instance, which provides 122 GB of RAM for &lt;code&gt;$1.33&lt;/code&gt; per hour; so most of its
LSM tree can fit into memory.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be run on the cheapest storage optimized instance &lt;code&gt;i3.large&lt;/code&gt;, which provides 475GB NVMe SSD
(&lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; test: 100K IOPS for 4KB block size), with 15.25GB RAM for &lt;code&gt;$0.156&lt;/code&gt; per hour.&lt;/li&gt;
&lt;li&gt;The cost of running &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is thus, &lt;strong&gt;8.5x cheaper&lt;/strong&gt; than running RocksDB on EC2, on-demand.&lt;/li&gt;
&lt;li&gt;Going 1-year term all upfront payment, this is $6182 for RocksDB v/s $870 for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, still 7.1x
cheaper. &lt;strong&gt;That&amp;rsquo;s a whopping 86% saving.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;We rented a storage optimized &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/&#34;&gt;i3.large
instance&lt;/a&gt; from Amazon AWS, which provides 450GB NVMe
SSD storage, 2 virtual cores along with 15.25GB RAM. This instance provides local SSD, which we
tested via &lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; to sustain close to 100K random read IOPS for 4KB
block sizes.&lt;/p&gt;

&lt;p&gt;The data sets were chosen to generate sizes too big to fit entirely in RAM, in either RocksDB
or &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Value size&lt;/th&gt;
&lt;th&gt;Number of keys (each key = 22B)&lt;/th&gt;
&lt;th&gt;Raw data size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;128B&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;td&gt;35GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1024B&lt;/td&gt;
&lt;td&gt;75M&lt;/td&gt;
&lt;td&gt;73GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16KB&lt;/td&gt;
&lt;td&gt;5M&lt;/td&gt;
&lt;td&gt;76GB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We then loaded data one by one, first in RocksDB then in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, never running the loaders
concurrently. This gave us the data loading times and output sizes. For random &lt;code&gt;Get&lt;/code&gt; and &lt;code&gt;Iterate&lt;/code&gt;,
we used Go benchmark tests and ran them for 3 minutes, going down to 1 minute for 16KB values.&lt;/p&gt;

&lt;p&gt;All the code for benchmarking is available &lt;a href=&#34;https://github.com/dgraph-io/badger-bench&#34;&gt;in this
repo&lt;/a&gt;. All the commands ran and
their measurements recorded are available in &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/blob/master/BENCH-rocks.txt&#34;&gt;this log
file&lt;/a&gt;. The
charts and their data is &lt;a href=&#34;https://docs.google.com/a/dgraph.io/spreadsheets/d/1x8LUw_85g8Jo9jFtbAwuXrLm_DB1SOG8QCTSjXj8Hk0/edit?usp=sharing&#34;&gt;viewable
here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;In the following benchmarks, we measured 4 things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data loading performance&lt;/li&gt;
&lt;li&gt;Output size&lt;/li&gt;
&lt;li&gt;Random key lookup performance (&lt;code&gt;Get&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Sorted range iteration performance (&lt;code&gt;Iterate&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the 4 measurements are visualized in the following charts.
&lt;img src=&#34;https://blog.dgraph.io/images/badger-benchmarks.png&#34; alt=&#34;[Badger](https://github.com/dgraph-io/badger) benchmarks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data loading performance:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-value separation design shows huge performance gains as
value sizes increase. For value sizes of 1KB and 16KB, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; achieves 4.5x and 11.7x more
throughput than RocksDB. For smaller values, like 16 bytes not shown here, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be 2-3x
slower, due to slower compactions (see further work).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Store size:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; generates much smaller LSM tree, but a larger value size log. The size of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is proportional only to the number of keys, not values. Thus, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree decreases in size as we progress from 128B to 16KB. In all three scenarios, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; produced an
LSM tree which could fit entirely in RAM of the target server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Random read latency:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt; latency is only 18% to 27% of RocksDB&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt;
latency. &lt;strong&gt;In our opinion, this is the biggest win of this design.&lt;/strong&gt; This happens because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s
entire LSM tree can fit into RAM, significantly decreasing the amount of time it takes to find the
right tables, check their bloom filters, pick the right blocks and retrieve the key. Value retrieval is then
a single SSD &lt;code&gt;file.pread&lt;/code&gt; away.&lt;/p&gt;

&lt;p&gt;In contrast, RocksDB can&amp;rsquo;t fit the entire tree in memory. Even assuming it can keep the table index
and bloom filters in memory, it would need to fetch the entire blocks from disk, decompress them,
then do key-value retrieval (&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s smaller LSM tree avoids
the need for compression). This obviously takes longer, and given lack of data access locality,
caching isn&amp;rsquo;t as effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Range iteration latency:&lt;/strong&gt;  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s range iteration is
significantly slower than RocksDB&amp;rsquo;s range iteration, when values are also retrieved from SSD. &lt;em&gt;We
didn&amp;rsquo;t expect this, and still don&amp;rsquo;t quite understand it.&lt;/em&gt; We expected some slowdown due to the need
to do IOPS on SSD, while RocksDB does purely serial reads. But, given the 100K IOPS &lt;code&gt;i3.large&lt;/code&gt;
instance is capable of, we didn&amp;rsquo;t even come close to using that bandwidth, despite pre-fetching.
This needs further work and investigation.&lt;/p&gt;

&lt;p&gt;On the other end of the spectrum, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration is blazingly faster than RocksDB or key-value
iteration (latency is shown by the almost invisible red bar). This is quite useful in certain use
cases we have at Dgraph, where we iterate over the keys, run filters and only retrieve values for a
much smaller subset of keys.&lt;/p&gt;

&lt;h2 id=&#34;further-work&#34;&gt;Further work&lt;/h2&gt;

&lt;h3 id=&#34;speed-of-range-iteration&#34;&gt;Speed of range iteration&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can do key-only iteration blazingly fast, things slow down when it
also needs to do value lookups. Theoretically, this shouldn&amp;rsquo;t be the case. Amazon&amp;rsquo;s i3.large disk
optimized instance can do 100,000 4KB block random reads per second. Based on this, we should be
able to iterate 100K key-value pairs per second, in other terms six million key-value pairs per minute.&lt;/p&gt;

&lt;p&gt;However, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s current implementation doesn&amp;rsquo;t produce SSD
random read requests even close to this limit, and the key-value iteration suffers as a result.
There&amp;rsquo;s a lot of room for optimization in this space.&lt;/p&gt;

&lt;h3 id=&#34;speed-of-compactions&#34;&gt;Speed of compactions&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower when it comes to running
compactions compared to RocksDB. Due to this, for a dataset purely containing smaller values, it is
slower to load data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. This needs more optimization.&lt;/p&gt;

&lt;h3 id=&#34;lsm-tree-compression&#34;&gt;LSM tree compression&lt;/h3&gt;

&lt;p&gt;Again in a dataset purely containing smaller values, the size of LSM tree would be significantly
larger than RocksDB because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; doesn&amp;rsquo;t run compression on LSM tree. This should be easy to add
on if needed, and would make a great first-time contributor project.&lt;/p&gt;

&lt;h3 id=&#34;b-tree-approach&#34;&gt;B+ tree approach&lt;/h3&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Recent improvements to SSDs might make B+-trees a viable option.
Since WiscKey paper was written, SSDs have made huge gains in random write performance. A new
interesting direction would be to combine the value log approach, and keep only keys and value
pointers in the B+-tree. This would trade LSM tree read-sort-merge sequential write compactions with
many random writes per key update and might achieve the same write throughput as LSM for a much
simpler design.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have built an efficient key-value store, which can compete in performance against top of the line
key-value stores in market. It is currently rough around the edges, but provides a solid platform
for any industrial application, be it data storage or building another database.&lt;/p&gt;

&lt;p&gt;We will be replacing Dgraph&amp;rsquo;s dependency on RocksDB soon with
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;; making our builds easier, faster, making Dgraph
cross-platform and paving the way for embeddable Dgraph. The biggest win of using
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is &lt;strong&gt;a performant Go native key-value store.&lt;/strong&gt; The
nice side-effects are &lt;strong&gt;~4 times faster &lt;code&gt;Get&lt;/code&gt; and a potential 86% reduction in AWS bills,&lt;/strong&gt; due to
less reliance on RAM and more reliance on ever faster and cheaper SSDs.&lt;/p&gt;

&lt;p&gt;So try out &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; in your project, and let us know your experience.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. Special thanks to &lt;a href=&#34;https://research.google.com/pubs/SanjayGhemawat.html&#34;&gt;Sanjay Ghemawat&lt;/a&gt; and
&lt;a href=&#34;http://pages.cs.wisc.edu/~ll/&#34;&gt;Lanyue Lu&lt;/a&gt; for responding to my questions about design choices.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: Juno spacecraft is the &lt;a href=&#34;http://www.livescience.com/32655-whats-the-fastest-spacecraft-ever.html&#34;&gt;fastest moving human made
object&lt;/a&gt;, traveling at a
speed of 265,00 kmph relative to Earth.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>