<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dgraph Blog</title>
    <link>https://open.dgraph.io/post/</link>
    <description>Recent content in Posts on Dgraph Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2016, Dgraph Labs, Inc. All rights reserved.</copyright>
    <lastBuildDate>Mon, 23 Jan 2017 18:07:44 +1100</lastBuildDate>
    <atom:link href="https://open.dgraph.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Neo4j vs Dgraph - The numbers speak for themselves</title>
      <link>https://open.dgraph.io/post/benchmark-neo4j/</link>
      <pubDate>Mon, 23 Jan 2017 18:07:44 +1100</pubDate>
      
      <guid>https://open.dgraph.io/post/benchmark-neo4j/</guid>
      <description>

&lt;p&gt;As &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is nearing its v0.8 release, we wanted to spend some time comparing it against Neo4j, which is the &lt;a href=&#34;http://db-engines.com/en/ranking/graph+dbms&#34;&gt;most popular graph database&lt;/a&gt;. We have divided this post into five parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Loading data&lt;/li&gt;
&lt;li&gt;Querying&lt;/li&gt;
&lt;li&gt;Issues faced&lt;/li&gt;
&lt;li&gt;Features&lt;/li&gt;
&lt;li&gt;Principles behind Dgraph&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;set-up&#34;&gt;Set up&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Thinkpad T460 laptop running Ubuntu Linux, Intel Core i7, with 16 GB RAM and SSD storage.&lt;/li&gt;
&lt;li&gt;Neo4j v3.1.0&lt;/li&gt;
&lt;li&gt;Dgraph from master branch (commit: 100c104a)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-loading-data&#34;&gt;1. Loading Data&lt;/h3&gt;

&lt;p&gt;We wanted to load a dense graph data set involving real world data. We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 have been using the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/21million.rdf.gz&#34;&gt;Freebase film data&lt;/a&gt; for our development and testing. We feel this data is highly interconnected and makes a good use case for storing in a graph database.&lt;/p&gt;

&lt;p&gt;The first problem we faced was that Neo4j doesn&amp;rsquo;t accept data in RDF format directly &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#1&#34;&gt;3.1&lt;/a&gt;
&lt;/sup&gt;
. The &lt;a href=&#34;https://neo4j.com/developer/guide-import-csv/#_super_fast_batch_importer_for_huge_datasets&#34;&gt;loader&lt;/a&gt; for Neo4j accepts data in CSV format which is essentially what SQL tables have. In our 21 million dataset, we have 50 distinct types of entities and 132 types of relationships between these entities. If we were to try and convert it to CSV format, we would end up with 100s of CSV files. One file for each type of entity, and one file per relationship between two types of entities. While this is okay for relational data, this doesn&amp;rsquo;t work for graph data sets, where each entity can be of multiple types, and relationships between entities are fluid.&lt;/p&gt;

&lt;p&gt;So, we looked into the next best option to load graph data into Neo4j. We wrote a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;small program&lt;/a&gt; similar to the Dgraphloader which reads N-Quads, batches them and tries to load them concurrently into Neo4j. This program used &lt;a href=&#34;https://neo4j.com/blog/neo4j-3-0-milestone-1-release/&#34;&gt;Bolt&lt;/a&gt;, a new protocol by Neo4j. It is the fastest way we could find to load RDF data into Neo4j. In the video below, you can see a comparison of loading 1.1 million N-Quads on &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 vs. Neo4j.&lt;/p&gt;

&lt;p&gt;Note that we only used 20 concurrent connections and batched 200 N-Quads for each request because Neo4j doesn&amp;rsquo;t work well if we increase either the number of connections or N-Quads per connection beyond this. In fact, that&amp;rsquo;s a sure way to make Neo4j data corrupt and hang the system &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#2&#34;&gt;3.2&lt;/a&gt;
&lt;/sup&gt;
. For Dgraph, we typically send 1000 N-Quads per request and have 500 concurrent connections.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/S_DsEMnawwU?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;With the golden data set of 1.1 million N-Quads, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 outperformed Neo4j 46.7k to 280 N-Quads per second. In fact, the Neo4j loader process &lt;em&gt;never finished&lt;/em&gt; (we killed it after a considerable wait).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is 160x faster than Neo4j for loading graph data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;2-querying&#34;&gt;2. Querying&lt;/h3&gt;

&lt;p&gt;We would have ideally liked to load up the entire 21 million RDF dataset so that we could compare the performance of both databases at scale. But given the difficulties we faced loading large amounts of data into Neo4j, we resorted to a subset dataset of 1.3 million N-Quads containing only certain types of entities and relationships. After a &lt;em&gt;painful&lt;/em&gt; process, we converted our data into &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data/neo4j&#34;&gt;five CSV files&lt;/a&gt;, one for each type of entity (film, director, and genre) and two for the relationships between them; so that we could do some queries. We loaded these files into Neo4j using their import tool.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./neo4j start
./neo4j-admin import --database film.db --id-type string --nodes:Film $DATA/films.csv --nodes:Genre $DATA/genres.csv --nodes:Director $DATA/directors.csv --relationships:GENRE $DATA/filmgenre.csv --relationships:FILMS $DATA/directorfilm.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we created some indexes in Neo4j for the best query performance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE INDEX ON :Director(directorId)
CREATE INDEX ON :Director(name)
CREATE INDEX ON :Film(release_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We tested Neo4j twice. Once with query caching turned off, and then with query caching turned on. &lt;strong&gt;Generally, it does not make sense to benchmark queries with caching turned on, but we decided to set it because that&amp;rsquo;s the default behavior Neo4j users see.&lt;/strong&gt; You can set it by modifying the following variable in &lt;code&gt;conf/neo4j.conf&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dbms.query_cache_size=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dgraph does not do any query caching. We loaded an equivalent &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/neo.rdf.gz&#34;&gt;data set&lt;/a&gt; into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 using the following schema and the commands below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
    type.object.name.en: string @index
    film.film.initial_release_date: date @index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The schema file specifies creation of an index on the two predicates.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Start Dgraph with a schema which specifies the predicates to index.
dgraph --schema ~/work/src/github.com/dgraph-io/benchmarks/data/goldendata.schema
# Load the data
dgraphloader -r ~/work/src/github.com/dgraph-io/benchmarks/data/neo4j/neo.rdf.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With data loaded up into both the databases, we &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmarked&lt;/a&gt; both simple and complex queries. The results didn&amp;rsquo;t surprise us.&lt;/p&gt;

&lt;h4 id=&#34;benchmarking-process&#34;&gt;Benchmarking process&lt;/h4&gt;

&lt;p&gt;The benchmarks for Neo4j and &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 were run separately so that both processes could utilize full CPU and RAM resources. Each sub-benchmark was run for 10s so that sufficient iterations could be run. We also monitored the memory usage for both the processes using a simple shell script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go test -v -bench=Dgraph -benchtime=10s .
go test -v -bench=Neo -benchtime=10s .
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Id&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQ&lt;/td&gt;
&lt;td&gt;Get all films and genres of &lt;strong&gt;films directed by Steven Spielberg.&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQM&lt;/td&gt;
&lt;td&gt;Runs the query above and changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and get &lt;strong&gt;their films sorted by release date&lt;/strong&gt;.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their films &lt;strong&gt;released after 1984-08&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their movies &lt;strong&gt;released between 1984-08 and 2000&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If the test id has a &lt;code&gt;P&lt;/code&gt; suffix, it was run in parallel.&lt;/p&gt;

&lt;h4 id=&#34;read-only-benchmarks&#34;&gt;Read-only benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Queries to Dgraph took the same amount of time, as expected in the both cases. But, Neo4j query latency was at least &lt;em&gt;halved&lt;/em&gt;. That&amp;rsquo;s not surprising given all the subsequent runs were using query cache. &lt;strong&gt;Thence, Neo4j latency was better than Dgraph with query caching turned on, and worse when off.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;read-write-benchmarks&#34;&gt;Read-write benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-write-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-write-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For intertwined reads and writes, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is at least 3x to 6x faster.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can see that Neo4j is &lt;strong&gt;even slower with query caching on&lt;/strong&gt; because they have to do the extra work of cache invalidation on writes. Dgraph was designed to achieve low latency querying with real world use cases, where reads are typically followed by writes and vice-versa, and the &lt;strong&gt;performance benefits show in the numbers.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not just that, Neo4j takes up &lt;strong&gt;much more memory&lt;/strong&gt;. At the start of the benchmarks &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumed around 20 MB which increased to 600 MB at the end. In comparison, Neo4j was already consuming 550 MB at the start which increased to 3.2 GB at the end of the benchmarks.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumes 5x lesser memory compared to Neo4j and is at least 3x faster for intertwined reads and writes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-issues-faced&#34;&gt;3. Issues faced&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;div id=&#34;1&#34;&gt;&lt;/div&gt;We couldn&amp;rsquo;t find a convenient way to load large amount of interconnected graph data into Neo4j apart from breaking it into CSV files. We had to write a loader which could concurrently load RDF data into Neo4j.&lt;/li&gt;
&lt;li&gt;&lt;div id=&#34;2&#34;&gt;&lt;/div&gt;We hit data corruption issues on sending more than 20 requests concurrently, which the database could not recover from. In comparison, we typically send 500 concurrent requests to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, each request batching 1000 N-Quads.&lt;/li&gt;
&lt;li&gt;While loading data concurrently and opening 100 connections, Neo4j started returning bad connection error because it hit the limit of maximum open file descriptors which was set to 1024 (the default). We have never witnessed such a problem with Dgraph.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-features&#34;&gt;4. Features&lt;/h3&gt;

&lt;p&gt;We talked about performance and issues. Now, let&amp;rsquo;s see how does Dgraph compare against Neo4j regarding features.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;th&gt;Neo4j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Production Features&lt;/td&gt;
&lt;td&gt;Highly available, Consistent, Fault tolerant&lt;/td&gt;
&lt;td&gt;Master-slave architecture (only full data replicas)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data Sharding&lt;/td&gt;
&lt;td&gt;Yes. Data sharded and replicated across servers, using consensus for writes.&lt;/td&gt;
&lt;td&gt;No data sharding.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Horizontal Scalability&lt;/td&gt;
&lt;td&gt;Yes. Add servers to cluster on the fly to distribute data better.&lt;/td&gt;
&lt;td&gt;Supports only full data replicas&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transactional Model&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.bailis.org/blog/linearizability-versus-serializability/&#34;&gt;Linearizability&lt;/a&gt; aka Atomic Consistency&lt;/td&gt;
&lt;td&gt;ACID transactions&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Backups&lt;/td&gt;
&lt;td&gt;Hot backups in RDF format available using the HTTP interface&lt;/td&gt;
&lt;td&gt;Hot full and incremental backups available only as part of paid enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;HTTP API for queries and mutations&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communication using clients over binary protocol&lt;/td&gt;
&lt;td&gt;Yes, using grpc&lt;/td&gt;
&lt;td&gt;Yes, using bolt protocol&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Bulk loading of graph data&lt;/td&gt;
&lt;td&gt;Yes, can load arbitrarily connected RDF data using dgraphloader&lt;/td&gt;
&lt;td&gt;Only supports loading relational data in CSV format using the loader&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Schema&lt;/td&gt;
&lt;td&gt;Optional (supports int, float, string, bool, date, datetime and geo types)&lt;/td&gt;
&lt;td&gt;Optional (supports byte, short, int, long, float, double, char and string types)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Geospatial Queries&lt;/td&gt;
&lt;td&gt;Yes. Supports near, within, contains, intersects&lt;/td&gt;
&lt;td&gt;No. Not part of core database&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Query language&lt;/td&gt;
&lt;td&gt;GraphQL like which responds in JSON&lt;/td&gt;
&lt;td&gt;Cypher&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Order by, limit, skip and filter queries&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Authorization and authentication&lt;/td&gt;
&lt;td&gt;SSL/TLS and auth token based security (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports basic user authentication and authorization&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Aggregation queries&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports count(), sum(), avg(), distinct and other aggregation queries&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Access Control Lists&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Available based on roles as part of enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Support for plugins and user defined functions&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Browser interface for visualization&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Dgraph (2016) is a lot younger project than Neo4j (2007), so reaching feature parity quickly was a tough job.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Dgraph supports most of the functionality that one &lt;em&gt;needs&lt;/em&gt; to get the job done; though it doesn&amp;rsquo;t have all the functionality one might &lt;em&gt;want&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;5-principles-behind-dgraph&#34;&gt;5. Principles behind Dgraph&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 runs very well on our (Linux) Thinkpads, it is designed to be a graph database for production. As such, it allows the ability to shard and distribute data over many servers. Consistency and fault tolerance are baked deep into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to the point where even our tests need to start a &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query_test.go#L2715&#34;&gt;single-node Raft cluster&lt;/a&gt;. All the writes, irrespective of which replica they end up on, can be read back instantaneously, i.e. linearizable (work in progress, ETA v0.8). A few server crashes would not lose data or affect the end-user queries, making the system highly-available.&lt;/p&gt;

&lt;p&gt;Such features have traditionally been a talk for NoSQL databases or Spanner, not for graph databases. But, we think any production system, on which the entire application stack is based, &lt;strong&gt;must stay up, perform and scale well.&lt;/strong&gt; The system must be able to utilize the server running it well, process a lot of queries per second, and provide a consistent latency.&lt;/p&gt;

&lt;p&gt;Also, given we&amp;rsquo;re building a graph database, the system should be able to handle &lt;strong&gt;arbitrarily dense interconnected data and complex queries.&lt;/strong&gt; It should not be confined by pre-optimization of certain edges, or other tricks to make certain queries run fast.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The speed achieved should be due to a better design and across the entire spectrum.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, running and maintaining such a system should be easy to the engineers. And that&amp;rsquo;s only possible if the system is &lt;strong&gt;as simple as it can be,&lt;/strong&gt; and every piece of complexity introduced to the system is carefully weighted.&lt;/p&gt;

&lt;p&gt;These are the principles which guide us towards building Dgraph. And we&amp;rsquo;re glad that in a short period, we&amp;rsquo;ve been able to achieve many of these. Now we leave it to you, our users to &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;try out Dgraph&lt;/a&gt;, and let us know what you think.&lt;/p&gt;

&lt;hr /&gt;

&lt;h5 id=&#34;criticism-to-these-benchmarks-updated-feb-1-2017&#34;&gt;Criticism to these benchmarks (Updated Feb 1, 2017)&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;This reads like marketing material:&lt;/strong&gt; &lt;em&gt;You&amp;rsquo;re on Dgraph blog!&lt;/em&gt; Having said that, the benchmarking code is &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;open source&lt;/a&gt; and available to any one willing to put some time to verify these benchmarks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Query caching was turned off:&lt;/strong&gt; The benchmarks above showcase results for Neo4j with &lt;em&gt;both caching turned on and off.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j only uses query plan cache, not result cache:&lt;/strong&gt; That&amp;rsquo;s not what we observed. In fact, for the same read-write query, Neo4j latency increased when caching was turned on, compared to when off (as you can see in the read-write benchmarks above). A pure query plan cache shouldn&amp;rsquo;t be affected by data changes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JVM takes time to warm up:&lt;/strong&gt; Each benchmark was run for 10 seconds by Go, which ran thousands of iterations for the same query to get accurate latency per iteration. We think the JVM should be able to warm up by then.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j queries could be optimized:&lt;/strong&gt; Just mentioning it doesn&amp;rsquo;t help. Please send us a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;pull request&lt;/a&gt; to optimize Neo4j data loading and queries. Or, &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;send us&lt;/a&gt; a mail.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Benchmarking on a laptop isn&amp;rsquo;t right:&lt;/strong&gt; We are just looking for relative performance, not absolute performance. It shouldn&amp;rsquo;t matter which machine you run them on.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Manish will be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Gophercon India on 24-25th Feb. If you&amp;rsquo;re attending the conference, find him to talk about all things Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are happy to &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;accept feedback&lt;/a&gt; about any improvements to the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;loader&lt;/a&gt; or the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmark tests&lt;/a&gt; to get better results for Neo4j.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you haven&amp;rsquo;t already tried &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/goddard/2016/hubble-gazes-at-a-cosmic-megamaser&#34;&gt;Hubble Gazes at a Cosmic Megamaser&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Releasing Dgraph v0.7.1</title>
      <link>https://open.dgraph.io/post/v0.7-release/</link>
      <pubDate>Thu, 05 Jan 2017 20:00:00 +1100</pubDate>
      
      <guid>https://open.dgraph.io/post/v0.7-release/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 team is super excited to present v0.7.1 of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
. This version is the biggest step we&amp;rsquo;ve taken towards our production aim of v1.0.
We&amp;rsquo;ve implemented &lt;strong&gt;90% of all the features we had planned&lt;/strong&gt; in our &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/1&#34;&gt;product roadmap&lt;/a&gt;, including replication and high-availability using RAFT protocol, indexing, filtering, sorting, geospatial queries, and backups.&lt;/p&gt;

&lt;p&gt;Today, I&amp;rsquo;m going to talk about these new features, and what you can expect from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note: This is going to be a long blog post. If you just want to try out &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, you can jump straight to our &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 v0.7.1 is the &lt;em&gt;fastest&lt;/em&gt; version of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 we&amp;rsquo;ve ever released. Live data loading is now so fast that we realized we no longer needed a separate offline batch data loader. So, we removed all that complexity and just wrote a simple script to send mutation queries to live &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 via GRPC.&lt;/p&gt;

&lt;p&gt;You can read more about loading and querying performance &lt;a href=&#34;https://wiki.dgraph.io/Performance&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;data-persistence-sharding-high-availability-and-crash-resilience&#34;&gt;Data Persistence, Sharding, High Availability, and Crash Resilience&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 has been built from ground up to be run in Google scale production environments. To run terabytes of structured data over commodity hardware has been the main aim since the beginning. To achieve that, Dgraph needs to be able to deal with server failures; without losing any data or dropping any queries.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve implemented RAFT, a distributed consensus algorithm within &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to handle such failures. Any writes that happen to go through a group of servers and are only acknowledged to the client once they&amp;rsquo;ve been applied to a majority of servers in the group. Thus, even if some of these servers crash, the data can be accessed, updated and queries can flow without the user getting affected.&lt;/p&gt;

&lt;p&gt;Also, new servers can be introduced into an existing cluster by providing the IP address of any healthy server in the cluster. They will automatically pick up the other members, pull in data shards from healthy nodes, join the groups and become part of the cluster.&lt;/p&gt;

&lt;p&gt;Such functionality has never been an aim for graph databases in the past. But we strongly believe that graph databases can be run as the primary databases; not just add-ons. To that effect, it&amp;rsquo;s important that they be able to survive machine crashes and avoid data loss.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This functionality makes &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 the most production ready graph database in the market.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can read more about running multiple instances of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, sharding and distributing data in a cluster &lt;a href=&#34;https://wiki.dgraph.io/Deploy&#34;&gt;here&lt;/a&gt;. In fact, we created a small video to show you how &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can recover from crashes without losing any data directly after a load.
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/dzTEXxF0TGs?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;h3 id=&#34;backups&#34;&gt;Backups&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 believes in standards. We heartily use the existing RDF NQuad standard for data input. Now, we&amp;rsquo;re making it easy to export data from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 to other systems, by exporting our backups in RDF NQuad format. This makes it easy to feed &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 data into other systems, upgrade &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 versions or to switch over to another graph database. You can read more about backup &lt;a href=&#34;https://wik.dgraph.io/Deploy#Backup&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;indexing&#34;&gt;Indexing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can now index various scalar values to allow sorting,  term matching, and inequality filters. We support these value types: &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;date&lt;/code&gt;, &lt;code&gt;datetime&lt;/code&gt;, &lt;code&gt;geo&lt;/code&gt;, &lt;code&gt;uid&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;String values get tokenized using ICU, and allow &lt;code&gt;allof&lt;/code&gt; and &lt;code&gt;anyof&lt;/code&gt; functions.
&lt;code&gt;geo&lt;/code&gt; values allow for geo-indexing and support the geo functions mentioned below. &lt;code&gt;uid&lt;/code&gt; value is a way to indicate that the predicate edge points to another entity node.
This is useful to generate edges in reverse direction automatically. The rest support sorting, equality and inequality functions.&lt;/p&gt;

&lt;p&gt;If you want to generate the index for a particular predicate, mention its type and specify the &lt;code&gt;@index&lt;/code&gt; keyword.
Similarly, to generate reverses for a uid predicate, you can specify the &lt;code&gt;@reverse&lt;/code&gt; keyword.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example schema file for freebase film data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
  film.director.film             : uid    @ reverse
  film.film.genre                : uid    @ reverse
  film.film.initial_release_date : date   @ index
  film.film.rating               : uid    @ reverse
  loc                            : geo    @ index
  type.object.name.en            : string @ index
  type.object.name.hi            : string @ index
  type.object.name.ta            : string @ index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 schema &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;reverse-edges&#34;&gt;Reverse Edges&lt;/h4&gt;

&lt;p&gt;Each graph edge is unidirectional. But a lot of times, you need to have both the forward and backward edges. For those cases, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now provides a &lt;code&gt;@reverse&lt;/code&gt; keyword, which can be applied to predicates of &lt;code&gt;uid&lt;/code&gt; type. This would trigger automatic generation of the reverse edges, to allow querying in the reverse direction.&lt;/p&gt;

&lt;p&gt;You can read more about reverse edges &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Reverse_Edges&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;sorting&#34;&gt;Sorting&lt;/h3&gt;

&lt;p&gt;You can now sort the results by any indexed predicate (except string and geo, of course). For example, you can now get a list of films directed by Steven Spielberg sorted by initial release date.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film(order: film.film.initial_release_date) {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}

# To sort in descending order, just use orderdesc instead of order.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about sorting &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Sorting&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;functions&#34;&gt;Functions&lt;/h3&gt;

&lt;p&gt;Functions are a great way to provide functionality with a simple and clear interface. &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 functions can be used as both starting points to queries and as filters.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a list of functions we introduced in v0.7.1:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;anyof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has any of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has all of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is less than or equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is greater than or equal to specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both &lt;code&gt;anyof&lt;/code&gt; and &lt;code&gt;allof&lt;/code&gt; functions work based on an index generated by tokenizing string values. We use ICU, which has vast support for human languages and is used by major projects like Google Web Search, Chrome, Mac OSX, Lucene, etc.&lt;/p&gt;

&lt;p&gt;Upcoming in v0.7.2:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;eq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;le(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is less than specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ge(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is greater than specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To enable these functions, a &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;schema providing the scalar type&lt;/a&gt; for the predicates should be provided. For e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar(
  name          : string @ index # anyof, allof
  age           : int    @ index # leq, geq
  date_of_birth : date   @ index # leq, geq
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about functions &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Functions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;geospatial-functions&#34;&gt;Geospatial functions&lt;/h4&gt;

&lt;p&gt;Geospatial queries are important to build location-aware search and recommendations. Being able to find the nearby restaurants who serve sushi, or bars in the city which play Jazz, or friends who are visiting your neighborhood is pretty crucial to such use cases. We couldn&amp;rsquo;t imagine building a database without providing full-fledged support for geo queries, and in v0.7.1, we added geo indexing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports four geospatial functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;near(predicate, geo-location)&lt;/code&gt;      : Finds all entities lying within a specified distance from a point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;within(predicate, geo-polygon)&lt;/code&gt;     : Finds all entities lying within a specified region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;contains(predicate, geo-location)&lt;/code&gt;  : Finds all enclosures for a specified point or region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;intersects(predicate, geo-polygon)&lt;/code&gt; : Finds all entities which intersect a specified region.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:8080/query -XPOST -d $&#39;
{
  tourist( near(&amp;quot;loc&amp;quot;, &amp;quot;{\&#39;type\&#39;:\&#39;Point\&#39;, \&#39;coordinates\&#39;: [-122.469829, 37.771935]}&amp;quot;, &amp;quot;1000&amp;quot; ) ) {
    name
  }
}&#39; | python -m json.tool | grep name

            &amp;quot;name&amp;quot;: &amp;quot;Steinhart Aquarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Spreckels Temple of Music&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Pioneer Log Cabin&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Conservatory of Flowers&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;De Young Museum&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Chinese Pavillion&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Japanese Tea Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Peace Lantern&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;San Francisco Botanical Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Morrison Planetarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;California Academy of Sciences&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Hamon Tower&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;National AIDS Memorial Grove&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;La Rose des Vents&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Strawberry Hill&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Buddha&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Rose Garden&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about Geolocation functionality &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Geolocation&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;filtering&#34;&gt;Filtering&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports pretty advanced and complex filtering operations. We do both &amp;amp;&amp;amp; (and) and || (or) filters, using round brackets to specify the right sequence. For e.g., &lt;code&gt;(A || (B &amp;amp;&amp;amp; C))&lt;/code&gt;, as demonstrated in the following query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film @filter(
      allof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jones indiana&amp;quot;) ||
      (anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jurassic&amp;quot;) &amp;amp;&amp;amp; anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;park&amp;quot;)))  {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that, I&amp;rsquo;ll finish the blog post. &lt;strong&gt;If you found these interesting, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ll be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Go Meetup in Sydney on 19th Jan and in Gophercon India on 24-25th Feb. So, come talk to me about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;

</description>
    </item>
    
    <item>
      <title>Dgraph hugo blog theme</title>
      <link>https://open.dgraph.io/post/hugo/</link>
      <pubDate>Thu, 06 Oct 2016 16:56:08 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/hugo/</guid>
      <description>&lt;p&gt;We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 love &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and use it for our blog. It&amp;rsquo;s blazingly fast, supports Markdown is written in Go and is very easy to work with. Initially, we were confused between Hugo vs. having a publication on Medium but later decided to go with Hugo because of the factors mentioned above. One of the things that we found lacking in the Hugo ecosystem was a good theme that we could use for our blog.&lt;/p&gt;

&lt;p&gt;So we got a theme designed which fit well with our website and used the screen estate well. It&amp;rsquo;s now available at &lt;a href=&#34;http://themes.gohugo.io/hugo-dgraph-theme/&#34;&gt;Dgraph theme&lt;/a&gt;. The theme is responsive, supports syntax highlighting for code and &lt;a href=&#34;https://www.discourse.org/&#34;&gt;discourse&lt;/a&gt; for comments. If your project is open source, you can also link to Github. We would encourage you to try out the theme and let us know your experiences with it.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.nasa.gov/image-feature/jpl/pia20027/infrared-echoes-of-a-black-hole-eating-a-star/&#34;&gt;Infrared Echoes of a Black Hole Eating a Star&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang: Run multiple services on one port</title>
      <link>https://open.dgraph.io/post/cmux/</link>
      <pubDate>Tue, 04 Oct 2016 11:59:57 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/cmux/</guid>
      <description>&lt;p&gt;Ever faced the problem of having multiple ports in an application, one for each service?
In this post, I&amp;rsquo;m going to brief about how to run multiple services via the same listener port.&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we used to have one port to serve HTTP requests, one for gRPC and one more for internal communication among the servers.
But now we just use one port for all the outside facing services and one for internal server communications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/soheilhy/cmux&#34;&gt;Cmux&lt;/a&gt; is a connection multiplexing library for Go. It allows you to differentiate services based on the payload. Hence, you can serve HTTP, HTTPS, gRPC, etc on the same port. For complete information on the protocols supported, refer to their &lt;a href=&#34;https://godoc.org/github.com/soheilhy/cmux&#34;&gt;godoc&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let us jump into the three simple steps with some code sample and get this working in a jiffy.&lt;/p&gt;

&lt;p&gt;First setup the different services as you would usually do. In our case we setup a gRPC service and an HTTP handler function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Setup gRPC server.
type grpcServer struct{}

func (s *grpcServer) Query(ctx context.Context,
  req *graph.Request) (*graph.Response, error) {
  .
  .
  .
}

// Handler function for http/https queries.
func queryHandler(w http.ResponseWriter, r *http.Request) {
  addCorsHeaders(w)
  .
  .
  .

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Second, write separate functions to start each service using a net.Listener object as if it is the only service using that listener.
Later we&amp;rsquo;ll multiplex a single TCP listener into multiple listeners.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Wrapper functions to start serving different services.

func serveGRPC(l net.Listener) {
  s := grpc.NewServer(grpc.CustomCodec(&amp;amp;query.Codec{}))
  graph.RegisterDgraphServer(s, &amp;amp;grpcServer{})
  if err := s.Serve(l); err != nil {
    log.Fatalf(&amp;quot;While serving gRpc request: %v&amp;quot;, err)
  }
}

func serveHTTP(l net.Listener) {
  if err := http.Serve(l, nil); err != nil {
    log.Fatalf(&amp;quot;While serving http request: %v&amp;quot;, err)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Third, create a listener object and multiplex it using a cmux matcher.
It&amp;rsquo;ll read the header bytes of exchanges and figure out which service to trigger by giving us a new sub-listener (We just call it that, though it&amp;rsquo;s actually just net.Listener) for every match.
We then call the services that we wrote earlier with these corresponding sub-listeners.
Look at the following code sample to get a better hang of the above-mentioned steps.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func setupServer() {
  go worker.RunServer(*workerPort) // For internal communication.

  // Create a listener at the desired port.
  l, err := net.Listen(&amp;quot;tcp&amp;quot;, fmt.Sprintf(&amp;quot;:%d&amp;quot;, *port))
  if err != nil {
    log.Fatal(err)
  }

  // Create a cmux object.
  tcpm := cmux.New(l)

  // Declare the match for different services required.
  httpl := tcpm.Match(cmux.HTTP1Fast())
  grpcl := tcpm.MatchWithWriters(
    cmux.HTTP2MatchHeaderFieldSendSettings(&amp;quot;content-type&amp;quot;, &amp;quot;application/grpc&amp;quot;))
  http2 := tcpm.Match(cmux.HTTP2())

  // Link the endpoint to the handler function.
  http.HandleFunc(&amp;quot;/query&amp;quot;, queryHandler)

  // Initialize the servers by passing in the custom listeners (sub-listeners).
  go serveGRPC(grpcl)
  go serveHTTP(httpl)
  go serveHTTP(http2)

  // Close the listener when done.
  go func() {
    &amp;lt;-closeCh
    // Stops listening further but already accepted connections are not closed.
    l.Close()
  }()

  log.Println(&amp;quot;grpc server started.&amp;quot;)
  log.Println(&amp;quot;http server started.&amp;quot;)
  log.Println(&amp;quot;Server listening on port&amp;quot;, *port)

  // Start cmux serving.
  if err := tcpm.Serve(); !strings.Contains(err.Error(),
    &amp;quot;use of closed network connection&amp;quot;) {
    log.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, there we have it. A single port to cater to many services that you might be using.&lt;/p&gt;

&lt;p&gt;Hope you had fun with this post and learnt something new. Thanks for reading and do let us know your thoughts and how it works out for you.&lt;/p&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://mars.nasa.gov/mars2020/images/Mars-2020-Artist-Concept-Instrument-SuperCam-br2.jpg&#34;&gt;Mars 2020, Artist Concept Instrument&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dgraph: JSON vs. Binary clients</title>
      <link>https://open.dgraph.io/post/protobuf/</link>
      <pubDate>Mon, 12 Sep 2016 10:54:15 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/protobuf/</guid>
      <description>

&lt;p&gt;When I started building the initial version of the &lt;a href=&#34;https://github.com/dgraph-io/dgraphgoclient&#34;&gt;Dgraph Go client&lt;/a&gt;, we were looking for a serialization format which was fast, easy to use and supported multiple language runtimes. We finally implemented our client using &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt; which &lt;strong&gt;gave twice the speed and consumed two-third memory&lt;/strong&gt; compared to JSON according to our benchmarks.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 v0.2 already supported serialization to JSON for the HTTP client. For our language specific drivers, we wanted something that would give us some performance improvement over JSON. Though we use &lt;a href=&#34;https://google.github.io/flatbuffers/&#34;&gt;Flatbuffers&lt;/a&gt; for everything internally, they lacked support for encoding recursive data structures. Protocol buffers seemed the right choice because they worked with most of the &lt;a href=&#34;https://github.com/google/protobuf#protobuf-runtime-installation&#34;&gt;modern languages&lt;/a&gt; and could encode recursive data structures efficiently.&lt;/p&gt;

&lt;h2 id=&#34;how-to-use-protocol-buffers&#34;&gt;How to use Protocol Buffers&lt;/h2&gt;

&lt;p&gt;To use protocol buffers, you define the message (data structures that form the basis of communication) in a &lt;code&gt;.proto&lt;/code&gt; file and then compile it using the protocol buffer &lt;a href=&#34;https://github.com/google/protobuf/releases&#34;&gt;compiler&lt;/a&gt;. For communication, we use &lt;a href=&#34;http://www.grpc.io/&#34;&gt;gRPC&lt;/a&gt; which is an open-source RPC framework by Google. gRPC requires services to be defined in the same &lt;code&gt;.proto&lt;/code&gt; file. Using gRPC allows us to communicate in binary format which is faster than retrieving JSON formatted results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// The Node object which can have other children node and properties.

message Node {
    uint64 uid = 1;
    string xid = 2;
    string attribute = 3;
    repeated Property properties = 4;
    repeated Node children = 5; // Each node can have multiple children
}

message Request {
    string query = 1;
    // and other fields
}

message Response {
    Node n = 1;
    // and other fields
}

// &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 service used for communication between the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 server and client over gRPC.

service Dgraph {
    rpc Query (Request) returns (Response) {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find the full &lt;code&gt;.proto&lt;/code&gt; file &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/graph/graphresponse.proto&#34;&gt;here&lt;/a&gt;. The &lt;code&gt;.proto&lt;/code&gt; file can be used to generate the corresponding Go code using the &lt;code&gt;protoc&lt;/code&gt; compiler and the runtime library.&lt;/p&gt;

&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;

&lt;p&gt;In Go, you can easily measure how your algorithm does (in terms of time and space) by writing benchmarks. Go benchmarks are unique in that they&amp;rsquo;d iterate over the test code &lt;code&gt;b.N&lt;/code&gt; number of times, where &lt;code&gt;b.N&lt;/code&gt; is adjusted until the benchmark function lasts long enough to be timed reliably.
To test how our implementation was doing against our JSON implementation we wrote benchmarks for it. But first, let&amp;rsquo;s understand what a benchmark is and how can we interpret its results.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s write a simple function, which just adds integers to a list.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func addToList() {
    list := make([]int, 10)
    for i := 0; i &amp;lt; 1000; i++ {
        list = append(list, i)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s benchmarking code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func BenchmarkAddToList(b *testing.B) {
    b.ReportAllocs()
    for i := 0; i &amp;lt; b.N; i++ {
        addToList()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can run the above benchmark using &lt;code&gt;go test -bench=.&lt;/code&gt; Here, Go benchmark would repeatedly call the function with different values for &lt;code&gt;b.N&lt;/code&gt; until it can be timed reliably.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench=.

BenchmarkAddToList-4  200000  8153 ns/op  22624 B/op  7 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s what the output means:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;200000 is the number of times the benchmark loop ran.&lt;/li&gt;
&lt;li&gt;8153 ns/op represents the time it took on average for an iteration of the loop to finish.&lt;/li&gt;
&lt;li&gt;22624 B/op is the number of bytes allocated per iteration.&lt;/li&gt;
&lt;li&gt;7 allocs/op is the number of distinct memory allocations per iteration.&lt;/li&gt;
&lt;li&gt;Note that we get B/op and allocs/op only if we call b.ReportAllocs() as part of the benchmark.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we change the line which initializes the slice to
&lt;code&gt;list := make([]int, 0, 1000)&lt;/code&gt; and run the benchmarks again, we get better results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkAddToList-4  1000000  1618 ns/op  0 B/op  0 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The allocs/op reduced because we had already initialized the list with the appropriate size and the runtime doesn&amp;rsquo;t have to reallocate it when we append elements. Also the B/op reduced because the list is not initialized with 0 for all its elements.&lt;/p&gt;

&lt;h2 id=&#34;benchmarking-topb-against-tojson&#34;&gt;Benchmarking ToPB against ToJSON&lt;/h2&gt;

&lt;p&gt;After implementing serialization using the protocol buffers, to get exact metrics we wrote benchmark tests for our ToJson and ToProtocolBuffer methods. These methods convert the internal SubGraph data structure to a byte array which is transferred over the network. Benchmark tests are an excellent way to compare different implementations or to measure if new code leads to any improvements.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Benchmark test for ToProtocolBuffer method.

func benchmarkToPB(file string, b *testing.B) {
    b.ReportAllocs()
    var sg SubGraph
    var l Latency

    // Reading the SubGraph data structure from a file.
    f, err := ioutil.ReadFile(file)
    if err != nil {
        b.Error(err)
    }

    buf := bytes.NewBuffer(f)
    dec := gob.NewDecoder(buf)
    err = dec.Decode(&amp;amp;sg)
    if err != nil {
        b.Error(err)
    }

    b.ResetTimer()
    // Running the benchmark tests.
    for i := 0; i &amp;lt; b.N; i++ {
        pb, err := sg.ToProtocolBuffer(&amp;amp;l)
        if err != nil {
            b.Fatal(err)
        }
        r := new(graph.Response)
        r.N = pb
        var c Codec
        if _, err = c.Marshal(r); err != nil {
            b.Fatal(err)
        }
    }
}

// Benchmark test for ToJSON
func benchmarkToJson(file string, b *testing.B) {
    b.ReportAllocs()
    var sg SubGraph
    var l Latency

    f, err := ioutil.ReadFile(file)
    if err != nil {
        b.Error(err)
    }

    buf := bytes.NewBuffer(f)
    dec := gob.NewDecoder(buf)
    err = dec.Decode(&amp;amp;sg)
    if err != nil {
        b.Error(err)
    }

    b.ResetTimer()
    for i := 0; i &amp;lt; b.N; i++ {
        if _, err := sg.ToJSON(&amp;amp;l); err != nil {
            b.Fatal(err)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find the complete benchmark tests &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query_test.go&#34;&gt;here&lt;/a&gt;. There are some differences in the algorithm that converts the internal Subgraph structure to JSON/Protocol Buffers. You can have a look at the code responsible for this &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query.go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Using these benchmark tests we were able to improve our metrics by over 50% by switching over to &lt;code&gt;[]byte&lt;/code&gt; from &lt;code&gt;{}interface&lt;/code&gt; for &lt;code&gt;ObjectValue&lt;/code&gt; as part of &lt;a href=&#34;https://github.com/dgraph-io/dgraph/pull/86&#34;&gt;this change&lt;/a&gt;. Later when we shifted to Gogo Protobuf, we compared these benchmarks again with the previous ones to confirm improvement.&lt;/p&gt;

&lt;h4 id=&#34;marshalling&#34;&gt;Marshalling&lt;/h4&gt;

&lt;p&gt;This is how the final benchmark results compare for a query which returns 1000 entities in the result.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToJSON_1000_Director-2  500  2512808 ns/op  560427 B/op  9682 allocs/op
BenchmarkToPB_1000_Director-2   2000  1338410 ns/op  196743 B/op  3052 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The benchmarks show that ToPB method is almost &lt;strong&gt;2x faster&lt;/strong&gt; than ToJSON as it takes much lesser nanoseconds per operation. The bytes allocated per operation show that ToPB &lt;strong&gt;allocates 65% less memory&lt;/strong&gt; compared to ToJSON. You could find more information about those benchmarks and what we changed to get here in our &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/benchmark/README.txt&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;unmarshalling&#34;&gt;Unmarshalling&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToJSONUnmarshal_1000_Director-4  1000  1279297 ns/op  403746 B/op  5144 allocs/op
BenchmarkToPBUnmarshal_1000_Director-4    3000   489585 ns/op  202256 B/op  5522 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can see that unmarshalling on the client would also be &lt;strong&gt;2.6x faster&lt;/strong&gt; for protocol buffers compared to JSON. ToPB &lt;strong&gt;allocates 50% less memory&lt;/strong&gt; compared to ToJSON.&lt;/p&gt;

&lt;h3 id=&#34;golang-protobuf-vs-gogo-protobuf&#34;&gt;Golang protobuf vs. Gogo protobuf&lt;/h3&gt;

&lt;p&gt;If both your server and client are written in Go, then we recommend &lt;a href=&#34;https://github.com/gogo/protobuf&#34;&gt;Gogo Protobuf&lt;/a&gt; instead of &lt;a href=&#34;https://github.com/golang/protobuf&#34;&gt;Golang Protobuf&lt;/a&gt; as the runtime library. Gogo has &lt;strong&gt;2.3x faster marshaling while allocating 80% fewer bytes&lt;/strong&gt; per operation and &lt;strong&gt;1.5x faster unmarshalling&lt;/strong&gt; compared to Golang protobuf as shown in the benchmarks below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToPBMarshal_1000_Director-4    3000  360545 ns/op 226504 B/op   22 allocs/op # Golang protobuf
BenchmarkToPBMarshal_1000_Director-4    10000 156820 ns/op 49152 B/op     1 allocs/op # Gogo protobuf

BenchmarkToPBUnmarshal_1000_Director-4  2000  733481 ns/op 200241 B/op 5523 allocs/op # Golang protobuf
BenchmarkToPBUnmarshal_1000_Director-4  3000  487745 ns/op 202256 B/op 5522 allocs/op # Gogo protobuf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that Gogo protobuf has support only for Go as of now. However, if you are using some other language, this isn&amp;rsquo;t a problem. Gogo protobuf is backward compatible with Golang protobuf. Our Python and Java clients can still interact with the server (which does marshaling using Gogo), hence making Gogo a safe choice.&lt;/p&gt;

&lt;h2 id=&#34;recommendations&#34;&gt;Recommendations&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;If you are interacting with the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 from the browser directly with Javascript, we recommend that you use the more browser-friendly JSON.&lt;/li&gt;
&lt;li&gt;If you are interacting with &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 through one of our language drivers, we recommend you do it using gRPC and protocol buffers.&lt;/li&gt;
&lt;li&gt;If you are using Go client with gRPC, you will automatically be using the faster Gogo protobuf.&lt;/li&gt;
&lt;li&gt;Overall, &lt;strong&gt;fastest way to query &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is via a Go client communicating over gRPC.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We would love to hear about your interaction with the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 server.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.nasa.gov/image-feature/sept-14-1966-view-from-gemini-xi-850-miles-above-the-earth/&#34;&gt;View From Gemini XI, 850 Miles Above the Earth&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gru: Open source solution for better technical interviews</title>
      <link>https://open.dgraph.io/post/gru/</link>
      <pubDate>Thu, 21 Jul 2016 11:53:04 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/gru/</guid>
      <description>

&lt;p&gt;Candidate &lt;strong&gt;REJECTED&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;4 out of 5 interviewers had liked the candidate. I was one of the 4. He had received either above or very close to 3.0, which is a good score. The interviewer who didn&amp;rsquo;t like the candidate had been at Google since early 2004. And he didn&amp;rsquo;t like the candidate&amp;rsquo;s joke question about whether he was very rich because he joined before Google went IPO. &lt;em&gt;I guess he wasn&amp;rsquo;t.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The system in place was methodical. On a scale of 0.0 to 5.0, only terrible candidates received less than 2.0. And only in very rare cases did someone receives above 4.0. Anything above 3.0 was a pretty solid YES for hire. But how the interviewers scored a candidate was very subjective. There was no standardized training for interviewers on how to interview. Some people tend to give higher scores; some tend to give lower scores. So, the hiring committee had been asked to take the interviewer&amp;rsquo;s previous scoring patterns into account, along with how much evidence and conviction they had presented in the feedback form.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was duct tape on a broken system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It&amp;rsquo;s not an issue specific to Google. Many tech companies follow some variance of the same approach. Two phone screens + five onsite technical interviews, followed by feedback presented to a committee which then decided if the candidate should be hired or not.&lt;/p&gt;

&lt;p&gt;Except that the interviewers have no particular training in judging other people. Most would ask one question; which would get dragged on for the entire length of the interview. If the candidate did well on that question, they might ask another one. So, if the candidate messes up that first question, there&amp;rsquo;s no coming back, mostly even including the rest of the interviews (unless you do exceptionally well in the rest).&lt;/p&gt;

&lt;p&gt;Also, given the inflow of smart young engineers flowing into the valley, the questions are generic enough to be answered by &lt;em&gt;anyone&lt;/em&gt;. So, these drill down to basic computer science concepts &amp;ndash; graphs, trees, sorting, and other algorithms. The candidate is expected to come up with a solution and code it up on a whiteboard within the allocated time under pressure.&lt;/p&gt;

&lt;p&gt;Not surprisingly, &lt;strong&gt;experienced professionals tend to do worse at these interviews than fresh grads&lt;/strong&gt;. Very few professional tech problem can be coded up in 20 mins. Over years of coding, they lose the practice of solving simple problems under time pressure, instead focusing on deeper, harder design problems.&lt;/p&gt;

&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.&lt;/p&gt;&amp;mdash; Max Howell (@mxcl) &lt;a href=&#34;https://twitter.com/mxcl/status/608682016205344768&#34;&gt;June 10, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;I&amp;rsquo;m convinced that the existing technical interview system is expensive and broken.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Without any objective measurement, judging the smarts, skills and experience of an engineer is just handwaving.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Triplebyte recently &lt;a href=&#34;http://blog.triplebyte.com/three-hundred-programming-interviews-in-thirty-days&#34;&gt;came up with a post about hiring&lt;/a&gt;. I found it instantly interesting. With a lot of data, they found a higher correlation between a quiz and successful candidates; and a lower one between coding questions and successful candidates.
This got us thinking.
&lt;strong&gt;If we wanted to design an objective interviewing system, we should design a quiz.&lt;/strong&gt;
It would have multiple benefits:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A single question wouldn&amp;rsquo;t dictate the entire interview. If the candidate is stuck, they can just skip the question.&lt;/li&gt;
&lt;li&gt;Focus on different aspects of systems and algorithms, with multiple questions from each. Looking at a final report would make it clear where the strengths and weaknesses of the candidate lie.&lt;/li&gt;
&lt;li&gt;Give us an objective score, which we can then use to compare them against other candidates.&lt;/li&gt;
&lt;li&gt;Generate a common repository of interview questions, which can ascertain that any leaked questions can&amp;rsquo;t be asked again, and new ones can be added collectively by engineers.&lt;/li&gt;
&lt;li&gt;Cut down on engineers&amp;rsquo; time spent on interviewing significantly. That in itself is a huge benefit about this system. &lt;strong&gt;Any human interaction can then focus on the cultural fit&lt;/strong&gt;, which I think is equally important to technical skills.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And we did exactly this. We painstakingly and after much cross-examination came up with 30 or so quiz questions in the house. These questions test various aspects of algorithms, concurrency and server interaction.&lt;/p&gt;

&lt;p&gt;Over the past months, we have had 20 candidates take our quiz. It&amp;rsquo;s a small number, but it&amp;rsquo;s still telling. The following graph shows how the candidates fared.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/score.png&#34; alt=&#34;Graph representing scores of different candidates&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the red dots represent the score (y-axis left), and the green dots represent the time taken (y-axis right). Candidates with experience in big companies are tagged as such - GB for Googlers who primarily worked on backend/infrastructure projects, GO for Googlers who worked on other projects, Intel, Microsoft and Amazon. Every other company whose name we didn&amp;rsquo;t recognize (startup/smaller company) is tagged as OC.&lt;/p&gt;

&lt;p&gt;What we can learn from this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we have an affinity for Googlers!&lt;/li&gt;
&lt;li&gt;The performance of Googlers on our quiz varied quite a lot. Googlers with backend experience performed not only great but the best out of all candidates.&lt;/li&gt;
&lt;li&gt;Googlers from other fields didn&amp;rsquo;t fare so well. This goes to show that there&amp;rsquo;s quite a significant difference in skills and experience of Googlers working on different projects.&lt;/li&gt;
&lt;li&gt;Note also that there&amp;rsquo;s a selection bias here because our quiz includes questions about concurrency and distributed systems. Folks with frontend experience don&amp;rsquo;t deal with these problems on a regular basis and hence didn&amp;rsquo;t do so well; which in a way is a validation that the quiz system worked as intended.&lt;/li&gt;
&lt;li&gt;Worst scorers tend to take more time than the best. In fact, all 4 top scorers finished approximately under 50 mins, at least 10 mins before the test ended, because they ran out of questions to answer. In fact, the top scoring candidate finished the quiz in half the time!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;So, we decided to improve upon this basic quiz and converted it to an adaptive test.&lt;/strong&gt;
Based on Triplebyte&amp;rsquo;s and our experience, we know that best candidates take less time to solve the quiz.
We hypothesize if the best performers were allowed to answer more questions in the same fixed time, their score would have been significantly better.&lt;/p&gt;

&lt;p&gt;So, instead of showing a fixed number of questions to be answered in a given maximum time duration, we fix the time and let the candidates answer as many questions as they can in an hour.
And if they&amp;rsquo;re performing well, we show them harder questions carrying higher scores (and vice-versa).
This system would make the difference between an okay candidate and a stellar candidate much more evident.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In fact, the best candidates would become outliers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This inspiration is what &lt;a href=&#34;https://github.com/dgraph-io/gru&#34;&gt;lead to Gru&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;gru-finding-the-right-minions&#34;&gt;Gru: Finding the right minions&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Update: Gru&amp;rsquo;s design has changed significantly since this blog post. It has a browser based frontend, and uses &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 as backend. Over 200 candidates have taken &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 screening quiz using this new version of Gru.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gru is an open-source, adaptive quiz system written entirely in Go. Gru server has a simple design and is very easy to setup. It doesn&amp;rsquo;t require maintaining a database. Questions and candidate information are stored and read from files. All the communication between the client and the server is encrypted.&lt;/p&gt;

&lt;p&gt;Engineers collectively come up with questions from different areas and put them in a YAML formatted file. They tag them as &lt;code&gt;easy&lt;/code&gt;, &lt;code&gt;medium&lt;/code&gt;, &lt;code&gt;hard&lt;/code&gt;. You can add more tags to define the field, for, e.g., &lt;code&gt;concurrency&lt;/code&gt;, &lt;code&gt;graph&lt;/code&gt;, &lt;code&gt;sorting&lt;/code&gt;, &lt;code&gt;searching&lt;/code&gt;, etc. Each question has it&amp;rsquo;s own positive and negative scores, generally determined based on their complexity, uniqueness, or statistical probability of anyone getting it right, etc. Here&amp;rsquo;s an example from our demo quiz.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;- id: spacecraftmars
  str: Which year did we first land a spacecraft on Mars?
  correct: [spacecraftmars-1976]
  opt:
  - uid: spacecraftmars-2001
    str: 2001
  - uid: spacecraftmars-1976
    str: 1976
  - uid: spacecraftmars-1981
    str: 1981
  - uid: spacecraftmars-2013
    str: 2013
  positive: 5
  negative: 2.5
  tags: [medium,demo,mars]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gru client runs on the command line and makes use of &lt;a href=&#34;https://github.com/gizak/termui&#34;&gt;termui&lt;/a&gt; for displaying the questions. The score of the candidate is always visible to them, providing real-time feedback on how they are doing during the test.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/gru_screenshot.png&#34; alt=&#34;Screenshot of the Gru client in action&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If you want to get your hands dirty, we have a server running with some demo questions. The binaries for both Gru server and Gru client &lt;a href=&#34;https://github.com/dgraph-io/gru/releases&#34;&gt;are released here&lt;/a&gt;. To take the demo quiz, download the gruclient binary for your platform and just run it. It would automatically connect to our Gru server, and test your knowledge about humankind&amp;rsquo;s space missions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;You could start running Gru at your company for free. For more details on how Gru works and how to host it, please visit &lt;a href=&#34;https://wiki.dgraph.io/Gru&#34;&gt;Gru wiki&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gru is a work in progress. Let us know what you think about it and how we could improve it on &lt;a href=&#34;https://discuss.dgraph.io&#34;&gt;discuss.dgraph.io&lt;/a&gt;. If you find any issues with Gru, &lt;a href=&#34;https://github.com/dgraph-io/gru/issues&#34;&gt;file a bug&lt;/a&gt;. Hope you like Gru and looking forward to a world with better technical interviews.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Gru Links
- &lt;a href=&#34;https://github.com/dgraph-io/gru&#34;&gt;Github repository&lt;/a&gt;
- &lt;a href=&#34;https://wiki.dgraph.io/Gru&#34;&gt;Gru Wiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Other posts I&amp;rsquo;ve written about interview process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@manishrjain/technical-interviews-open-ended-design-questions-ea7fff3486a7#.d6y5gyjys&#34;&gt;Technical Interviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/Why-cant-I-get-a-job-at-some-tech-giants-despite-doing-well-at-interviews/answer/Manish-Rai-Jain?srid=5tVr&#34;&gt;Why can&amp;rsquo;t I get a job despite doing well in interviews?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;

</description>
    </item>
    
    <item>
      <title>Releasing v0.4</title>
      <link>https://open.dgraph.io/post/v0.4-release/</link>
      <pubDate>Thu, 14 Jul 2016 16:16:14 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/v0.4-release/</guid>
      <description>

&lt;p&gt;Thanks for your feedback over the last couple of months. This release addresses some of the main pain points of using &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 uses &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;, which doesn&amp;rsquo;t have a native Go interface.
To use RocksDB via Go, Cgo is required, which makes doing a simple &lt;code&gt;go get&lt;/code&gt; installation of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 hard.
You first need to download, compile and install RocksDB, before installing &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
While &lt;code&gt;go get&lt;/code&gt; would still require more manual steps, starting this version only contributors to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 would have to do that.&lt;/p&gt;

&lt;p&gt;We have embedded RocksDB into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 binary and generated binaries for both Linux and Mac.
Now, most users can just choose one of these two options:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl https://get.dgraph.io | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, download the latest release &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases&#34;&gt;from Github&lt;/a&gt;. And extract the binaries to &lt;code&gt;/usr/local/bin&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# For Linux
$ sudo tar -C /usr/local/bin -xzf dgraph-linux-amd64-VERSION.tar.gz

# For Mac
$ sudo tar -C /usr/local/bin -xzf dgraph-darwin-amd64-VERSION.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s it! These simple steps give you everything that you need to install &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is a small team of enthusiastic developers, who like to code more than they like to write docs.
Even when the team writes documentation, it gets stale very quickly.
Honestly, that&amp;rsquo;s not a story unique to us. It&amp;rsquo;s a common problem affecting many projects.&lt;/p&gt;

&lt;p&gt;So, I thought why not solve it in a way where our documentation would never get stale.
I looked around for inspiration and found these two documentations that maximized screen estate usage and were easy to follow.
Each of these allowed search engines to easily index them while providing a lot of content per web page, which made doing a browser search easy.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.archlinux.org/&#34;&gt;Arch Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.gentoo.org/wiki/Main_Page&#34;&gt;Gentoo Linux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I run Arch Linux on my desktop and laptop, and love it&amp;rsquo;s thorough up to date documentation.
So, I couldn&amp;rsquo;t be more excited about building something similar for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;So, after last 3 weeks of &lt;em&gt;no-coding-only-documentation&lt;/em&gt; effort, &lt;strong&gt;presenting &lt;a href=&#34;https://wiki.dgraph.io&#34;&gt;wiki.dgraph.io&lt;/a&gt;, the official source of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 documentation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Just like Arch and Gentoo, it&amp;rsquo;s using MediaWiki software, which most people use on a daily basis (Thanks, Wikipedia).&lt;/p&gt;

&lt;p&gt;The main reason we chose wiki over other solutions is that it puts the power of editing right in the hands of the user.
So if a user spots an error, they have everything they need to fix it.
If the fix is more complicated, writing a note stating that this article or section is out of date is sufficient to get the team and more importantly, other users notified; so they can take appropriate action.&lt;/p&gt;

&lt;p&gt;And &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 community welcomed the change! We already have contributions to wiki from community members on various pages.
They keep us accountable and help maintain the quality of the documentation.
So, check it out, and if you find any issues or need more clarity in some section, log in, and edit the page. It&amp;rsquo;s that simple.&lt;/p&gt;

&lt;p&gt;Btw, if you installed &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 above, this is the page you&amp;rsquo;re looking for: &lt;a href=&#34;https://wiki.dgraph.io/Beginners_Guide&#34;&gt;https://wiki.dgraph.io/Beginners_Guide&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;clients&#34;&gt;Clients&lt;/h2&gt;

&lt;p&gt;In v0.3, we released a Go client for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
Thanks to our enthusiastic community, we got contributions for other languages. Now we have client code for both &lt;strong&gt;Java&lt;/strong&gt; and &lt;strong&gt;Python&lt;/strong&gt;.
Thanks &lt;a href=&#34;https://github.com/bitmalloc&#34;&gt;@bitmalloc&lt;/a&gt; and &lt;a href=&#34;https://github.com/mohitranka&#34;&gt;@mohitranka&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;In fact, Python client installation is as simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install -U pydgraph
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about how to install and use them here: &lt;a href=&#34;https://wiki.dgraph.io/Clients&#34;&gt;https://wiki.dgraph.io/Clients&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;debugging&#34;&gt;Debugging&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Why did this query take so long to run?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This question stumped us! We didn&amp;rsquo;t know why. &lt;code&gt;logrus&lt;/code&gt; was useful only for general logging.
It couldn&amp;rsquo;t pinpoint which log was from which query, and show which steps of execution took how long, during the life of the query.&lt;/p&gt;

&lt;p&gt;The moment I realized that &lt;a href=&#34;https://grpc.io&#34;&gt;grpc.io&lt;/a&gt; is a ground-up rewrite of stubby, Google&amp;rsquo;s internal rpc system; I knew that we had to switch to it.
Stubby could provide amazing debugging information about each request to the server, and something that&amp;rsquo;s very well translated to grpc.&lt;/p&gt;

&lt;p&gt;So, after thorough effort, I was able to replace most of the &lt;code&gt;logrus.Log&lt;/code&gt; statements to use &lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;context&lt;/a&gt; and &lt;a href=&#34;https://godoc.org/golang.org/x/net/trace&#34;&gt;trace&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks to these, you can now easily debug live queries running on &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
In fact, you can see all this in action on one of our demo &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 instance &lt;a href=&#34;http://dgraph.xyz/debug/requests?fam=Dgraph&amp;amp;b=0&amp;amp;exp=1&#34;&gt;via /debug/requests&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/07/14 06:54:55.615143    0.003184    Query
06:54:55.615157     .    14    ... Query received: { me(_xid_: m.0bxtg) { type.object.name.en film.actor.film { film.performance.film { type.object.name.en type.object.name.ru } } } }
06:54:55.615295     .   138    ... Xid: m.0bxtg Uid: 14685953405111677952
06:54:55.615312     .    17    ... Query parsed
06:54:55.615323     .    11    ... Sample value for attr: _root_ Val:
06:54:55.617188     .    55    ... (18 events discarded)
06:54:55.617190     .     3    ... Reply from child. Index: 1 Attr: type.object.name.ru
06:54:55.617192     .     2    ... Reply from child. Index: 0 Attr: film.performance.film
06:54:55.617194     .     2    ... Reply from child. Index: 1 Attr: film.actor.film
06:54:55.617195     .     1    ... Graph processed
06:54:55.618252     .  1057    ... Latencies: Total: 3.102143ms Parsing: 163.283µs Process: 1.88333ms Json: 601.266µs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These live queries are further categorized by how long they took to run. So, you can easily identify slower queries.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/07/14 03:16:13.684030    0.100109    Query
03:16:13.684045     .    15    ... Query received: { me(_xid_: m.06pj8) { type.object.name.en film.director.film { type.object.name.en film.film.initial_release_date film.film.country film.film.starring { film.performance.actor { type.object.name.en } film.performance.character { type.object.name.en } } film.film.genre { type.object.name.en } } } }
03:16:13.684175     .   130    ... Xid: m.06pj8 Uid: 4255310415198890869
03:16:13.684193     .    17    ... Query parsed
03:16:13.684197     .     4    ... Sample value for attr: _root_ Val:
03:16:13.744452     .    41    ... (47 events discarded)
03:16:13.744458     .     5    ... Reply from child. Index: 1 Attr: film.performance.character
03:16:13.744466     .     8    ... Reply from child. Index: 4 Attr: film.film.genre
03:16:13.744477     .    11    ... Reply from child. Index: 1 Attr: film.director.film
03:16:13.744482     .     5    ... Graph processed
03:16:13.783501     . 39020    ... Latencies: Total: 99.461379ms Parsing: 156.916µs Process: 60.288205ms Json: 25.813948ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, you can see latency (in microseconds) statistics over various time intervals.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Count: 20    Mean: 59979    StdDev: 37593    Median: 84261
[    2048,    4096)    4    20.000%    20.000%
[    4096,    8192)    2    10.000%    30.000%
[    65536,    131072)    14    70.000%    100.000%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the first time we have such data available, and we&amp;rsquo;ll tweak what gets reported over time to make these logs more and more useful.&lt;/p&gt;

&lt;p&gt;Hope you like these features and try out &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases&#34;&gt;the new release&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Thanks &lt;a href=&#34;https://twitter.com/mholt6&#34;&gt;Matt Holt&lt;/a&gt; from the Caddy team, for the inspiration to have &lt;code&gt;https://get.dgraph.io&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/cygnus-cargo-craft-released-from-space-station/&#34;&gt;Cygnus Cargo Craft Released From Space Station&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Custom encoding: Go implementation in net/rpc vs grpc and why we switched</title>
      <link>https://open.dgraph.io/post/rpc-vs-grpc/</link>
      <pubDate>Sat, 25 Jun 2016 19:06:45 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/rpc-vs-grpc/</guid>
      <description>

&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we aim to build a low latency, distributed graph database.
This means our data is distributed among nodes in the cluster.
Executing a query means multiple nodes are communicating with each other.
To keep our latency of communication low, we use a new form of serialization library called &lt;a href=&#34;https://google.github.io/flatbuffers/&#34;&gt;Flatbuffers&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;What sets FlatBuffers apart is that it represents hierarchical data in a flat binary buffer in such a way that it can still be accessed directly without parsing/unpacking, while also still supporting data structure evolution (forwards/backwards compatibility).
The only memory needed to access your data is that of the buffer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;How is Flatbuffers better than &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt;&lt;/strong&gt;? FlatBuffers does not need a parsing/unpacking step to a secondary representation before you can access data, often coupled with per-object memory allocation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 responses can contain millions of entities and binary blob values.
And the fact that Flatbuffers doesn&amp;rsquo;t need to recreate the entire information in language specific data structures is very helpful for both memory and speed.&lt;/p&gt;

&lt;p&gt;Also, TCP is always going to be faster than HTTP, because HTTP is one extra layer on top of TCP.
So, our goal was to implement communication using RPC over custom encoding utilizing Flatbuffers.&lt;/p&gt;

&lt;h1 id=&#34;go-net-rpc&#34;&gt;Go net/rpc&lt;/h1&gt;

&lt;p&gt;Our first approach was to use Go language library &lt;code&gt;net/rpc&lt;/code&gt; and implement custom encoding in it.&lt;/p&gt;

&lt;p&gt;Helper function to deal with writing and parsing header for the payload:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;bytes&amp;quot;
    &amp;quot;encoding/binary&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;

    &amp;quot;github.com/dgraph-io/dgraph/x&amp;quot;
)

type Query struct {
    Data []byte
}

type Reply struct {
    Data []byte
}

func writeHeader(rwc io.ReadWriteCloser, seq uint64,
    method string, data []byte) error {

    var bh bytes.Buffer
    var rerr error

    // In package x: func SetError(prev *error, n error)
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, seq))
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, int32(len(method))))
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, int32(len(data))))
    _, err := bh.Write([]byte(method))
    x.SetError(&amp;amp;rerr, err)
    if rerr != nil {
        return rerr
    }
    _, err = rwc.Write(bh.Bytes())
    return err
}

func parseHeader(rwc io.ReadWriteCloser, seq *uint64,
    method *string, plen *int32) error {

    var err error
    var sz int32
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, seq))
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, &amp;amp;sz))
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, plen))
    if err != nil {
        return err
    }

    buf := make([]byte, sz)
    n, err := rwc.Read(buf)
    if err != nil {
        return err
    }
    if n != int(sz) {
        return fmt.Errorf(&amp;quot;Expected: %v. Got: %v\n&amp;quot;, sz, n)
    }
    *method = string(buf)
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Code at server to read requests and write responses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;io&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net/rpc&amp;quot;
)

type ServerCodec struct {
    Rwc        io.ReadWriteCloser
    payloadLen int32
}

func (c *ServerCodec) ReadRequestHeader(r *rpc.Request) error {
    return parseHeader(c.Rwc, &amp;amp;r.Seq, &amp;amp;r.ServiceMethod, &amp;amp;c.payloadLen)
}

func (c *ServerCodec) ReadRequestBody(data interface{}) error {
    b := make([]byte, c.payloadLen)
    _, err := io.ReadFull(c.Rwc, b)
    if err != nil {
        return err
    }

    if data == nil {
        // If data is nil, discard this request.
        return nil
    }
    query := data.(*Query)
    query.Data = b
    return nil
}

func (c *ServerCodec) WriteResponse(resp *rpc.Response,
    data interface{}) error {

    if len(resp.Error) &amp;gt; 0 {
        log.Fatal(&amp;quot;Response has error: &amp;quot; + resp.Error)
    }
    if data == nil {
        log.Fatal(&amp;quot;Worker write response data is nil&amp;quot;)
    }
    reply, ok := data.(*Reply)
    if !ok {
        log.Fatal(&amp;quot;Unable to convert to reply&amp;quot;)
    }

    if err := writeHeader(c.Rwc, resp.Seq,
        resp.ServiceMethod, reply.Data); err != nil {
        return err
    }

    _, err := c.Rwc.Write(reply.Data)
    return err
}

func (c *ServerCodec) Close() error {
    return c.Rwc.Close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, the code at the client to read requests and write responses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;errors&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net/rpc&amp;quot;
)

type ClientCodec struct {
    Rwc        io.ReadWriteCloser
    payloadLen int32
}

func (c *ClientCodec) WriteRequest(r *rpc.Request, body interface{}) error {
    if body == nil {
        return fmt.Errorf(&amp;quot;Nil request body from client.&amp;quot;)
    }

    query := body.(*Query)
    if err := writeHeader(c.Rwc, r.Seq, r.ServiceMethod, query.Data); err != nil {
        return err
    }
    n, err := c.Rwc.Write(query.Data)
    if n != len(query.Data) {
        return errors.New(&amp;quot;Unable to write payload.&amp;quot;)
    }
    return err
}

func (c *ClientCodec) ReadResponseHeader(r *rpc.Response) error {
    if len(r.Error) &amp;gt; 0 {
        log.Fatal(&amp;quot;client got response error: &amp;quot; + r.Error)
    }
    if err := parseHeader(c.Rwc, &amp;amp;r.Seq,
        &amp;amp;r.ServiceMethod, &amp;amp;c.payloadLen); err != nil {
        return err
    }
    return nil
}

func (c *ClientCodec) ReadResponseBody(body interface{}) error {
    buf := make([]byte, c.payloadLen)
    _, err := io.ReadFull(c.Rwc, buf)
    reply := body.(*Reply)
    reply.Data = buf
    return err
}

func (c *ClientCodec) Close() error {
    return c.Rwc.Close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, each server should be able to send multiple requests in parallel.
So, we built a connection pool to create, store and reuse multiple connections:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;net&amp;quot;
    &amp;quot;net/rpc&amp;quot;
    &amp;quot;strings&amp;quot;
    &amp;quot;time&amp;quot;

    &amp;quot;github.com/dgraph-io/dgraph/x&amp;quot;
)

var glog = x.Log(&amp;quot;conn&amp;quot;) // In package x: func Log(p string) *logrus.Entry

type Pool struct {
    clients chan *rpc.Client
    Addr    string
}

func NewPool(addr string, maxCap int) *Pool {
    p := new(Pool)
    p.Addr = addr
    p.clients = make(chan *rpc.Client, maxCap)
    client, err := p.dialNew()
    if err != nil {
        glog.Fatal(err)
        return nil
    }
    p.clients &amp;lt;- client
    return p
}

func (p *Pool) dialNew() (*rpc.Client, error) {
    d := &amp;amp;net.Dialer{
        Timeout: 3 * time.Minute,
    }
    var nconn net.Conn
    var err error
    // This loop will retry for 10 minutes before giving up.
    for i := 0; i &amp;lt; 60; i++ {
        nconn, err = d.Dial(&amp;quot;tcp&amp;quot;, p.Addr)
        if err == nil {
            break
        }
        if !strings.Contains(err.Error(), &amp;quot;refused&amp;quot;) {
            break
        }

        glog.WithField(&amp;quot;error&amp;quot;, err).WithField(&amp;quot;addr&amp;quot;, p.Addr).
            Info(&amp;quot;Retrying connection...&amp;quot;)
        time.Sleep(10 * time.Second)
    }
    if err != nil {
        return nil, err
    }
    cc := &amp;amp;ClientCodec{
        Rwc: nconn,
    }
    return rpc.NewClientWithCodec(cc), nil
}

func (p *Pool) Call(serviceMethod string, args interface{},
    reply interface{}) error {

    client, err := p.get()
    if err != nil {
        return err
    }
    if err = client.Call(serviceMethod, args, reply); err != nil {
        return err
    }

    select {
    case p.clients &amp;lt;- client:
        return nil
    default:
        return client.Close()
    }
}

func (p *Pool) get() (*rpc.Client, error) {
    select {
    case client := &amp;lt;-p.clients:
        return client, nil
    default:
        return p.dialNew()
    }
}

func (p *Pool) Close() error {
    // We&#39;re not doing a clean exit here. A clean exit here would require
    // synchronization, which seems unnecessary for now. But, we should
    // add one if required later.
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This worked well.
And both v0.2 and v0.3 of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 were using this code for the nodes to communicate with each other.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;the-switch&#34;&gt;The Switch&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/martian-receiving.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we spend Fridays learning and improving.
This means reading books, papers, articles, watching talks.
And we came across a great talk by Jeff Dean of Google: &lt;a href=&#34;https://discuss.dgraph.io/t/jeff-deans-talk-about-rapid-response-times/83&#34;&gt;Rapid Response Times&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As I mentioned above, we care a lot about query latency.
After watching it a couple of times from two different conferences, the prime learning I gathered from his talk was:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Send request to the first replica, telling it that it&amp;rsquo;s going to send it to a second one.&lt;/li&gt;
&lt;li&gt;2 ms later, send the request to the second one, telling it that it&amp;rsquo;s already sent to the first one.&lt;/li&gt;
&lt;li&gt;When one of them starts processing the request, it sends a cancellation request directly to its peer.&lt;/li&gt;
&lt;li&gt;If the peer hasn&amp;rsquo;t started processing the request, it would just cancel the request.&lt;/li&gt;
&lt;li&gt;In a rare case, both of them process it and overall do twice the work.&lt;/li&gt;
&lt;li&gt;Overall, your latencies improve considerably due to this method.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Jeff_Dean_(computer_scientist)&#34;&gt;Jeff Dean&lt;/a&gt; has an impressive track record at Google. He&amp;rsquo;s behind almost every distributed system in production at Google.
So, when he gives a suggestion, you take it seriously.&lt;/p&gt;

&lt;p&gt;At v0.4, we&amp;rsquo;re not doing replication yet. So, we can&amp;rsquo;t send queries to multiple servers in parallel.
However, that&amp;rsquo;s how the system is going to look like a few minor releases down the lane.&lt;/p&gt;

&lt;p&gt;So, we started thinking about how we could change our custom encoding based RPC implementation to achieve something like this.
Around the same time, we were looking for a way to figure out slow rpcs on servers.
&lt;a href=&#34;https://forum.golangbridge.org/t/equivalent-of-rpcz-at-google/2609&#34;&gt;Dave Cheney&amp;rsquo;s response&lt;/a&gt; pointed us to &lt;a href=&#34;http://www.grpc.io/&#34;&gt;grpc.io&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While I had considered Google built &lt;code&gt;grpc&lt;/code&gt; in the past, I&amp;rsquo;d rejected it understanding that it requires you to use Protocol Buffers; but we&amp;rsquo;d already chosen to go with Flatbuffers.
But when &lt;a href=&#34;https://www.youtube.com/watch?v=sZx3oZt7LVg&#34;&gt;Sameer Ajmani&amp;rsquo;s talk&lt;/a&gt; pointed that &lt;code&gt;grpc&lt;/code&gt; is essentially a rewrite of Google internal Stubby from ground up, that got me to dig deeper.
&lt;code&gt;grpc&lt;/code&gt; came with &lt;code&gt;net/context&lt;/code&gt; which could easily do what Jeff Dean had talked about.
Also, it can help see live rpcs and track the slowest ones.&lt;/p&gt;

&lt;p&gt;Overall, there was a lot of advantages to switching to &lt;code&gt;grpc&lt;/code&gt;.
But, we didn&amp;rsquo;t want to give up the performance benefits of Flatbuffers.&lt;/p&gt;

&lt;p&gt;So, digging deeper, we found that &lt;code&gt;grpc&lt;/code&gt; did support custom encoding. And we implemented it.
This is the whole equivalent code implemented in &lt;code&gt;grpc&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package worker

import (
    &amp;quot;log&amp;quot;

    &amp;quot;google.golang.org/grpc&amp;quot;
)

type PayloadCodec struct{}

func (cb *PayloadCodec) Marshal(v interface{}) ([]byte, error) {
    p, ok := v.(*Payload)
    if !ok {
        log.Fatalf(&amp;quot;Invalid type of struct: %+v&amp;quot;, v)
    }
    return p.Data, nil
}

func (cb *PayloadCodec) Unmarshal(data []byte, v interface{}) error {
    p, ok := v.(*Payload)
    if !ok {
        log.Fatalf(&amp;quot;Invalid type of struct: %+v&amp;quot;, v)
    }
    p.Data = data
    return nil
}

func (cb *PayloadCodec) String() string {
    return &amp;quot;worker.PayloadCodec&amp;quot;
}

type Pool struct {
    conns chan *grpc.ClientConn
    Addr  string
}

func NewPool(addr string, maxCap int) *Pool {
    p := new(Pool)
    p.Addr = addr
    p.conns = make(chan *grpc.ClientConn, maxCap)
    conn, err := p.dialNew()
    if err != nil {
        glog.Fatal(err)
        return nil
    }
    p.conns &amp;lt;- conn
    return p
}

func (p *Pool) dialNew() (*grpc.ClientConn, error) {
    return grpc.Dial(p.Addr, grpc.WithInsecure(), grpc.WithInsecure(),
        grpc.WithCodec(&amp;amp;PayloadCodec{}))
}

func (p *Pool) Get() (*grpc.ClientConn, error) {
    select {
    case conn := &amp;lt;-p.conns:
        return conn, nil
    default:
        return p.dialNew()
    }
}

func (p *Pool) Put(conn *grpc.ClientConn) error {
    select {
    case p.conns &amp;lt;- conn:
        return nil
    default:
        return conn.Close()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the proto file with Payload and &lt;code&gt;service&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

package worker;

message Payload {
    bytes Data = 1;
}

service Worker {
    rpc Hello (Payload) returns (Payload) {}
    rpc GetOrAssign (Payload) returns (Payload) {}
    rpc Mutate (Payload) returns (Payload) {}
    rpc ServeTask (Payload) returns (Payload) {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;So, turns out, &lt;code&gt;grpc&lt;/code&gt; not only does custom encoding, but it also leads to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;smaller code footprint.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;net/context&lt;/a&gt;, which in turn allows client to cancel pending rpc requests to servers, among many other benefits.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/trace&#34;&gt;net/trace&lt;/a&gt;, which allows tracing of rpcs and long-lived objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more, read the &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commit/c4629b907702748694712637cbef1fb2c1f15d07&#34;&gt;pull request which made this change&lt;/a&gt; across our code base.
Hope you find this useful.&lt;/p&gt;

&lt;p&gt;Also read:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Research paper on &lt;a href=&#34;https://www.google.com.au/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0ahUKEwipuJ3rjsPNAhWEopQKHeeZBkMQFggiMAE&amp;amp;url=http%3A%2F%2Fresearch.google.com%2Fpeople%2Fjeff%2FBerkeley-Latency-Mar2012.pdf&amp;amp;usg=AFQjCNGnP9v7v9xN93MM6KPVJ7FcML6LvQ&amp;amp;bvm=bv.125596728,d.dGo&#34;&gt;Rapid Response Times&lt;/a&gt; by Jeff Dean.&lt;/li&gt;
&lt;li&gt;Blog post on &lt;a href=&#34;https://blog.golang.org/context&#34;&gt;Go Concurrency Patterns: Context&lt;/a&gt; by Sameer Ajmani.&lt;/li&gt;
&lt;li&gt;Slides on &lt;a href=&#34;https://talks.golang.org/2014/gotham-context.slide#1&#34;&gt;Cancellation, Context and Plumbing&lt;/a&gt; by Sameer Ajmani.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Images courtesy: &lt;a href=&#34;http://www.foxmovies.com/movies/the-martian&#34;&gt;The Martian&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;

</description>
    </item>
    
    <item>
      <title>Can it really scale?</title>
      <link>https://open.dgraph.io/post/performance-throughput-latency/</link>
      <pubDate>Tue, 21 Jun 2016 10:20:32 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/performance-throughput-latency/</guid>
      <description>

&lt;p&gt;In this post, we’ll look at how &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 performs on varying the number of nodes in the cluster, specs of the machine and load on the server to answer the ultimate question: &lt;em&gt;Can it really scale?&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-dataset&#34;&gt;The Dataset&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Freebase&#34;&gt;Freebase&lt;/a&gt; is an online collection of structured data which includes contributions from many sources including individual and user-generated contributions.
Currently, it has &lt;a href=&#34;https://developers.google.com/freebase/&#34;&gt;1.9 Billion RDF N-Triples&lt;/a&gt; worth 250GB of uncompressed data.
On top of that, this dataset is over 95% accurate with a complex and rich real world schema.
It is an ideal data set to test the performance of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
We decided not to use the entire data set as it wasn&amp;rsquo;t necessary for our goal here.&lt;/p&gt;

&lt;p&gt;Given our love for movies, we narrowed it down to the film data.
We ran some scripts and filtered in the movie data only.
All the data and scripts are present in &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data&#34;&gt;our benchmarks repository&lt;/a&gt;.
There are two million nodes, which represent directors, actors, films and all the other objects in the database.
Moreover, 21 million edges (including 4M edges for names) are representing the relationships between actors, films, directors and all the other nodes in the database.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Some interesting information about this data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# film.film --{film.film.starring}--&amp;gt; [mediator] --{film.performance.actor}--&amp;gt; film.actor
# Film --&amp;gt; Mediator
$ zgrep &amp;quot;&amp;lt;film.film.starring&amp;gt;&amp;quot; rdf-films.gz | wc -l
1397647

# Mediator --&amp;gt; Actor
$ zgrep &amp;quot;&amp;lt;film.performance.actor&amp;gt;&amp;quot; rdf-films.gz | wc -l
1396420

# Film --&amp;gt; Director
$ zgrep &amp;quot;&amp;lt;film.film.directed_by&amp;gt;&amp;quot; rdf-films.gz | wc -l
242212

# Director --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.director.film&amp;gt;&amp;quot; rdf-films.gz | wc -l
245274

# Film --&amp;gt; Initial Release Date
$ zgrep &amp;quot;&amp;lt;film.film.initial_release_date&amp;gt;&amp;quot; rdf-films.gz | wc -l
240858

# Film --&amp;gt; Genre
$ zgrep &amp;quot;&amp;lt;film.film.genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
548152

# Genre --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.film_genre.films_in_this_genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
546698

# Generated language names from names freebase rdf data.
$ zcat langnames.gz | awk &#39;{print $1}&#39; | uniq | sort | uniq | wc -l
55

# Total number of countries.
$ zgrep &amp;quot;&amp;lt;film.film.country&amp;gt;&amp;quot; rdf-films.gz | awk &#39;{print $3}&#39; | uniq | sort | uniq | wc -l
304
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;This data set contains information about ~480K actors, ~100K directors and ~240K films.
Some example of entries in the dataset are :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;m.0102j2vq&amp;gt; &amp;lt;film.actor.film&amp;gt; &amp;lt;m.011kyqsq&amp;gt; .
&amp;lt;m.0102xz6t&amp;gt; &amp;lt;film.performance.film&amp;gt; &amp;lt;m.0kv00q&amp;gt; .
&amp;lt;m.050llt&amp;gt; &amp;lt;type.object.name&amp;gt; “Aishwarya Rai Bachchan”@hr .
&amp;lt;m.0bxtg&amp;gt; &amp;lt;type.object.name&amp;gt; “Tom Hanks”@es .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Throughput: Number of queries served by the server per second and received by the client&lt;/li&gt;
&lt;li&gt;Latency: Difference between the time when the server received the request and the time it finished processing the request&lt;/li&gt;
&lt;li&gt;95 percentile latency: The worst case latency which 95 percentage of users that query the database face&lt;/li&gt;
&lt;li&gt;50 percentile latency: The worst case latency which half the users that query the database face&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;All the testing was done on GCE instances. Each machine had 30GB of SSD and at least 7.5 GB of RAM. The number of cores varied depending on the experiments performed.&lt;/p&gt;

&lt;p&gt;The tests were run for 1-minute intervals during which all the parallel connections made requests to the database.
This was repeated ten times and throughput, mean latency, 95th percentile latency, 50th percentile latency were measured.
Note that for user-facing systems, measuring percentile latency is better than mean latency as the average can be skewed by outliers.&lt;/p&gt;

&lt;p&gt;In a multi-node cluster set up, the queries were distributed among each node in a round-robin fashion.
Note that no single machine contains all the data to answer these queries, in a multi-node cluster.
They still have to communicate with each other to respond to the queries.&lt;/p&gt;

&lt;h2 id=&#34;variables&#34;&gt;Variables&lt;/h2&gt;

&lt;p&gt;The parameters that were varied were:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A number of parallel connections to the database. In Go, this equated to the number of goroutines a client would have. Each goroutine would run in an infinite loop, querying the database via a blocking function.&lt;/li&gt;
&lt;li&gt;Number of cores per server&lt;/li&gt;
&lt;li&gt;Number of servers in the cluster&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This gave us an idea of what to expect from the system and would help in predicting the configuration required to handle a given load.&lt;/p&gt;

&lt;h2 id=&#34;queries&#34;&gt;Queries&lt;/h2&gt;

&lt;p&gt;We ran broadly 2 categories of queries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For each actor (478,936 actors), get their name, the films they acted in, and those films&amp;rsquo; names.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.actor.film {
      film.performance.film {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;For each director (90,063 directors), get their name, the films they directed, and names of all the genres of those films.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.director.film {
      film.film.genre {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;During each iteration, either an actor or a director category was chosen randomly.
Furthermore, for that category, an actor or director was chosen randomly; their &lt;code&gt;XID&lt;/code&gt; filled in in the query template.&lt;/p&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;Let us look at some graphs obtained by varying the machine specs and the number of nodes in the cluster under different loads.&lt;/p&gt;

&lt;h3 id=&#34;vary-the-number-of-cores-in-a-single-instance&#34;&gt;Vary the number of cores in a single instance&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_thru.jpg&#34; alt=&#34;Throughput on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;With the same number of cores, when we increase the number of connections, i.e. load on the system, the throughput as well as the latency increase.&lt;/li&gt;
&lt;li&gt;Throughput increases till some point and then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;As expected, the latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;When we increase the number of cores, the latency decreases and the throughput increases.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vary-number-of-instances&#34;&gt;Vary number of instances&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/topo_thru.jpg&#34; alt=&#34;Throughput on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When we increase the number of parallel connections, the throughput increases, but then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;The latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;Latency in the case of a single instance is observed to be the equal to (or a bit lower than) that of distributed configurations as the former doesn’t require any network calls. However, as the number of requests/load increase, the cumulative computational power comes into play and overshadows the latency incurred due to network calls. Hence, the latency reduces in the distributed version under higher loads.&lt;/li&gt;
&lt;li&gt;On comparing across the one, two and five node clusters, we can see that the latency, as well as the throughput, are better for configurations with a higher number of nodes, i.e., when there is more computational capacity at disposal. The throughput increases as we have greater computational power and can handle more queries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;From the above experiments, we can see a relationship between the throughput, latency and the overall computational power of the cluster.
The graphs show that the throughput increases as the computational power increases.
Which can be achieved either by increasing the number of cores on each server or the number of nodes in the cluster.&lt;/p&gt;

&lt;p&gt;The latency increases as the amount of load on the database increases.
However, the rate of the increase differs based on how much computational power we have available.&lt;/p&gt;

&lt;p&gt;This experiment also shows that there is a limit on how much computational power a single node can have, and once we reach that limit, scaling horizontally is the right option.
Not only that, but it also proves that scaling horizontally improves the performance.
Hence, having more replicas, distributing the dataset optimally across machines are some factors which help in improving the throughput and reducing the latency that the users face.&lt;/p&gt;

&lt;p&gt;Based on this experiment, our recommendation for running &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 would be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use as many cores as possible&lt;/li&gt;
&lt;li&gt;Have the servers geographically close-by so that network latency is reduced&lt;/li&gt;
&lt;li&gt;Distribute the data among servers and query them in a round-robin fashion for greater throughput&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These might seem pretty obvious recommendations for a distributed system, but &lt;strong&gt;this experiment proves that the underlying design of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is scalable.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hope this helps you get a sense of what sort of performance you could expect out of Dgraph!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is derived from my report for B.tech Project on “A Distributed Implementation of the Graph Database System, Dgraph”.
The full report is &lt;a href=&#34;https://www.dropbox.com/s/7h4ytak39r2pdun/Ashwin_Thesis.pdf?dl=0&#34;&gt;available for download here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://mars.nasa.gov/images/PIA14840.jpg&#34;&gt;Mars Rover Landing via Nasa&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Wisemonk: A slackbot to move discussions from Slack to Discourse</title>
      <link>https://open.dgraph.io/post/wisemonk/</link>
      <pubDate>Wed, 15 Jun 2016 11:39:27 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/wisemonk/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;Then there was the fact that we had so many channels and direct messages and group chats.
It multiplexed my brain and left me in a constant state of anxiety, feeling that I needed to always be on guard.
&lt;em&gt;— &lt;a href=&#34;https://blog.agilebits.com/2016/04/19/curing-our-slack-addiction/&#34;&gt;Dave Teare, Curing Our Slack Addiction&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;the-beginning&#34;&gt;The Beginning&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;— Manish Jain&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Sitting in a Japanese restaurant, waiting for my lunch, this is the line that hit me hard.
I’d experienced this exact thing in my previous company.&lt;/p&gt;

&lt;p&gt;Every block of time dedicated to coding was either interrupted by pings on the chat system, or a consistent feeling that you’re missing out.
Away from the desk, phones would start ringing every evening.
And they’d ring some more on the weekends, Sunday evenings in particular.
We were always doing something — the feeling was like being on &lt;em&gt;unpaid pager duty&lt;/em&gt;.
People are talking, and if I’m not around to show my presence, it would mean I’m not working.
But what was getting done, I wasn’t so clear about.&lt;/p&gt;

&lt;p&gt;So, when we started exploring options for both internal and external communication for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we wanted to do things differently.
We’d focus on asynchronous communication, so people can take their time before jumping in.
People can reply when they get to it — this might be hours later.
And there’ll be an incentive to modify your reply as more things become clear to you or you find better words to express yourself.
Something better than Email, but not so distracting as Slack.
The winner came out to be Discourse by Jeff Atwood and his team(edit: not Discord, another chat app).&lt;/p&gt;

&lt;p&gt;Having run it for over two months, we couldn’t have been happier.
Discourse sits somewhere between emails and real-time chat systems.
You feel like you’re having a real-time conversation.
But it won’t interrupt you in the middle of a 3-hour block of time you’ve set for distraction-free coding.
Discourse has become such an integral part of our company that we abandoned making decisions in meetings entirely.
All decisions happen over discourse, so everyone has a chance to voice their opinions and suggestions at their pace.
And others can embark on fact-finding and put figures together to support or deny arguments.
I’ve seen a lot smarter discussions, and hence decisions happening over our Discourse forum than over any other medium.&lt;/p&gt;

&lt;p&gt;Don’t get me wrong.
&lt;strong&gt;We still need Slack&lt;/strong&gt; for casual chit chat and team bonding.
But, Slack is an addiction.
You write one thing, someone replies; then someone else jumps in; and the result is an hour-long frenzy, where everyone feels like they’ve contributed a lot.
But a few hours later, you can’t pinpoint what changed.&lt;/p&gt;

&lt;p&gt;Most useful discussions require a bit more time and thought.
More than when someone else is typing while you’re in the middle of your sentence.&lt;/p&gt;

&lt;p&gt;This is what lead to Wisemonk.
This bot would push the conversation away from Slack into Discourse.
And this has to happen just when the team is getting sucked into the frenzy.
&lt;strong&gt;Before it’s too late&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;how-we-built-it&#34;&gt;How we built it&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;— Pawan Rawal&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Wisemonk makes use of the Slack RTM API.
We make good use of the concurrency features in Go.
For each Slack channel passed in channels flag, we initialise an instance of type Counter.
The counter keeps track of the messages and other states for a Slack channel.
Each counter has a buffered channel (called &lt;code&gt;messages&lt;/code&gt;) to which Slack messages are sent.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cmap := make(map[string]*Counter)
for _, cid := range schannels {
  wg.Add(1)
  c := &amp;amp;Counter{channelId: cid}
  c.messages = make(chan *slack.Msg, 500)
  cmap[cid] = c
  go c.checkOrIncr(rtm, wg, memmap)
}
go listen(rtm)
wg.Wait()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The listen function which runs as a goroutine gives us access to the messages sent on Slack.
We use this library to authenticate with and get messages from Slack.
Then the listen function passes messages on the relevant Go channel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case *slack.MessageEvent:
  if sm, ok := msg.Data.(*slack.MessageEvent); ok {
  // Putting the message on the Counter it belongs to
  m := sm.Msg
  if c, ok := cmap[m.Channel]; ok {
    c.messages &amp;lt;- &amp;amp;m
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;checkOrIncr&lt;/code&gt; method which runs as a goroutine for every counter keeps a count of the number of messages exchanged in a given interval.
Below is the basic version of the method.
It runs a never ending &lt;code&gt;for&lt;/code&gt; loop.
Now every time a message is received on the messages channel of the counter instance, it adds the message.
NewTicker function from the time package provides us with a Ticker, which sends the time on a channel with the period specified.
So every 10 seconds we get a time value and check if the count of messages exchanged increases the &lt;code&gt;maxmsg&lt;/code&gt; that we passed as a flag.
If it does, then we send a warning to the relevant Slack channel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Counter) checkOrIncr(rtm *slack.RTM, wg sync.WaitGroup, memmap map[string]string) {
   defer wg.Done()
   ticker := time.NewTicker(time.Second * 10)
   for {
       select {
       case msg := &amp;lt;-c.messages:
           c.Increment(msg, memmap)
       case &amp;lt;-ticker.C:
           count := c.Count()
           if count &amp;gt;= *maxmsg {
               go sendMessage(c, rtm)
           }
       }
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the basic functionality was in place, we added integration with discourse.
Wisemonk stores the last n messages exchanged, creates a discourse topic with the messages when they exceed the max count and shares the URL with us on Slack.&lt;/p&gt;

&lt;p&gt;You can create a discourse topic on demand too and get the URL for it. This makes shifting conversations to Discourse super easy.&lt;/p&gt;

&lt;p&gt;For the weekends or in the evenings when you want to have a casual chat and don’t want to be interrupted by Wisemonk, you could ask him to meditate, and it won’t disturb you for a while.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;wisemonk-in-action&#34;&gt;Wisemonk in Action&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-in-action.png&#34; alt=&#34;Wisemonk alerting us when we talk too much&#34; /&gt;
&lt;em&gt;Wisemonk alerting us when we talk too much&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-creating-topic.png&#34; alt=&#34;Asking wisemonk to create a topic&#34; /&gt;
&lt;em&gt;Asking wisemonk to create a topic&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-meditating.png&#34; alt=&#34;Asking wisemonk to meditate&#34; /&gt;
&lt;em&gt;Asking wisemonk to meditate&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;parting-thoughts&#34;&gt;Parting Thoughts&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/wisemonk#install&#34;&gt;Setting up wisemonk&lt;/a&gt; is super easy and we have found that it has enhanced our productivity a lot.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s open source and &lt;a href=&#34;https://github.com/dgraph-io/wisemonk&#34;&gt;available at Github&lt;/a&gt;, so feel free to contribute to it. We would love to hear about your usage of Wisemonk.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Yoda guides actions. Wisemonk guides conversations. Image courtesy: &lt;a href=&#34;http://www.wired.com/wp-content/uploads/2015/08/Yoda-featured1.jpg&#34;&gt;wired.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;

</description>
    </item>
    
    <item>
      <title>Hello, World!</title>
      <link>https://open.dgraph.io/post/hello-world/</link>
      <pubDate>Mon, 18 Apr 2016 14:37:08 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/hello-world/</guid>
      <description>&lt;p&gt;&lt;strong&gt;I&amp;rsquo;m very excited&lt;/strong&gt; to use this first post to talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, what it is and why it was created.&lt;/p&gt;

&lt;p&gt;Before I explain what&amp;rsquo;s &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, let&amp;rsquo;s start with a basic understanding of graphs.
A graph is a mathematical structure used to model a pairwise relationship between entities.
A graph is thus composed of nodes connected by edges.
Each node represents an entity (a person, place, thing, etc.), and each edge represents the relationship between two nodes.
Some popular graphs that we all know about are the &lt;a href=&#34;https://en.wikipedia.org/wiki/Social_graph&#34;&gt;Facebook Social Graph&lt;/a&gt; and the &lt;a href=&#34;https://en.wikipedia.org/wiki/Knowledge_Graph&#34;&gt;Google Knowledge Graph&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A graph database is a database that uses graph structures with nodes and edges to represent, store and serve data.&lt;/p&gt;

&lt;p&gt;But who really uses graph databases? More teams and companies than you&amp;rsquo;d think.
Google, Facebook, Twitter, eBay, LinkedIn, Amazon, Dropbox, Pinterest &amp;ndash; pick a company you are familiar with.
If they&amp;rsquo;re doing something smart, chances are they&amp;rsquo;re probably using a graph database.
Even very simple web apps have much to gain from graph databases.
In the past, I&amp;rsquo;ve built a graph based REST framework and using that &lt;a href=&#34;https://mrjn.xyz/post/Porting-To-Gocrud/&#34;&gt;cut down the code in half&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So now that we understand graphs, let&amp;rsquo;s talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is an open source, low-latency, high throughput, native and distributed graph database.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To understand why it was created, let&amp;rsquo;s rewind a few years back to 2011.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;I&amp;rsquo;d been at Google&lt;/strong&gt; about 4+ years with the Web Search Infrastructure Group.
Google had just then acquired Metaweb a year earlier in 2010.
I&amp;rsquo;d been wrapping my head around the newly acquired Knowledge Graph, trying to find ways to integrate Knowledge Graph with Google Search.
This is when I found a problem.&lt;/p&gt;

&lt;p&gt;At Google, we had multiple knowledge bearing feeds called One Boxes.
You know, the boxed snippets that sometimes show up at the top of the search results, for instance when you search for &lt;a href=&#34;https://www.google.com/#q=tesla+stock&#34;&gt;Tesla stock&lt;/a&gt;, &lt;a href=&#34;https://www.google.com/#q=weather+in+sydney&#34;&gt;Weather in Sydney&lt;/a&gt;, or &lt;a href=&#34;https://www.google.com/#q=events+in+san+francisco&#34;&gt;Events in San Francisco&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There were multiple custom built backends, each serving a One Box.
A search query hitting &lt;em&gt;&lt;a href=&#34;https://www.google.com&#34;&gt;www.google.com&lt;/a&gt;&lt;/em&gt; would be sent iteratively through each of these One Box backends to check if any of them has a response.
When one of the backends responds, the One Box data is retrieved and rendered on the top of the search results page.
This is how that well-formatted box with just the right information shows up below the search bar, thus saving you a few clicks.&lt;/p&gt;

&lt;p&gt;As good as it sounded, One Boxes had several inefficiencies and missed opportunities.&lt;/p&gt;

&lt;p&gt;For starters, each One Box was custom built by a separate team that was responsible for running and maintaining it.
As a result, there was no particular sharing of the framework used to build the One Box.&lt;/p&gt;

&lt;p&gt;This also meant that there was no single standard for the data format used by the One Boxes.
Each One Box kept its data in its very own data structure, and no common querying language.
Thus, there didn&amp;rsquo;t exist an opportunity to share data amongst the boxes, to respond to more interesting queries that required an intersection of diverse data feeds.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A good example of this would be the ability to &lt;em&gt;recommend events based on the weather&lt;/em&gt; to a tourist exploring NYC &amp;ndash; that couldn&amp;rsquo;t easily be done with the existing system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/nyc.jpg&#34; alt=&#34;NYC in rain&#34; /&gt;
&lt;em&gt;Courtesy: &lt;a href=&#34;https://flic.kr/p/azztBd&#34;&gt;Several Seconds&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This motivated me to start a project to standardize the data structures and eventually serve them all using a single backend.
Using the vast expertise of Metaweb team, we chose a data normalization structure that was also used by Knowledge Graph, the RDF Triples.
By reconciling all the various entities from the different data feeds, we could start to reuse the data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;But, there was a second and more challenging part to the problem.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It was to build a system that could serve structured queries with data updating in real time.
The system had to run behind Web Search, which meant that if it doesn&amp;rsquo;t respond within allocated milliseconds, Search would time out and move on.
Also, this system had to tackle a major chunk of query load to Web Search, which amounts to thousands of queries per second.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;We basically had to build a low latency, high throughput system to serve graph queries.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It was certainly an exciting project and held much promise.
But, the harsh realities of the business environment and the attendant politics resulted in the cancellation of the project.
Shortly thereafter I left Google in 2013 and didn&amp;rsquo;t give much thought to the project.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;Fast forward two years,&lt;/strong&gt; I was hanging out on the Go language&amp;rsquo;s Slack channel and Stack Overflow.
I saw quite a few people complaining about a popular graph database&amp;rsquo;s performance and stability.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s when I realized that graph databases were starting to be used more frequently than it would appear from the surface.
But a bit more digging around revealed a deeper problem.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Existing native graph databases weren&amp;rsquo;t designed to be performant or distributed.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The ones that sharded the data and distributed it across a cluster weren&amp;rsquo;t actually native graph databases.
They were largely serving as a graph layer over another database.
This meant having many network calls should the intermediate number of results be large, which leads to performance degradation.&lt;/p&gt;

&lt;p&gt;For example, say you wanted to find &lt;strong&gt;[People living in SF who eat Sushi]&lt;/strong&gt;.
Assuming you have this data (&lt;em&gt;hey Facebook!&lt;/em&gt;) and keeping things simple, this requires 2 steps.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/sushi.jpg&#34; alt=&#34;Sushi&#34; /&gt;
&lt;em&gt;Courtesy: &lt;a href=&#34;https://flic.kr/p/nLkbkQ&#34;&gt;Yannig Van de Wouwer&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First, you find all the people living in SF, and then secondly, intersect that list with all the people who eat Sushi.&lt;/p&gt;

&lt;p&gt;As you can imagine, the intermediate step here has a &lt;em&gt;large fan-out&lt;/em&gt;, i.e. there&amp;rsquo;re over a million results.
If you were to shard the data by &lt;em&gt;entities&lt;/em&gt; (people), you&amp;rsquo;d end up broadcasting to all the servers in the cluster.
Thus, this query would be affected by even a single slow machine in the cluster.&lt;/p&gt;

&lt;p&gt;Do that for every query, and it would spike the 95%-ile latency numbers up dramatically, &lt;em&gt;higher latency being worse&lt;/em&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, on the other hand, is a native graph database&lt;/strong&gt; in the sense that the data is handled directly by &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, and not given off to another database layer.&lt;/p&gt;

&lt;p&gt;This allows us to shard and relocate the data better, to minimize the number of network calls required per query.
In fact, the above query would run in 2 network calls, irrespective of the cluster size.&lt;/p&gt;

&lt;p&gt;The number of network calls being &lt;em&gt;directly proportional to the complexity of the query&lt;/em&gt;, not the number of intermediate or final results.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is designed to easily scale from meeting the needs of a small startup to that of Dropbox, or even Facebook.
This means being able to run on a laptop as well as on a big cluster of hundreds of machines serving thousands of queries per second.&lt;/p&gt;

&lt;p&gt;Additionally, it would also have to survive machine failures and partial data center collapses.
The data stored would have to be automatically replicated with no single point of failure, and be able to move around the cluster to better distribute traffic.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is the big vision which led to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/strong&gt; And I&amp;rsquo;m &lt;a href=&#34;http://dgraph.io/&#34;&gt;fortunate to have a team&lt;/a&gt; that believes in and shares this vision with me.&lt;/p&gt;

&lt;p&gt;Apart from use with diverse social and knowledge graphs, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can also be used to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;build real-time recommendation engines,&lt;/li&gt;
&lt;li&gt;do semantic search,&lt;/li&gt;
&lt;li&gt;pattern matching,&lt;/li&gt;
&lt;li&gt;serve relationship data, and&lt;/li&gt;
&lt;li&gt;serve web apps via &lt;a href=&#34;https://facebook.github.io/graphql/&#34;&gt;GraphQL&lt;/a&gt;, a full feature graph query language by Facebook.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We&amp;rsquo;ll be reporting some performance numbers for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 in our next few posts, to give you an idea of what you can expect from the system.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
  &lt;p&gt;We are building a distributed graph database designed for production environment.&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;p&gt;&lt;strong&gt;Does your product have over a million users? Are you interested in trying out Dgraph? &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;. If selected, we&amp;rsquo;ll set up a Dgraph cluster, run and maintain it for you free of charge.&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://go.nasa.gov/1VlGVXx&#34;&gt;Mars Rover Curiosity in Buckskin Selfie&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>