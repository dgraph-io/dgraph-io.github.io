<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Dgraph Blog</title>
    <link>https://blog.dgraph.io/post/index.xml</link>
    <description>Recent content in Posts on Dgraph Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2017, Dgraph Labs, Inc. All rights reserved.</copyright>
    <lastBuildDate>Mon, 14 Aug 2017 13:21:25 +1000</lastBuildDate>
    <atom:link href="https://blog.dgraph.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Making Badger Crash Resilient with ALICE</title>
      <link>https://blog.dgraph.io/post/alice/</link>
      <pubDate>Mon, 14 Aug 2017 13:21:25 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/alice/</guid>
      <description>

&lt;p&gt;Crashes can occur for many different reasons and can manifest themselves in
many different forms. A program can experience a segfault or uncaught
exception.  If it&amp;rsquo;s running on Linux, a kernel panic could occur.  If on
Windows, a STOP error could occur, displaying the infamous
&lt;a href=&#34;https://en.wikipedia.org/wiki/Blue_Screen_of_Death&#34;&gt;BSOD&lt;/a&gt;.  Even then, crashes
aren&amp;rsquo;t the only thing you have to worry about. The UPS could fail (or be
absent), or the power could go out.  Someone could be walking through the data
center and trip over a power cord.  In short, any program can terminate
prematurely and unexpectedly.&lt;/p&gt;

&lt;p&gt;When a database crashes, what happens to your data? If your database has a high
level of crash resilience, your data is safe. The database can be started up
again, and you&amp;rsquo;re pretty much good to go. You might have to rerun the last few
mutations you made before the crash, but for the most part, your data is still
intact. But what about databases with low levels of crash resilience? I &lt;em&gt;hope&lt;/em&gt;
you make regular backups, because your database might not even start up.&lt;/p&gt;

&lt;p&gt;At Dgraph Labs, current efforts are being spent ramping up towards a 1.0
version of our flagship product, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt;.
&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; is already very stable, but we
want to go the extra mile and make it robust and rock solid, even under rare
and unlikely scenarios.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; relies on
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (our key value store) to persist
its data. This is an obvious place to look when it comes to making the whole
system resilient against crashes.  This blog post will explore the area of
crash resilience. It will look at a tool called ALICE, and how we used it to
improve the crash resilience of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; contains a write ahead value log,
which is replayed when &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up.
You can read more about the internals of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;
&lt;a href=&#34;https://open.dgraph.io/post/badger/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The design of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is based on a paper
titled &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WiscKey: Separating Keys from Values in SSD-conscious
Storage&lt;/a&gt;.
This paper discusses a property of modern file systems that aids in creating
crash resilient systems:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;[There is] an interesting property of modern file systems (such as ext4,
btrfs, and xfs). &amp;hellip;  Consider a file that contains [a] sequence of bytes &amp;hellip;
and the user appends &amp;hellip; to it. If a crash happens, &amp;hellip; only some prefix of the
appended bytes will be added to the end of the file. &amp;hellip; It is not possible for
random bytes or a non-prefix subset of the appended bytes to be added to the
file.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We wanted to use this interesting file system property to improve
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.  Specifically, to increase the
crash resilience of the value log.&lt;/p&gt;

&lt;p&gt;We decided to add an entry checksum to each value log entry. The idea was that
this would enable us to detect short appends during log file replay so that we
could truncate the value log at the end of the last good entry and continue
with the normal start up procedure.&lt;/p&gt;

&lt;p&gt;This task was one of the &lt;a href=&#34;https://github.com/dgraph-io/badger/pull/148&#34;&gt;first things that I worked
on&lt;/a&gt; when I started at Dgraph Labs
a couple of weeks ago.&lt;/p&gt;

&lt;h2 id=&#34;enter-alice&#34;&gt;Enter ALICE&lt;/h2&gt;

&lt;p&gt;After adding checksums to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, I
started looking at papers from the same authors as the WiscKey paper. I came a
cross a paper titled &lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;All File Systems Are Not Created Equal&lt;/a&gt;: On the Complexity
of Crafting Crash-Consistent
Applications.
This paper describes a &lt;a href=&#34;https://github.com/madthanu/alice&#34;&gt;tool called ALICE&lt;/a&gt;
(Application-Level Intelligent Crash Explorer), written by the authors.  ALICE
discovers crash vulnerabilities in programs. A crash vulnerability is a bug in a
program that manifests itself when the program starts up after a system crash.
The main use of ALICE is to help programmers make their programs more robust and
resilient to crashes. ALICE will be explained in greater detail later in this
blog post.&lt;/p&gt;

&lt;p&gt;ALICE helped identify two different crash vulnerabilities in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; and even hinted towards how those
vulnerabilities could be fixed. Despite having minimal experience with the
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; code base, I was able to identify
and implement those fixes.  This is a testament to the usefulness of ALICE as a
tool (although the simplicity of the
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; codebase helped a lot here!).&lt;/p&gt;

&lt;p&gt;I learned a lot about file systems and Linux system calls while working with
ALICE. Some things I already intuitively knew, but other things were totally
surprising.&lt;/p&gt;

&lt;h2 id=&#34;what-could-go-wrong-when-you-modify-a-file&#34;&gt;What could go wrong when you modify a file?&lt;/h2&gt;

&lt;p&gt;Say you have a file named &lt;code&gt;f&lt;/code&gt; on disk. It contains the sequence of bytes &lt;code&gt;ABC&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;You then have a C program that operates on the file. The intent of the file is
to change the content to &lt;code&gt;12345&lt;/code&gt;. The program isn&amp;rsquo;t crash resilient though;
under certain crash scenarios, the file could end up having content &lt;em&gt;other&lt;/em&gt;
than &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;f&amp;quot;, O_RDWR | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 close(fd);
# Boilerplate and error checking left out for brevity.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So if the program crashes part way through, what possible states could the file
&lt;code&gt;f&lt;/code&gt; be in? For each of the following possible states, think about whether the
state is possible or not.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;12345&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is now empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;123&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC$9&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Take a few seconds and think about the possible states before reading on.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Alright! Let&amp;rsquo;s go through the possibility of the states.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;States 1 and 2&lt;/strong&gt; are not only possible, they&amp;rsquo;re intended. They&amp;rsquo;re the only
allowable states if the program is to be 100% resilient to crashes. State 1 can
occur if the program crashes before opening the file. State 2 can occur if the
crash occurs after the close.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 3&lt;/strong&gt; is possible. It can occur if the program crashes after the call to
&lt;code&gt;open&lt;/code&gt; but before the &lt;code&gt;write&lt;/code&gt; call is persisted to disk. Note that the
&lt;code&gt;O_TRUNC&lt;/code&gt; flag truncates the file to zero length when the file is opened.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 4&lt;/strong&gt; is not possible. The file &lt;code&gt;f&lt;/code&gt; will always exist on disk in some form.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 5&lt;/strong&gt; is possible. Writes are not atomic and can be batched up in arbitrary
sized chunks (although the size is usually much larger than a few bytes).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 6&lt;/strong&gt; is a strange case, but surprisingly, possible! How does that
happen? It appears as though garbage data was appended to the file!&lt;/p&gt;

&lt;p&gt;This disk state is possible because writes are sometimes executed as two
parallel operations.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The data content is written.&lt;/li&gt;
&lt;li&gt;The size of the file is updated.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If a crash occurs at precisely the wrong time, the change to the file size may
be persisted to disk without the additional data being written.&lt;/p&gt;

&lt;p&gt;This even happens in modern file systems such as &lt;em&gt;ext4&lt;/em&gt; (although only in
writeback mode). So if you&amp;rsquo;re the author of a program that writes to files and
you care about crash resilience, this is something you should design your
program around.&lt;/p&gt;

&lt;p&gt;So how can we get around these problems? A common idiom is to create a
temporary file, write the new content to it, then rename it to the old file.
&lt;strong&gt;But&amp;hellip;&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;what-could-go-wrong-when-you-rename-a-file&#34;&gt;What could go wrong when you rename a file?&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 close(fd);
04 rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are some crash states where the
file &lt;code&gt;f&lt;/code&gt; contains content other than &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;. Below are the same set
crash states as before. Again, think about whether each crash
state is possible or not.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;12345&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is now empty.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;123&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; contains &lt;code&gt;ABC$9&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Pause for a moment to consider the possible states before reading on.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Okay! Let&amp;rsquo;s go through the different possibilities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;States 1 and 2&lt;/strong&gt; are still possible. That&amp;rsquo;s good, it means we don&amp;rsquo;t have a
regression.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 3&lt;/strong&gt; is still possible. It can occur when &lt;code&gt;rename&lt;/code&gt; on line 4 persists to
disk before the &lt;code&gt;write&lt;/code&gt; on line 2 (and the crash occurs before the write
persists). The calls to &lt;code&gt;write&lt;/code&gt; and &lt;code&gt;rename&lt;/code&gt; are not guaranteed to persist in
order.&lt;/p&gt;

&lt;p&gt;Notably, the &lt;code&gt;close&lt;/code&gt; &lt;em&gt;doesn&amp;rsquo;t force the file contents to be persisted to disk.&lt;/em&gt;
There is a common misconception among programmers that closing a file flushes
to disk, but this is not true.  This is the behaviour for C as well as some
higher level languages such as &lt;a href=&#34;https://golang.org/pkg/os/#File&#34;&gt;Go&lt;/a&gt; and
&lt;a href=&#34;https://docs.python.org/2/library/stdtypes.html#file-objects&#34;&gt;Python&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;From the &lt;a href=&#34;https://linux.die.net/man/2/close&#34;&gt;man page&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A successful close does not guarantee that the data has been successfully saved
to disk, as the kernel defers writes. It is not common for a file system to
flush the buffers when the stream is closed. If you need to be sure that the
data is physically stored use fsync(2). (It will depend on the disk hardware at
this point.)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 4&lt;/strong&gt; is not possible. This is because &lt;code&gt;rename&lt;/code&gt; is atomic, so there will
never be a case where &lt;code&gt;f&lt;/code&gt; is missing from disk.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 5&lt;/strong&gt; is possible; after crashing the file may contain only &lt;code&gt;123&lt;/code&gt;. The first
part of the &lt;code&gt;write&lt;/code&gt; on line 2 could persist, then the file could be renamed. If
the crash occurs before the final part of the &lt;code&gt;write&lt;/code&gt; persists, then &lt;code&gt;123&lt;/code&gt; would
be the result.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;State 6&lt;/strong&gt; could also occur. This is similar to state 5. The rename may be
persisted before the write. The write may only partially persist before the
crash, leaving the file size updated without the data being written.&lt;/p&gt;

&lt;p&gt;Notice that the set of bad crash states is the same as before&amp;hellip;  So in a
certain sense, the program has become more complicated but can still break in
the same ways. &lt;em&gt;Not to fear though,&lt;/em&gt; with one small tweak we can fix everything!&lt;/p&gt;

&lt;p&gt;We need one more system call to fix the program. Remember how &lt;code&gt;close&lt;/code&gt; doesn&amp;rsquo;t
flush the file content to disk? The man page gave an important hint, &lt;code&gt;fsync&lt;/code&gt;!&lt;/p&gt;

&lt;h2 id=&#34;sync-as-a-solution&#34;&gt;Sync as a solution&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;fsync&lt;/code&gt; flushes all pending &lt;code&gt;write&lt;/code&gt;s through any buffers and persists them to
physical disk. It&amp;rsquo;s a blocking call, and doesn&amp;rsquo;t return until the data is
completely persisted.  There are equivalents in higher level languages. In Go
it&amp;rsquo;s &lt;a href=&#34;https://golang.org/pkg/os/#File.Sync&#34;&gt;File.Sync&lt;/a&gt;, and in Python it&amp;rsquo;s
&lt;a href=&#34;https://golang.org/pkg/os/#File.Sync&#34;&gt;os.fsync&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So how does it help? Let&amp;rsquo;s alter the program again. It&amp;rsquo;s the same as before,
except that we use &lt;code&gt;fsync&lt;/code&gt; after the write.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;01 int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0644);
02 write(fd, &amp;quot;12345&amp;quot;, 5);
03 fsync(fd);
04 close(fd);
05 rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we&amp;rsquo;re getting somewhere! The temp file is created and has &lt;code&gt;12345&lt;/code&gt; written
to it. The sync causes the data to be persisted to disk. Only then is the file
renamed. The file &lt;code&gt;f&lt;/code&gt; cannot end up empty since the &lt;code&gt;write&lt;/code&gt; now &lt;em&gt;has to&lt;/em&gt;
persist before the &lt;code&gt;rename&lt;/code&gt;. For the same reason, the file can&amp;rsquo;t end up with
&lt;code&gt;123&lt;/code&gt; or &lt;code&gt;ABC$9&lt;/code&gt;. No matter how the program crashes, &lt;code&gt;f&lt;/code&gt; will always either
contain &lt;code&gt;ABC&lt;/code&gt; or &lt;code&gt;12345&lt;/code&gt;. Neat!&lt;/p&gt;

&lt;h2 id=&#34;back-to-alice&#34;&gt;Back to ALICE&lt;/h2&gt;

&lt;p&gt;In simple programs like the ones above, it&amp;rsquo;s &lt;em&gt;possible&lt;/em&gt; to identify and fix
crash resilience problems manually, &lt;em&gt;so long as you understand all of the
limitations and guarantees that file systems provide&lt;/em&gt;. For large programs like
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, it&amp;rsquo;s much more difficult.
Luckily, the process becomes easier with the aid of tooling.&lt;/p&gt;

&lt;p&gt;ALICE is one such tool that can help find crash vulnerabilities. You still need
to understand the limitations and guarantees of the file system to use the
tool, but it &lt;em&gt;does&lt;/em&gt; do most of the heavy lifting when it comes to the
identification of problems.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;So how does it work?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;ALICE works by executing a &lt;em&gt;workload&lt;/em&gt; (supplied by the user). This starts up
the application-under-test and makes it perform various operations.  ALICE
records the system calls made by the program, including the details of all file
system manipulations.  Using the record of those system calls, it is able to
create all of the possible crash states that could occur. To do this, it takes
into consideration all of the legal reorderings of the file system
manipulations made by the program-under-test. For each crash states,
ALICE runs a &lt;em&gt;checker&lt;/em&gt; (also supplied by the user).  The checker tests to see
if the crash state is permissible i.e. the program-under-test can start up,
recover from the crash, and continue from where it left off.&lt;/p&gt;

&lt;p&gt;So what does this look like for the &lt;code&gt;ABC&lt;/code&gt; -&amp;gt; &lt;code&gt;12345&lt;/code&gt; example?&lt;/p&gt;

&lt;p&gt;The workload is just the program that changes the content of the file (we start
with the &lt;em&gt;incorrect&lt;/em&gt; attempt at the program):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main()
{
    int fd = open(&amp;quot;f&amp;quot;, O_RDWR | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5);            // assert(ret == 5);
    ret = close(fd);                            // assert(ret == 0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What about the checker? It simply checks the consistency constraints that we
expect the program to maintain. It can be written in any language, e.g. Python:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import os
import sys

crashed_state_directory = sys.argv[1]
os.chdir(crashed_state_directory)
assert open(&#39;f&#39;).read() in [&#39;ABC&#39;, &#39;12345&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When ALICE is run, its output indicates that there are some crash
vulnerabilities:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_before_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The output indicates that there is a problem if the file is truncated, but
&lt;em&gt;not&lt;/em&gt; appended to.&lt;/p&gt;

&lt;p&gt;When we run the second version of the program, we get a different report from
ALICE.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main() {
    int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5); // assert(ret == 5);
    ret = close(fd);                 // assert(ret == 0);
    ret = rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);        // assert(ret == 0);
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_intermediate_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This time, ALICE indicates that the ordering of system calls is not guaranteed.
Specifically, the rename may persist before the append.&lt;/p&gt;

&lt;p&gt;Once the problem with the program is fixed (the &lt;code&gt;fsync&lt;/code&gt; call added), ALICE
reports that there are no errors:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;int main() {
    int fd = open(&amp;quot;tmp&amp;quot;, O_RDWR | O_CREAT | O_TRUNC, 0666); // assert(fd &amp;gt; 0);
    int ret = write(fd, &amp;quot;12345&amp;quot;, 5); // assert(ret == 5);
    ret = fsync(fd);                 // assert(ret == 0);
    ret = close(fd);                 // assert(ret == 0);
    ret = rename(&amp;quot;tmp&amp;quot;, &amp;quot;f&amp;quot;);        // assert(ret == 0);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_final_toy.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Excellent! The program is now free of crash vulnerabilities.&lt;/p&gt;

&lt;p&gt;As part of their
&lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;research&lt;/a&gt;, the
authors of ALICE checked various key value stores and databases for crash
vulnerabilities. We decided to put
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; through the same paces. There
were two main motivations for this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To see how &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; stacks up against
other existing key value stores.&lt;/li&gt;
&lt;li&gt;To find (&lt;em&gt;and fix!&lt;/em&gt;) any crash vulnerabilities in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;testing-badger-with-alice&#34;&gt;Testing Badger with ALICE&lt;/h2&gt;

&lt;p&gt;The
&lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/workload/workload.go&#34;&gt;workload&lt;/a&gt;
and
&lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/checker/checker.go&#34;&gt;checker&lt;/a&gt;
are a little bit more complicated for
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. The workload inserts some
key/value pairs, then updates them several times. The checker then ensures that
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can start up after the simulated
crash.&lt;/p&gt;

&lt;p&gt;In order to test as many code paths in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; as possible, we needed the
workload to trigger both &lt;em&gt;LSM tree compaction&lt;/em&gt; and a &lt;em&gt;value log garbage
collection&lt;/em&gt;. LSM tree compactions are necessary to allow the high write
throughput possible with the design. Value log garbage collection rewrites
value log files to reclaim disk space, discarding stale entries in the process.&lt;/p&gt;

&lt;p&gt;In order to coax &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; into performing
both of the above, Badger&amp;rsquo;s parameters &lt;a href=&#34;https://github.com/dgraph-io/tove/blob/master/badger/util/util.go#L14-L26&#34;&gt;are set
up&lt;/a&gt;
so that it will aggressively trigger them, even for small data writes.&lt;/p&gt;

&lt;p&gt;When ALICE was first run over &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;,
the output indicated quite a few problems:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering value log garbage collection:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_before_badger.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering LSM tree compaction:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_lsm_compaction_before.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The long list of problems from the output only corresponds to two different
vulnerabilities, which are discussed in detail in the next sections.&lt;/p&gt;

&lt;p&gt;To put &lt;em&gt;two crash vulnerabilities&lt;/em&gt; into perspective, we can compare to the
number of vulnerabilities that were found by the ALICE authors in other
programs, as documented
&lt;a href=&#34;http://research.cs.wisc.edu/adsl/Publications/alice-osdi14.pdf&#34;&gt;in the paper&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/crash_vulnerability_comparison.png&#34; alt=&#34;comparison&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; does considerably better than
some other database style applications, even those that are backed by large
organisations, e.g.:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Google&amp;rsquo;s Leveldb: 6 crash vulnerabilities.&lt;/li&gt;
&lt;li&gt;GNU&amp;rsquo;s GDBM: 5 crash vulnerabilities.&lt;/li&gt;
&lt;li&gt;HSQLDB: 10 crash vulnerabilities.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Another thing to note is that at Dgraph Labs, we&amp;rsquo;re actively seeking out
resources to make our products the best that they can be. When you&amp;rsquo;re writing
world class software, behaving reactively and waiting for the bug reports to
roll in, just isn&amp;rsquo;t an option!&lt;/p&gt;

&lt;p&gt;So what does the ALICE output mean, and how does it translate into actual crash
vulnerabilities?&lt;/p&gt;

&lt;h2 id=&#34;crash-vulnerability-1-garbage-writes&#34;&gt;Crash Vulnerability #1 - Garbage Writes&lt;/h2&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; appends to a value log file,
it just does a normal appending &lt;code&gt;write&lt;/code&gt;. As seen previously, a crash during or
shortly after an append can result in the file containing some garbage data.&lt;/p&gt;

&lt;p&gt;In the ALICE output:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul1_trace.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul1_vulns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;ALICE is able to generate crash states containing garbage by artificially
injecting garbage bytes into the ends of the recorded writes.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is a little bit confusing though.&lt;/em&gt; Recall that this was a known problem
that was previously &amp;lsquo;solved&amp;rsquo; by adding a checksum to the end of each value log
entry. While replaying a value log, if an entry&amp;rsquo;s checksum doesn&amp;rsquo;t match up, we
assume that the value log is corrupted and truncate it. So why are garbage
writes causing crashes in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;? They
should just be discarded.&lt;/p&gt;

&lt;p&gt;Unfortunately, ALICE doesn&amp;rsquo;t give any clues. It doesn&amp;rsquo;t show the output of the
checker, it just indicates that it failed.  I had to hack the ALICE source code
to leave the crash states on disk, rather than cleaning them up at the end of
its execution. I could then iterate over the crash states myself, manually
checking how &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; reacts when it starts up.&lt;/p&gt;

&lt;p&gt;Once I did this, it was obvious what the problem was. For some crash states,
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; terminated with an out of memory
error. The stack traces indicated the problem was occurring in the value log
replay code.&lt;/p&gt;

&lt;h4 id=&#34;vulnerability&#34;&gt;Vulnerability&lt;/h4&gt;

&lt;p&gt;The vulnerability occurs when the key and value lengths in a value log entry
header contain garbage data. These lengths are used to figure out how to read
the key and value. A 4-byte integer&amp;rsquo;s largest value is ~4
billion, causing a worst case memory allocation of 8GB (4GB for each of the key
and value). This can cause the process to go out of memory, resulting in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; refusing to start.&lt;/p&gt;

&lt;h4 id=&#34;solution&#34;&gt;Solution&lt;/h4&gt;

&lt;p&gt;Since we expect that keys will always be smaller than 1MB and values will
always be smaller than 1GB (these are generous bounds), we can simply cap the
allowable size of keys and values. If the header indicates that the key or
value is bigger than its bound, we know the entry is corrupt (and avoid a
memory allocation based on bad data). But what if the header is corrupt but
the key and value lengths are within their bounds? In that case, we can still
detect the corruption using the checksum.&lt;/p&gt;

&lt;p&gt;Once a corrupt entry is detected, we can truncate the value log at that point.&lt;/p&gt;

&lt;p&gt;The relevant pull request is
&lt;a href=&#34;https://github.com/dgraph-io/badger/pull/158&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;crash-vulnerability-2&#34;&gt;Crash Vulnerability #2&lt;/h2&gt;

&lt;p&gt;The value log is actually made up of many smaller &lt;em&gt;value log files&lt;/em&gt;.  When an
individual value log file gets too big, a new one is created. The value log
(conceptually the concatenation of all of the value log files) then continues
in the new value log file. Meanwhile,
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; maintains a head pointer,
corresponding to the offset in value log, uptil which everything has been
persisted to disk on the LSM tree.&lt;/p&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up, it picks the
latest value of head from the persisted portion of the LSM tree, and replays
the entries from value log from that offset onwards to bring them back into LSM
tree (for more details about how this works, see &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;the original
paper&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The ALICE output indicates that there is a problem around the transition from
one value log file (&lt;code&gt;*.vlog&lt;/code&gt;) to the next:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul2_trace.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/alice_vul2_vulns.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h5 id=&#34;vulnerability-1&#34;&gt;Vulnerability&lt;/h5&gt;

&lt;p&gt;When &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; starts up, all of the
&lt;code&gt;*vlog&lt;/code&gt; are first opened:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The latest &lt;code&gt;vlog&lt;/code&gt; file is opened in read/write mode. This is the &lt;code&gt;vlog&lt;/code&gt; file
that will be appended to when the key value store is mutated.&lt;/li&gt;
&lt;li&gt;All previous &lt;code&gt;vlog&lt;/code&gt; files are opened in read-only mode. They are only used
for value lookups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The value log is then replayed from the head persisted in the LSM tree.  When a
corrupt entry in a &lt;code&gt;vlog&lt;/code&gt; file is found during replay, that file is truncated
so that it contains only good entries. This is normally fine, because the
corrupt file is expected to be the latest one (since it would have been
appended to last before the crash).&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This isn&amp;rsquo;t always the case though&amp;hellip;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The problem occurs when the content of &lt;code&gt;000001.vlog&lt;/code&gt; is persisted to disk
before the content of &lt;code&gt;000000.vlog&lt;/code&gt;. &lt;code&gt;000001.vlog&lt;/code&gt; will be the latest value log
file (opened as read/write), but &lt;code&gt;000000.vlog&lt;/code&gt; (opened as read-only) may have
corrupt entries. The result is that we try to truncate a file that is opened in
read-only mode.&lt;/p&gt;

&lt;p&gt;This vulnerability only occurs when
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is configured with
&lt;code&gt;SyncWrites=false&lt;/code&gt;. This is a mode that trades off increased write performance
for the chance that if &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; crashes,
some small amount of recently written data may be lost. However, the
vulnerability &lt;em&gt;does&lt;/em&gt; leave &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; unable
to restart which is unacceptable.&lt;/p&gt;

&lt;h5 id=&#34;solution-1&#34;&gt;Solution&lt;/h5&gt;

&lt;p&gt;There are a few different possible fixes here. We went for a simple fix: always
&lt;a href=&#34;https://github.com/dgraph-io/badger/pull/157&#34;&gt;sync the current &lt;code&gt;vlog&lt;/code&gt; file before starting a new
one&lt;/a&gt;. That way, the nth value log
file is always persisted completely before the n+1th is written.&lt;/p&gt;

&lt;h2 id=&#34;concluding-thoughts&#34;&gt;Concluding thoughts&lt;/h2&gt;

&lt;p&gt;After we fixed the problems that ALICE reported, running ALICE again shows no
crash vulnerabilities for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. Awesome!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering value log garbage collection:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_after_badger.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Triggering LSM tree compaction:&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/alice_lsm_compaction_after.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Here at Dgraph Labs, we really care about making our products as robust as
possible,&lt;/strong&gt; even under unlikely and rare scenarios such as system crashes.
We want to stay ahead of the curve when it comes to rock solid
stability. Proactively finding and fixing bugs before they are reported in
production is a major part of that.&lt;/p&gt;

&lt;p&gt;If you own and maintain software that interacts directly with files, we
recommend that you give ALICE a try. Also, if you need a rock solid and
performant key-value store, you know &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;where to
look&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/jumping_badger.jpg&#34; alt=&#34;Happy Badger&#34; /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://fineartamerica.com/featured/galileo-spacecraft-burning-up-in-jupiter-christian-darkin.html&#34;&gt;Galileo Spacecraft Burning Up In
Jupiter&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Scale the shit out of this!</title>
      <link>https://blog.dgraph.io/post/scaling-dgraph/</link>
      <pubDate>Tue, 08 Aug 2017 17:23:51 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/scaling-dgraph/</guid>
      <description>

&lt;p&gt;Starting v0.8, we have aimed to focus purely on the stability and performance of &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;. Our feature set is at this point good enough for most users &amp;ndash; so we&amp;rsquo;ve decided to freeze it until we reach v1.0.&lt;/p&gt;

&lt;p&gt;Part of ensuring stability and performance led us to try and load the entire Stack Overflow on &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;; around 2 billion edges. With full-text search, reverses and other indices, this jumps between &lt;strong&gt;6-8 billion edges&lt;/strong&gt;; which poses unique challenges.&lt;/p&gt;

&lt;p&gt;Trying to load up this data has been an interesting journey in problem-solving.  Every step of the way we made our best judgment to come up with a good solution &amp;ndash; sometimes they stuck, other times they didn&amp;rsquo;t, only to be replaced by another solution.&lt;/p&gt;

&lt;p&gt;To give you an idea of how we store data, we convert all outgoing edges from a node, sharing the same predicate into a single key-value pair. The value is typically a sorted list of integers, what we refer to as posting list. Computer Science graduates familiar with Information Retrieval problem would instantly recognize this as &lt;a href=&#34;https://nlp.stanford.edu/IR-book/html/htmledition/an-example-information-retrieval-problem-1.html&#34;&gt;an inverted index&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/posting list.png&#34; alt=&#34;Inverted Index&#34; /&gt;&lt;/p&gt;

&lt;p&gt;While typical search engines have the luxury to create these posting lists once using a map-reduce; in &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt;, we need to update these in real time as mutations flow.  But for every new mutation to this posting list, we don&amp;rsquo;t rewrite this posting list. That&amp;rsquo;d be computationally expensive. Instead, we store these mutations in a layer above the list; and on some trigger, we merge this layer and regenerate the sorted integer list.&lt;/p&gt;

&lt;p&gt;If a posting list has a mutation, we consider it &lt;em&gt;dirty&lt;/em&gt;. We have a dirty channel, which we push the corresponding key to, after every successful mutation. A few goroutines would pick keys from this channel and &lt;em&gt;sync them to disk&lt;/em&gt;. This sync step includes regenerating the posting list, followed by a write to the underlying key-value store.&lt;/p&gt;

&lt;h2 id=&#34;stuck-write-throughput&#34;&gt;Stuck write throughput&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/houston-we-have-a-problem.jpg&#34; alt=&#34;Houston, we have a problem&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The problem we hit&lt;/strong&gt; was during loading. When we started loading the data, we saw our write throughput was getting stuck on around 50-60K updates per second. The system was definitely capable of doing more than that.&lt;/p&gt;

&lt;p&gt;After debugging, we realized that we were waiting too long for posting lists.&lt;/p&gt;

&lt;p&gt;See, when you do a sync to disk, you need to block access to this posting list: you regenerate the value (which could be expensive), then write it to disk, and then delete the value from memory. Then, when someone accesses this PL again, they fetch the value from the key-value store.&lt;/p&gt;

&lt;p&gt;The pre-mature optimization behind delete was to save memory, but clearly, it could be avoided. We still wrote to disk, but stopped deleting the value from memory; so the next guy has it ready for more operations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Things got better.&lt;/strong&gt; But, we were still waiting too long on popular posting lists. After some head scratching, the culprit turned out to be the dirty channel.  For every mutation, we were pushing this key to the dirty channel. And then these goroutines would trigger a sync to disk. For popular lists, we were doing this too frequently. Every mutation would in effect trigger a sync to disk, via the dirty channel. This was not good.&lt;/p&gt;

&lt;p&gt;We needed a way to delay the push to dirty channel. So, we introduced a goroutine and a local channel. This goroutine would listen on this channel, and we&amp;rsquo;ll push to this channel on every successful mutation. When the goroutine receives something on the channel, it will sleep for five seconds. On awake, it would check if there was something new on the channel. If so, it would repeat the loop of sleeping. If not, it would push to the global dirty channel.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This was a nifty idea but crumbled as soon as we ran it.&lt;/strong&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/mars-explosion.jpg&#34; alt=&#34;The Martian Movie - Explosion - Twentieth Century Fox/YouTube&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The memory usage spiked, and &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; quickly went OOM. For a while, we couldn&amp;rsquo;t figure out why.  The heap seemed normal. We debugged the cache; it seemed to be of normal size.  The mutations weren&amp;rsquo;t consuming too much either. Nothing in the system looked like it was out of place.&lt;/p&gt;

&lt;h2 id=&#34;the-stack&#34;&gt;The Stack&lt;/h2&gt;

&lt;p&gt;Then almost accidentally, we saw the stack size. We always tracked Go heap size but had never tracked the stack.  We just happened to print the entire Go memory stack and noticed that the stack size was totally out of whack.&lt;/p&gt;

&lt;p&gt;We quickly noticed the number of goroutines. We had millions of them running, one per key. Each goroutine consumes at least 4KB in the stack (in practice, more). &lt;strong&gt;10 million of them would consume at least 40GB!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Learning a new lesson about the cost of cheap goroutines, we changed our solution.  Note that when we pick something from the dirty channel, we don&amp;rsquo;t immediately work on it. We store it in a local dirty map. We then pick &lt;code&gt;X%&lt;/code&gt; of total entries in the dirty map and trigger sync to disk on them.&lt;/p&gt;

&lt;p&gt;Previously, we were just storing &lt;code&gt;struct{}&lt;/code&gt; in the map value. We changed that to store a timestamp. We removed the local goroutines per posting list and switched back to pushing to dirty chan on every mutation. But, when it reached the local dirty map, we&amp;rsquo;d just update the timestamp.&lt;/p&gt;

&lt;p&gt;When picking the &lt;code&gt;X%&lt;/code&gt; entries from the dirty map, we&amp;rsquo;d check if the timestamp was within five seconds. If not, we&amp;rsquo;ll just skip that list. &lt;strong&gt;This gave us the delay factor.&lt;/strong&gt; We just had to add a small break condition to avoid looping over the entire dirty map.&lt;/p&gt;

&lt;p&gt;Now, this worked. We saw a jump in our mutations per second, from 50-60K to close to 100K. At least initially.&lt;/p&gt;

&lt;h2 id=&#34;range-anxiety&#34;&gt;Range Anxiety&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/range anxiety.jpg&#34; alt=&#34;The Martian Movie - Range Anxiety&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The write throughput would start above 100K, but after a few minutes of running, the throughput would drop down to 70K, then 50K, then lower. We tried to figure out what was causing this drop. Turns out, some of our frequently written posting lists were taking longer and longer to add mutations.&lt;/p&gt;

&lt;p&gt;Remember, how we have a mutable layer above the immutable layer. For a small number of frequently updated posting lists, the time delay would almost never trigger. Within the 5 second period, at least some mutation would touch it, which caused its mutable layer to grow unbounded. And this layer is slower to access compared to the immutable layer. So, new additions were being slow.&lt;/p&gt;

&lt;p&gt;Along with the time delay, we added a heuristic that for every 1000 writes; these layers would be merged. This let the loading run for longer at higher throughputs. Another day, another fix!&lt;/p&gt;

&lt;p&gt;Now that write throughput was OK, &lt;strong&gt;we had a new problem.&lt;/strong&gt; After an hour or so of running, &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; would be killed by OOM.&lt;/p&gt;

&lt;p&gt;We tried various things, over many days. We enabled swap space. We used all the &lt;code&gt;sync.Pools&lt;/code&gt; in every critical path. We evicted things more aggressively. But, all we were able to do was to push it from one hour to three hours, before it would OOM.&lt;/p&gt;

&lt;p&gt;See, every time we read a posting list, we would store it in memory in case something else needed it. &lt;em&gt;That’s our version of cache.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We used a sharded map to store these posting lists in memory. We’d have 64 shards, to allow fast concurrent access by multi core machines. The thing is, this cache would grow as you access more and more lists.&lt;/p&gt;

&lt;p&gt;We had a mechanism in place to manage memory. We have a goroutine which periodically checks memory usage by our program. If that memory exceeds a certain specified value by the user, we will evict one shard. That is, we’d go over all the keys in one shard and just delete them. During our various attempts, we also added some heuristic to increase that number to 3 shards, if memory usage grew beyond some higher limit.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In theory, this works OK.&lt;/strong&gt; You go over memory, you discard a chunk of items, and let Go and hence the OS reclaim the memory. Now, Go is slow in releasing memory to the OS, so we’d trigger &lt;code&gt;debug.FreeOSMemory()&lt;/code&gt; method, to avoid the OS killing the process with an OOM.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In practice, it sunk fast!&lt;/strong&gt; First, Go might still not release memory despite calls to &lt;code&gt;debug.FreeOSMemory()&lt;/code&gt;. &lt;em&gt;It’s suggestion, not a command.&lt;/em&gt; It might hold tens of GBs of memory, while the OS is close to killing the process.  Second, we didn’t account for an interesting behavior.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/out-of-memory.jpg&#34; alt=&#34;Out of memory&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Every time the goroutine would check our memory usage is greater than the threshold, it would trigger an &lt;code&gt;EvictShard()&lt;/code&gt;. What happened was, memory usage would sort of stay above the limit for a while, causing many evict shards.  Eventually, almost the entire cache would be evicted; and the memory usage would go below the threshold (but not too much, because Go holds memory).&lt;/p&gt;

&lt;p&gt;A memory having gone to normal state, the system would accept requests again and start loading the data. But the requests have been retrying for a while, so they’d reload too many posting lists all at once (plus, almost zero caches). The memory usage would suddenly spike, and before the goroutine could trigger another evict shard, the program would OOM.&lt;/p&gt;

&lt;p&gt;The lesson learned here was not only to avoid the program from going above the normal limit (which is what we were doing) but to &lt;strong&gt;avoid evicting big chunks of cache all at once.&lt;/strong&gt; Because when it comes back, it comes back with a &lt;em&gt;vengeance&lt;/em&gt;!&lt;/p&gt;

&lt;p&gt;So, we switched to a single shard LRU cache, which would release memory consistently over time (&lt;em&gt;well, we should have had that in the first place, but it was slower compared to sharded map; so it was a pending investigative TODO item for over a year&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Also, we couldn’t rely upon the goroutine doing Go memory monitoring to tell us how much to release — because of its unreliability. So, we just set the size of the LRU cache upfront, and then maintain that over time.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;That fixed our OOM issue. Almost surprisingly!&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&#34;getting-back-to-your-perf-review&#34;&gt;Getting back to your perf review&lt;/h1&gt;

&lt;p&gt;Now that memory issue was solved, it was time to load the entire 2B edges and play with it. &lt;em&gt;Almost!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;After some hours of loading data, we realized we had some huge posting lists, containing millions of integers. These were the frequently updating ones, which have a very &lt;strong&gt;high fan-out.&lt;/strong&gt; That is, one node has millions of edges going outwards.&lt;/p&gt;

&lt;p&gt;This particularly troubled us in indices. For, e.g., &lt;code&gt;Type&lt;/code&gt; index, which points from a certain type to all the instances of that type. If you have 100s of millions of comments, all these comments would be referenced in one posting list. Another good example is full-text search, where certain common terms can cause high fan-out nodes.&lt;/p&gt;

&lt;p&gt;As the list size grows, re-encoding the list after every 1000 mutations was getting slower and slower. This would cause all writes waiting on this list to slow down considerably; which in turn slows down the data loading.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This is where we are right now! And we have ideas to solve this problem.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;One is to split the posting list into smaller and smaller shards, to create essentially &lt;em&gt;sharded posting lists&lt;/em&gt;.  Each shard holding a contiguous portion of the sorted list. This way, the mutations could be applied to these lists concurrently, and each of these could be re-encoded easily.&lt;/p&gt;

&lt;p&gt;The problem with this approach is that when iterating or intersecting these posting lists, all the shards of the posting list would have to be brought into memory. &lt;strong&gt;This is bad for two reasons.&lt;/strong&gt; One, bringing the whole thing into memory is still a problem. And two, more disk reads are now required to read the posting list.&lt;/p&gt;

&lt;p&gt;Without going into details, the other option is based on research, which is to encode the posting list smartly.&lt;/p&gt;

&lt;p&gt;We initially worked on the first approach, but after writing it quickly rejected it in favor of the second approach.&lt;/p&gt;

&lt;p&gt;Posting list encoding change is currently being implemented and tested. We’ll know soon how effective this is, and what new issues we encounter along the path to scaling &lt;a href=&#34;https://dgraph.io&#34;&gt;Dgraph&lt;/a&gt; to billions of edges. Stay tuned!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. To see the commits corresponding to this blog post, &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commits/master?author=janardhan1993&#34;&gt;see recent activity here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Images: Stills from &lt;a href=&#34;http://www.foxmovies.com/movies/the-martian&#34;&gt;The Martian&lt;/a&gt;
and &lt;a href=&#34;https://www.uphe.com/movies/apollo-13&#34;&gt;Apollo 13&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building a Stack Overflow Clone with Dgraph, and React</title>
      <link>https://blog.dgraph.io/post/building-graphoverflow/</link>
      <pubDate>Wed, 02 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/building-graphoverflow/</guid>
      <description>&lt;p&gt;I have recently built a Stack Overflow clone with Dgraph and React. I was delightfully surprised by the pleasant developer experience and the performance of my application. In this post, I would like to tell the story of how I built &lt;em&gt;Graphoverflow&lt;/em&gt; and share the best practices I learned for using Dgraph to build a modern web application.
&lt;/p&gt;

&lt;p&gt;As you can see in the &lt;a href=&#34;https://graphoverflow.dgraph.io&#34;&gt;live demo&lt;/a&gt;, &lt;em&gt;Graphoverflow&lt;/em&gt; implements all core functionalities of Stack Overflow. Through the web interface, you can create, read, update, and delete questions, answers, comments. You can also cast upvotes and downvotes. In addition, it is smart enough to recommend you questions to read based on &lt;a href=&#34;https://en.wikipedia.org/wiki/Collaborative_filtering&#34;&gt;collaborative filtering&lt;/a&gt;. In many ways, &lt;em&gt;Graphoverflow&lt;/em&gt; successfully embodies many important features that most modern web applications depend on: CRUD operations, and user authentication and authorization. As &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;the source code&lt;/a&gt; shows, all this is achieved by using Dgraph as the primary and only data storage.&lt;/p&gt;

&lt;p&gt;Looking back the past three weeks of building &lt;em&gt;Graphoverflow&lt;/em&gt;, I feel that the journey was unexpectedly simple and straightforward. I have never built anything using a graph database in my entire life. Therefore when I started building this application I knew I was set out for a bumpy ride. However, the intuitive query language of Dgraph did the heavy lifting out of the box, and I did not have to struggle too much. &lt;em&gt;Graphoverflow&lt;/em&gt; is not a simple application by any means, as it needs to retrieve and render a large amount of data with complex relationships, and has a built-in recommendation system. However, a quick analysis of the code base reveals that I only had to write 700 LOC (18%) on the server side, and 3300 LOC (82%) on the client side to ship it, excluding&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Server side
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
JavaScript                       7             94             21            654
JSON                             1              0              0             39
-------------------------------------------------------------------------------
SUM:                             8             94             21            693
-------------------------------------------------------------------------------


# Client side
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
JavaScript                      62            391             74           2880
Sass                            17             91              1            461
-------------------------------------------------------------------------------
SUM:                            79            482             75           3341
-------------------------------------------------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The simplicity of the code base clearly demonstrates that, with Dgraph, you can end up with a lot less complex application code for your non-trivial requirements.&lt;/p&gt;

&lt;h2 id=&#34;the-query-language-was-the-key&#34;&gt;The Query Language Was The Key&lt;/h2&gt;

&lt;p&gt;I believe that &lt;em&gt;Graphoverflow&lt;/em&gt; owes its simple code base and the fast iteration cycle to Dgraph&amp;rsquo;s homebred query language, &lt;a href=&#34;https://docs.dgraph.io/query-language/&#34;&gt;&lt;em&gt;Graphql+-&lt;/em&gt;&lt;/a&gt;. To me, the biggest benefit of the query language was that I was able to retrieve complex data by writing a single, and intuitive tree-like structure. I could spend less time worrying about what tables to create or join together to store and fetch the data that the frontend required. Instead, I could simply focus on polishing my front-end components, while relying on Dgraph&amp;rsquo;s flexible schema system and its powerful query language.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/graphoverflow-question.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The inner workings of the question page shown above can shed lights on Dgraph&amp;rsquo;s ability to retrieve complex data in a straightforward way. In order to render this page on the front-end, I needed to fetch &lt;code&gt;question&lt;/code&gt;, and all of its &lt;code&gt;answers&lt;/code&gt;. For all of them, I needed to fetch the total number of &lt;code&gt;upvotes&lt;/code&gt; and &lt;code&gt;downvotes&lt;/code&gt;, &lt;code&gt;viewCounts&lt;/code&gt;, its &lt;code&gt;history&lt;/code&gt;, &lt;code&gt;comments&lt;/code&gt;, and those comments&amp;rsquo; respective &lt;code&gt;scores&lt;/code&gt;. Not only that but also I needed to fetch 30 &lt;code&gt;related questions&lt;/code&gt; based on the tags attached to the displayed question. These data have complex schemas and interdependent relationships with one another. The queries I wrote, on the other hand, felt very straightforward to me.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    Title {
      Text
    }
    Body {
      Text
    }
    ViewCount
    UpvoteCount: count(Upvote)
    DownvoteCount: count(Downvote)

    Comment {
      ...
    }

    Has.Answer {
      Comment {
        ...
      }
      ...
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above is the query responsible for fetching the &lt;code&gt;question&lt;/code&gt;, its &lt;code&gt;answers&lt;/code&gt;, and their relevant properties and children such as &lt;code&gt;comments&lt;/code&gt;. GraphQL+- is comprised of the root node and its nested blocks, and when executed it returns a result in a subgraph format. A query can have multiple root nodes, and you can see the whole query &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow/blob/master/app/client/src/queries/Question.js#L131&#34;&gt;here on GitHub&lt;/a&gt;. In short, the above query returns a result shaped like the following code block. We can see that starting from the root node, &lt;code&gt;question&lt;/code&gt;, Dgraph finds and returns all the children nodes represented by nested blocks.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;{
  &amp;quot;question&amp;quot;: [
    {
      &amp;quot;Timestamp&amp;quot;: &amp;quot;2015-10-06T15:34:33.75Z&amp;quot;,
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I keep my cat off my keyboard?&amp;quot;
        }
      ]
      &amp;quot;Body&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;...&amp;quot;
        }
      ],
      &amp;quot;ViewCount&amp;quot;: 21767,
      &amp;quot;UpvoteCount&amp;quot;: 169,
      &amp;quot;DownvoteCount&amp;quot;: 2,
      &amp;quot;Comment&amp;quot;: [ { ... }, ... ],
      &amp;quot;Has.Answer&amp;quot;: [
        {
          &amp;quot;Comment&amp;quot;: [ { ... }, ... ],
          ...
        },
        ...
      ],
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-in-react&#34;&gt;Using in React&lt;/h2&gt;

&lt;p&gt;To query Dgraph and use the result in a React application, we can use the component lifecycle method provided by React. When a component responsible for displaying the question mounts to the DOM, &lt;em&gt;Graphoverflow&lt;/em&gt; sends a query to Dgraph and displays a loading screen for a short while until the result arrives. Therefore, it handles the data fetching in the &lt;a href=&#34;https://facebook.github.io/react/docs/react-component.html#componentdidmount&#34;&gt;&lt;code&gt;compnentDidMount&lt;/code&gt;&lt;/a&gt; lifecycle method which is invoked immediately after a component mounts. The simplified code looks like the following:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import React from &#39;react&#39;;
import { runQuery } from &amp;quot;../lib/helpers&amp;quot;;
import { getQuestionQuery } from &amp;quot;../queries/Question&amp;quot;;

class Question extends React.Component {
  constructor(props) {
    super(props);

    this.state = {
      questionLoaded: false,
      question: {}
    };
  }

  componentDidMount() {
    const questionUID = this.props.match.params.uid;
    const query = getQuestionQuery(questionUID);

    runQuery(query).then(res =&amp;gt; {
      const question = res.question[0];
      this.setState({ question, questionsLoaded: true });
    })
  }

  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three things need to happen in &lt;code&gt;componentDidMount&lt;/code&gt;: constructing a query for the question, sending the query to the server, storing the result so that it can be rendered. Let us look at this simple process step-by-step.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Since we need to fetch a question with a specific &lt;code&gt;_uid_&lt;/code&gt;, we need to dynamically make a query string by interpolating string. &lt;code&gt;getQuestionQuery&lt;/code&gt; is a factory that takes a &lt;code&gt;questionUID&lt;/code&gt; and returns a string representing the query.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;  function getQuestionQuery(questionUID) {
    return `
      question(func: uid(${questionUID})) {
        ...
      }
    `;
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Once we have the query, simply make an HTTP &lt;code&gt;POST&lt;/code&gt; request to Dgraph server. &lt;code&gt;runQuery&lt;/code&gt; is a helper method that returns a promise that resolves with the JSON response from Dgraph server. It uses &lt;a href=&#34;https://github.com/visionmedia/superagent&#34;&gt;superagent&lt;/a&gt;, but you can surely use other solutions such as &lt;a href=&#34;https://github.com/github/fetch&#34;&gt;fetch&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import request from &amp;quot;superagent&amp;quot;;

function runQuery(queryText) {
  const endpointBaseURL = &#39;http://localhost:3030&#39;;

  return request.post(`${endpointBaseURL}/query`).send(queryText).then(res =&amp;gt; {
    return JSON.parse(res.text);
  });
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;When we get the response, we store it in an application state so that the data can be rendered in the browser. &lt;em&gt;Graphoverflow&lt;/em&gt; persists the data in component&amp;rsquo;s state to keep the demonstration simple. However, you can easily integrate state management libraries such as &lt;a href=&#34;https://github.com/reactjs/redux&#34;&gt;Redux&lt;/a&gt; or &lt;a href=&#34;https://github.com/mobxjs/mobx&#34;&gt;MobX&lt;/a&gt; to this step.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Having completed the above process in &lt;code&gt;componentDidMount&lt;/code&gt;, now we can render the question page. Here is what &lt;code&gt;render&lt;/code&gt; method of &lt;code&gt;Question&lt;/code&gt; component looks like in a simplified way.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;render() {
  const {
    question,
    questionLoaded,
  } = this.state;

  if (!questionLoaded) {
    return &amp;lt;Loading /&amp;gt;;
  }

  return (
    &amp;lt;div&amp;gt;
      &amp;lt;QuestionLayout question={question} /&amp;gt;
    &amp;lt;/div&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once I got the hang of the query language, it felt very natural using Dgraph with React simply because there was nothing new or paradigm-shifting. The process described above is exactly how I would use PostgreSQL or MongoDB in a purely client-side rendered Single Page Application.&lt;/p&gt;

&lt;p&gt;The mechanism described here can be adapted to support more advanced use cases such as server-side rendering; we can move the whole process into a static method of the component that returns a promise, and call it on the server side and delay the render until a response is fetched and promise resolved. We can even integrate Redux with ease so that the app state can be rehydrated on the client side.&lt;/p&gt;

&lt;h2 id=&#34;best-practices&#34;&gt;Best Practices&lt;/h2&gt;

&lt;p&gt;Through building &lt;em&gt;Graphoverflow&lt;/em&gt;, I have come up with some practices that I believe will help keep your code base maintainable and save time. Those are based on my collective lessons from numerous trial, errors, and redesign attempts. Often a lack of documented practices is the biggest barrier hindering us from dipping our unfamiliar technologies and cultivating their benefits. The following practices will help you instantly get started with building fast modern web applications with Dgraph and React.&lt;/p&gt;

&lt;h3 id=&#34;organize-your-queries-along-with-your-components&#34;&gt;Organize Your Queries Along With Your Components&lt;/h3&gt;

&lt;p&gt;It is a good idea to couple together a component and all queries that component relies on for data. The reason is that you need to know the shape of JSON response from Dgraph server in order to render your components. And the shape of the response can vary for mainly two reasons. Names of predicates can change because a query can use an &lt;a href=&#34;https://docs.dgraph.io/query-language/#alias&#34;&gt;alias&lt;/a&gt;. Alternatively, a nested block in a query might be omitted either by need or an error. Those situations can suddenly take away fields that your React component assumes are present. If you have a chain of attribute getters and one of those attributes is missing, you will end up chaining a getter on an &lt;code&gt;undefined&lt;/code&gt;. Prior to React 16, such scenario can &lt;a href=&#34;https://facebook.github.io/react/blog/2017/07/26/error-handling-in-react-16.html#behavior-in-react-15-and-earlier&#34;&gt;lead to cryptic error messages&lt;/a&gt; that are hard to debug.&lt;/p&gt;

&lt;p&gt;Here is an example of how a change in Dgraph response can cause an error in your React application. The query for the question page includes the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    Title {
      Text
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the &lt;code&gt;Question&lt;/code&gt; component, &lt;em&gt;Graphoverflow&lt;/em&gt; renders the title while assuming the result has the shape of &lt;code&gt;{ question: { title: [ { text } ], ... } }&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;class Question extends React.Component {
  ...
  render() {
    ...

    return (
      ...
      &amp;lt;h1 className=&amp;quot;post-title&amp;quot;&amp;gt;{post.Title[0].Text}&amp;lt;/h1&amp;gt;
      ...
    );
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we change the query to the following, the component will not work anymore because &lt;code&gt;post.Title&lt;/code&gt; will be &lt;code&gt;undefined&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  question(func: uid(0xa421) {
    question_title as Title {
      Text
    }
    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Your queries will evolve as your requirements change. Iterating on your query can be error-prone if the queries are scattered in a random manner without a formal structure. Therefore I recommend the following directory structure in your project to mitigate such issue and keep your code base maintainable.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;your_project
├── components
│   ├── EditPost.js
│   ├── Home.js
│   └── Question.js
├── queries
│   ├── EditPost.js
│   ├── Home.js
│   └── Question.js
...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Within your component, import needed queries from the corresponding query file. This way, we can easily iterate on queries for your components in a reliable manner. It is clean and reassuring to have a separate, go-to file to see all the queries that your component is relying on. It keeps possible errors in check and makes debugging feasible in case of an error.&lt;/p&gt;

&lt;h3 id=&#34;use-functions-to-dynamically-construct-queries&#34;&gt;Use Functions to Dynamically Construct Queries&lt;/h3&gt;

&lt;p&gt;When your query needs to be built dynamically, write a function that takes values and returns a query string using those values. In other words, make a factory to dynamically generate queries rather than doing string interpolation directly in your component. Previously we have seen an example of such function that generates a query for a specific question:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;function getQuestionQuery(questionUID) {
  return `
    question(func: uid(${questionUID})) {
      ...
    }
  `;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Many occasions will arise in which you need to generate a query dynamically. Most common cases are fetching a single resource by its unique identifier, or posting information while performing &lt;a href=&#34;https://docs.dgraph.io/query-language/#mutations&#34;&gt;mutations&lt;/a&gt;. In such occasions, simply export functions like the example above from the appropriate query file that you have established following the previous best practice. Doing so allows you to keep all the queries in a single file in a clean way.&lt;/p&gt;

&lt;h3 id=&#34;use-fragments-for-repeated-structures&#34;&gt;Use Fragments for Repeated Structures&lt;/h3&gt;

&lt;p&gt;If queries for one of your components exhibits repeated structures, consider extracting them as fragments that can be reused. Doing so will allow us to avoid the mismatch between the shape of Dgraph response and your React component&amp;rsquo;s expectation of it, a common pitfall that we already identified above.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/graphoverflow-node-cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see from the picture, the &lt;code&gt;Home&lt;/code&gt; component of &lt;em&gt;Graphoverflow&lt;/em&gt; can fetch questions according to three different criteria: &amp;lsquo;Recommended&amp;rsquo;, &amp;lsquo;Most Recent&amp;rsquo;, and &amp;lsquo;Hot&amp;rsquo;. While these criteria fetch questions of different ilks, the returned fields for the questions must be consistent because a single React component is responsible for rendering a question item, no matter what criteria is used to fetch them.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;import React from &amp;quot;react&amp;quot;;

const QuestionItem = ({ question, history }) =&amp;gt; {
  return (
    &amp;lt;li&amp;gt;
      ...
      {question.AnswerCount}
      ...
      {question.ViewCount}
      ...
      &amp;lt;Link to={questionLink} className=&amp;quot;question-title&amp;quot;&amp;gt;
        {JSON.stringify(question.Title[0].Text)}
      &amp;lt;/Link&amp;gt;
    &amp;lt;/li&amp;gt;
  );
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are three different queries in &lt;code&gt;queries/Home.js&lt;/code&gt;, all fetching data required for rendering &lt;code&gt;QuestionItem&lt;/code&gt; while following different criteria.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;export const recommendedQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
export const hotQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
export const recentQuestionQuery = `{
  ...
  questions(...) {
    _uid_
    Title {
      Text
    }
    ...
  }
}`;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we happen to under-fetch a field for &lt;code&gt;questions&lt;/code&gt; in one of these queries, the data for our React component will be incomplete, causing run-time errors. Therefore, it is much more sensible to abstract out the common parts as a &amp;lsquo;fragment.&amp;rsquo; Doing so can eliminate the chance of errors in the future iterations.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-js&#34;&gt;const questionFragment = `
_uid_
Title {
  Text
}
...
`;
export const recommendedQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
export const hotQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
export const recentQuestionQuery = `{
  ...
  questions(...) {
    ${questionFragment}
  }
}`;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Building an application with Dgraph left me with a strange aftertaste. Usually, a new technology inevitably leaves a feeling of ennui, after the excitement of trying out something new eventually subsides. Yet this time, I felt something quite different. Perhaps it was a taste of delight, a hint at something exciting in the making.&lt;/p&gt;

&lt;p&gt;As a young developer, I often find myself in a vain pursuit of the newest and the shiniest piece of technology. In that hedonistic treadmill, I time and again stumbled upon many burgeoning technologies proclaiming to be the fastest, the newest, the most game-changing. Perhaps all those claims are justified in their own unique ways, but for the most part, it feels that they are merely clamoring for attention. In contrast, Dgraph seems to make a persuasive case with its well-designed query language alone.&lt;/p&gt;

&lt;p&gt;Dgraph has proven to work seamlessly with React, and its rich and intuitive query language allowed me to make and ship a Stack Overflow clone in a matter of weeks without a previous experience. The ease of iteration, coupled with the performance, indicates that Dgraph is a valuable addition to our tool belts for building modern web applications.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;You can try Graphoverflow on &lt;a href=&#34;https://graphoverflow.dgraph.io&#34;&gt;https://graphoverflow.dgraph.io&lt;/a&gt; and view its source code on &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;https://github.com/dgraph-io/graphoverflow&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://images.nasa.gov/#/details-iss042e021664.html&#34;&gt;International Space Station Night Europe&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building apps with Dgraph&#39;s Go client</title>
      <link>https://blog.dgraph.io/post/client0.8.0/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/client0.8.0/</guid>
      <description>

&lt;p&gt;We&amp;rsquo;ve just released v0.8 and it contains lots of &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases/tag/v0.8.0&#34;&gt;new features and improvements&lt;/a&gt;.  The Go client saw some nice improvements, so this post will walk you through the client interface and demonstrate some example code.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://godoc.org/github.com/dgraph-io/dgraph/client&#34;&gt;GoDoc&lt;/a&gt; already contains all the specs and small examples of how to use the client.  This post will take you on a guided tour and with examples that are more on the scale of a real app.&lt;/p&gt;

&lt;p&gt;There are basically three ways to use the client:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;queries,&lt;/li&gt;
&lt;li&gt;request based mutations, and&lt;/li&gt;
&lt;li&gt;batched mutations.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Of course you can mix those up in a single client session, but to give each its own treatment, I&amp;rsquo;ll deal with each separately here.  This post will walk you through &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/wiki/resources/examples/goclient/&#34;&gt;three programs available in our github&lt;/a&gt;, a few hundred lines each, that demonstrate interactions in those three modes.  The examples also show how concurrent goroutines can safely use the client.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/cmd/dgraphloader&#34;&gt;dgraphloader&lt;/a&gt; uses the client interface to batch updates it reads from gzipped RDF files.  It will save you from writing code to read RDF into Dgraph, and it&amp;rsquo;s another good example of how to use the client interface.&lt;/p&gt;

&lt;p&gt;Before reading the rest of the post, you might like to watch this introductory video on using the Go client.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/pq2o_IHgbww&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;&lt;em&gt;We&amp;rsquo;re developing more tutorials and presentations on our &lt;a href=&#34;https://www.youtube.com/channel/UCghE41LR8nkKFlR3IFTRO4w&#34;&gt;YouTube channel&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&#34;getting-started&#34;&gt;Getting Started&lt;/h2&gt;

&lt;p&gt;These shouldn&amp;rsquo;t be your first Go programs, so let&amp;rsquo;s assume that you have &lt;code&gt;$GOPATH&lt;/code&gt; setup and thus you can go get the version 0.8 release branch&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get -u -v github.com/dgraph-io/dgraph/client

cd $GOPATH/src/github.com/dgraph-io/dgraph &amp;amp;&amp;amp; git checkout release/v0.8.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;or work with the master branch.&lt;/p&gt;

&lt;h2 id=&#34;fundamental-types&#34;&gt;Fundamental types&lt;/h2&gt;

&lt;p&gt;A graph is about nodes and edges, so no surprises that the two fundamental graph types in the client are &lt;code&gt;client.Node&lt;/code&gt; and &lt;code&gt;client.Edge&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The other two main types are &lt;code&gt;client.Dgraph&lt;/code&gt;, which is the connection to the Dgraph backend, and &lt;code&gt;client.Req&lt;/code&gt; which stores mutations and queries to be sent to the backend.&lt;/p&gt;

&lt;h2 id=&#34;starting-the-client&#34;&gt;Starting the client&lt;/h2&gt;

&lt;p&gt;The client takes a slice of grpc connections to the Dgraph database.  This can be a single connection, multiple connections to the one server, or connections to multiple servers if connecting to a cluster.  The client will spread your requests and batches across the given connections.  All connections from the client to Dgraph are to the ports given at &lt;code&gt;--grpc_port&lt;/code&gt; when the Dgraph instances were started (default 9080).&lt;/p&gt;

&lt;p&gt;Start a single connection by dialing the Dgraph backend (check out dgraphloader &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/release/v0.8.0/cmd/dgraphloader/main.go#L182-L204&#34;&gt;&lt;code&gt;setupConnection()&lt;/code&gt;&lt;/a&gt; to see how to enable TLS).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;conn, err := grpc.Dial(dgraph-grpc-address, grpc.WithInsecure())
if err != nil {
    log.Fatal(err)
}
defer conn.Close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then put either the single connection or multiple connections into a slice when starting the client.&lt;/p&gt;

&lt;p&gt;The client stores maps of blank-node-name -&amp;gt; &lt;code&gt;Node&lt;/code&gt; and &lt;a href=&#34;https://docs.dgraph.io/query-language/#external-ids&#34;&gt;XID&lt;/a&gt; -&amp;gt; &lt;code&gt;Node&lt;/code&gt;, so you can do quick look ups while using the client.  The following places these maps in a temporary directory, to be deleted when the program exits, but you can also keep the directory to persist the maps across multiple sessions (check out dgraphloader option &lt;code&gt;--c&lt;/code&gt; to see how you could persist XID maps across multiple loads of RDF data).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clientDir, err := ioutil.TempDir(&amp;quot;&amp;quot;, &amp;quot;client_&amp;quot;)
if err != nil {
    log.Fatal(err)
}
defer os.RemoveAll(clientDir)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For batching, the client builds multiple batches concurrently which it submits to the backend as the batches fill.  Set the batch options with the &lt;code&gt;BatchMutationOptions&lt;/code&gt; type, or supply the defaults.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dgraphClient := client.NewDgraphClient(connections, client.DefaultOptions, clientDir)
defer dgraphClient.Close()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That starts a client and all interaction with Dgraph goes through the started client.&lt;/p&gt;

&lt;h2 id=&#34;queries-through-the-go-client&#34;&gt;Queries through the Go client&lt;/h2&gt;

&lt;p&gt;When we built our &lt;a href=&#34;https://tour.dgraph.io/&#34;&gt;tour&lt;/a&gt;, we needed a dataset that was complex enough to teach the whole query language, small enough to load quickly and engaging enough that people could relate immediately to the data.  The dataset of &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data&#34;&gt;21 million&lt;/a&gt; edges about movies and actors was about right, but we wanted to take a subset, so loading it didn&amp;rsquo;t break the flow of the tour.  Because it&amp;rsquo;s a graph, we couldn&amp;rsquo;t just grab part of the input file, so we crawled it.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/wiki/resources/examples/goclient/crawlerRDF&#34;&gt;Here&amp;rsquo;s a program&lt;/a&gt; that does just that.&lt;/p&gt;

&lt;p&gt;The 21million data is all about movies, directors and actors.  Here&amp;rsquo;s a conceptual view of some of what the dataset contains.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/movies-schema.png&#34; alt=&#34;Movies Schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Directors are linked to their films with &lt;code&gt;director.film&lt;/code&gt;.  Films have an &lt;code&gt;initial_release_date&lt;/code&gt; a &lt;code&gt;genre&lt;/code&gt; and are linked to performances by &lt;code&gt;starring&lt;/code&gt;.  Performances tell us about an actor playing a character.  Actors are linked to their roles and thus movies.  Actors, directors, movies and genres all have a &lt;code&gt;name&lt;/code&gt;.  I drew the actors and directors overlapping because some people are both actors and directors.  The data doesn&amp;rsquo;t contain typing information for directors etc.  We know, however, that a node represents a director when it has the &lt;code&gt;director.film&lt;/code&gt; edge, or an actor when it has &lt;code&gt;actor.film&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Most of the queries I&amp;rsquo;d thought of for the tour were about directors, so I decided to make the crawl based around directors.  For each director the crawl sees, it grabs all their movies and pushes any director the actors in those movies have worked for onto the queue of directors to visit.  That way the crawl will finish with each director and movie it&amp;rsquo;s seen completed, but won&amp;rsquo;t complete all movies for every actor it encounters.&lt;/p&gt;

&lt;h3 id=&#34;query&#34;&gt;Query&lt;/h3&gt;

&lt;p&gt;Queries in the client are pretty straight forward.  There are two options:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A stand alone query, which is added to a request &lt;code&gt;req&lt;/code&gt; with &lt;code&gt;req.SetQuery(&amp;lt;query-string&amp;gt;)&lt;/code&gt;.  And,&lt;/li&gt;
&lt;li&gt;A query with embedded variables, which is added to a request &lt;code&gt;req&lt;/code&gt; with &lt;code&gt;req.SetQueryWithVariables(&amp;lt;query-string&amp;gt;,&amp;lt;map[string]string&amp;gt;)&lt;/code&gt;.  The query will contain variables &lt;code&gt;$a&lt;/code&gt;, &lt;code&gt;$b&lt;/code&gt;, etc and the map will have keys mapping the variables to values.  If a query is used multiple times, it&amp;rsquo;s generally easier to just update the map then to manipulate a raw string (the example program has examples of both).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;directorsMoviesTemplate = `{
  movies(func: uid($a)) {
    movie: director.film {
      _uid_
      EnglishName: name@en
      GermanName: name@de
      ItalianName: name@it
      starring {
        performance.actor {
          _uid_
          name@en
        }
        performance.character {
          _uid_
          name@en
        }
      }
      genre {
        _uid_
        name@en
      }
      ~director.film {
        _uid_
        name@en
      }
      initial_release_date
    }
  }
}`
directorMoviesMap = make(map[string]string)

...

req := client.Req{}
directorMoviesMap[&amp;quot;$a&amp;quot;] = &amp;lt;some director UID&amp;gt;

req.SetQueryWithVariables(directorsMoviesTemplate, directorMoviesMap)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sets up a request with a query for all a director&amp;rsquo;s movies.  That&amp;rsquo;s then run with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resp, err := dgraphClient.Run(context.Background(), &amp;amp;req)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that the query uses &lt;code&gt;name@en&lt;/code&gt;, &lt;code&gt;name@de&lt;/code&gt; and &lt;code&gt;name@it&lt;/code&gt;.  Version 0.8 introduced new &lt;a href=&#34;https://docs.dgraph.io/query-language/#language-support&#34;&gt;language preference&lt;/a&gt; rules, and a query for &lt;code&gt;name&lt;/code&gt; won&amp;rsquo;t work if there is no untagged name &amp;mdash; &lt;code&gt;name@.&lt;/code&gt; would return a name in some language if &lt;code&gt;name&lt;/code&gt; didn&amp;rsquo;t exist.&lt;/p&gt;

&lt;p&gt;If there were mutations in the request too, those would be run first.&lt;/p&gt;

&lt;p&gt;The question with a query is what to do with the response &lt;code&gt;resp&lt;/code&gt;.  It&amp;rsquo;s got latency information &lt;code&gt;resp.L&lt;/code&gt;, assigned nodes &lt;code&gt;resp.AssignedUids&lt;/code&gt; (if the query string contained a mutation with blank nodes), &lt;code&gt;resp.Schema&lt;/code&gt; if there was a schema query and &lt;code&gt;resp.N&lt;/code&gt;, a Slice of &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/protos/graphresponse.proto&#34;&gt;protos.Node&lt;/a&gt; representing the nodes returned by the query.  The response can be printed with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;fmt.Printf(&amp;quot;Raw Response: %+v\n&amp;quot;, proto.MarshalTextString(resp))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And you&amp;rsquo;ll see that each &lt;code&gt;protos.Node&lt;/code&gt; has an &lt;code&gt;attribute&lt;/code&gt;, the edge that lead to this node, a slice of &lt;code&gt;properties&lt;/code&gt;, the scalar edges out of this node, and a slice of &lt;code&gt;children&lt;/code&gt;, the edges out to other nodes.  Here&amp;rsquo;s a small part of such a print for director Peter Jackson&amp;rsquo;s movies.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Raw Response: n: &amp;lt;
  attribute: &amp;quot;_root_&amp;quot;
  children: &amp;lt;
    attribute: &amp;quot;movies&amp;quot;
    children: &amp;lt;
      attribute: &amp;quot;movie&amp;quot;
      properties: &amp;lt;
        prop: &amp;quot;_uid_&amp;quot;
        value: &amp;lt;
          uid_val: 1891953090925962368
        &amp;gt;
      &amp;gt;
      properties: &amp;lt;
        prop: &amp;quot;EnglishName&amp;quot;
        value: &amp;lt;
          str_val: &amp;quot;The Hobbit: The Battle of the Five Armies&amp;quot;
        &amp;gt;
      &amp;gt;
      properties: &amp;lt;
        prop: &amp;quot;GermanName&amp;quot;
        value: &amp;lt;
          str_val: &amp;quot;Der Hobbit - Hin und zur\303\274ck&amp;quot;
        &amp;gt;
      &amp;gt;
      properties: &amp;lt;
        prop: &amp;quot;ItalianName&amp;quot;
        value: &amp;lt;
          str_val: &amp;quot;Lo Hobbit - La battaglia delle cinque armate&amp;quot;
        &amp;gt;
      &amp;gt;
      properties: &amp;lt;
        prop: &amp;quot;initial_release_date&amp;quot;
        value: &amp;lt;
          str_val: &amp;quot;2014-12-10T00:00:00Z&amp;quot;
        &amp;gt;
      &amp;gt;
      children: &amp;lt;
        attribute: &amp;quot;starring&amp;quot;
        children: &amp;lt;
          attribute: &amp;quot;performance.actor&amp;quot;
          properties: &amp;lt;
            prop: &amp;quot;_uid_&amp;quot;
            value: &amp;lt;
              uid_val: 1834782200806344758
            &amp;gt;
          &amp;gt;
          properties: &amp;lt;
            prop: &amp;quot;name@en&amp;quot;
            value: &amp;lt;
              str_val: &amp;quot;Benedict Cumberbatch&amp;quot;
            &amp;gt;
          &amp;gt;
        &amp;gt;
        children: &amp;lt;
          attribute: &amp;quot;performance.character&amp;quot;
          properties: &amp;lt;
            prop: &amp;quot;_uid_&amp;quot;
            value: &amp;lt;
              uid_val: 151357
            &amp;gt;
          &amp;gt;
          properties: &amp;lt;
            prop: &amp;quot;name@en&amp;quot;
            value: &amp;lt;
              str_val: &amp;quot;The Necromancer&amp;quot;
            &amp;gt;
          &amp;gt;
        &amp;gt;
      &amp;gt;
...
...
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;unmarshal&#34;&gt;Unmarshal&lt;/h3&gt;

&lt;p&gt;You can walk around the response programmatically &amp;mdash; check functions &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/release/v0.8.0/wiki/resources/examples/goclient/crawlerRDF/crawler.go#L250-L264&#34;&gt;&lt;code&gt;printNode()&lt;/code&gt;&lt;/a&gt; and &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/release/v0.8.0/wiki/resources/examples/goclient/crawlerRDF/crawler.go#L453-L512&#34;&gt;&lt;code&gt;visitActor()&lt;/code&gt;&lt;/a&gt; for examples of that.  But one of the best new features of the client in version 0.8 is &lt;code&gt;client.Unmarshal()&lt;/code&gt;.  It works just like &lt;code&gt;json.Unmarshal()&lt;/code&gt; in the standard libs to unpack directly into a struct.&lt;/p&gt;

&lt;p&gt;Here are some structures representing the types in our movie graph.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type movie struct {
    ReleaseDate time.Time      `dgraph:&amp;quot;initial_release_date&amp;quot;` // Often just use the edge name and a reasonable type.
    ID          uint64         `dgraph:&amp;quot;_uid_&amp;quot;`                // _uid_ is extracted to uint64 just like any other edge.
    Name        string         `dgraph:&amp;quot;EnglishName&amp;quot;`          // If there is an alias on the edge, use the alias.
    NameDE      string         `dgraph:&amp;quot;GermanName&amp;quot;`
    NameIT      string         `dgraph:&amp;quot;ItalianName&amp;quot;`
    Genre       []genre        `dgraph:&amp;quot;genre&amp;quot;`          // The struct types can be nested.  As long as the tags match up, all is well.
    Starring    []*performance `dgraph:&amp;quot;starring&amp;quot;`       // Pointers to structures are fine too - that might save copying structures later.
    Director    []*director    `dgraph:&amp;quot;~director.film&amp;quot;` // reverse edges work just like forward edges.
}

type performance struct {
    Actor     *actor     `dgraph:&amp;quot;performance.actor&amp;quot;`
    Character *character `dgraph:&amp;quot;performance.character&amp;quot;`
}

type movieQuery struct {
    Root []movie `dgraph:&amp;quot;movie&amp;quot;`
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now give Unmarshal a struct with tags matching the edges in the query (note how these tags match the query above) and the bit of a query response you want and, bang, the whole query result in the type that makes sense in your program, nice!&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var movs movieQuery
err = client.Unmarshal(resp.N[0].Children, &amp;amp;movs)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So model your data with types that make sense, write queries that extract out the data you need and Dgraph does the rest.&lt;/p&gt;

&lt;p&gt;From here the example program uses those data structures to write out the crawled information to a file.&lt;/p&gt;

&lt;h2 id=&#34;request-based-mutations-in-the-go-client&#34;&gt;Request-based mutations in the Go client&lt;/h2&gt;

&lt;p&gt;The previous example shows how to query and unmarshal results in the Go client.  It wrote results to a file.  That&amp;rsquo;s the sort of interaction you&amp;rsquo;d need to query an existing store and send the results somewhere.  To get the data into Dgraph in the first place the client allows you to build and run mutations.&lt;/p&gt;

&lt;p&gt;Instead of running a crawl that&amp;rsquo;s written to a file, how about a crawler that queries from one Dgraph store and builds mutations based on that data that it commits to another Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/wiki/resources/examples/goclient/crawlermutations&#34;&gt;Here&amp;rsquo;s a program&lt;/a&gt; that does just that.&lt;/p&gt;

&lt;p&gt;The code&amp;rsquo;s got similar ideas to the last example, but it&amp;rsquo;s stepped the interaction up a notch.  Firstly, there&amp;rsquo;s two clients: one for the source (only queried) and one for the target (only written to).  Secondly, for both those clients, the example allows for multiple grpc connections; for example, if the source and target are clusters.  Thirdly, there&amp;rsquo;s multiple connections, so to make use of that it runs concurrent crawlers in goroutines.&lt;/p&gt;

&lt;h3 id=&#34;adding-edges&#34;&gt;Adding edges&lt;/h3&gt;

&lt;p&gt;Function &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/release/v0.8.0/wiki/resources/examples/goclient/crawlermutations/crawler.go#L319-L509&#34;&gt;&lt;code&gt;visitMovie()&lt;/code&gt;&lt;/a&gt; is the interesting one for a discussion about mutations.  First it queries data for a movie from the source and unmarshals the result into the movie struct from the previous example.  From there it builds a mutation for the edges representing the movie and submits that to the target.&lt;/p&gt;

&lt;p&gt;A graph is about nodes and edges between nodes, so that&amp;rsquo;s what we&amp;rsquo;ve got to build to make a graph.&lt;/p&gt;

&lt;p&gt;First, a new request&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;req := client.Req{}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then make a node&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mnode, err := target.NodeBlank(&amp;quot;&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;then attach edges to the node.  This one adds a scalar edge for the English name.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;e = mnode.Edge(&amp;quot;name@en&amp;quot;)
err = e.SetValueString(m.Name)
if err != nil {
  ...
}
err = req.Set(e)
if err != nil {
  ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;after &lt;code&gt;Set()&lt;/code&gt;, the edge has been added into the request and it&amp;rsquo;s safe to reuse &lt;code&gt;e&lt;/code&gt;.  So, once the code has a node for a genre &lt;code&gt;gnode&lt;/code&gt;, it then connects the two nodes with another edge.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;e = mnode.ConnectTo(&amp;quot;genre&amp;quot;, gnode)
err = req.Set(e)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;visitMovie()&lt;/code&gt; continues in this fashion adding edges to the request for the movie name, release date, genres, directors and all the actors and characters.  If it fails at some point, &lt;code&gt;req&lt;/code&gt; is discarded and none of the edges are added to the store, so we don&amp;rsquo;t get half completed movies in our result.  If it successfully adds all the edges it runs the mutation.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;resp, err := target.Run(context.Background(), &amp;amp;req)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And all the edges are committed to the store.&lt;/p&gt;

&lt;p&gt;Deleting edges works in the same way.  Build the edge, then instead of adding to the request with &lt;code&gt;req.Set()&lt;/code&gt;, add with &lt;code&gt;req.Delete()&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;batching-updates-in-the-go-client&#34;&gt;Batching updates in the Go client&lt;/h2&gt;

&lt;p&gt;Just a few weeks back we wrote a series of posts about recommendation engines in Dgraph.  Our sample data, in text files, and the Go program that turned that into RDF is &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Instead of writing RDF and then using dgraphloader to load into Dgraph, we can use the client to write directly to Dgraph.  Dgraph isn&amp;rsquo;t really an RDF database.  It&amp;rsquo;s a graph database &amp;mdash; a graph is just about nodes and edges (and maybe facets on the edges).  dgraphloader is a helper app that loads RDF because there&amp;rsquo;s lots of RDF data around and it&amp;rsquo;s a standard format.  In this example we&amp;rsquo;ll skip the intermediate format and go straight from source data to Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/wiki/resources/examples/goclient/movielensbatch&#34;&gt;Here&amp;rsquo;s a program&lt;/a&gt; that reads the text input files and submits batched mutations to Dgraph.&lt;/p&gt;

&lt;h3 id=&#34;batches&#34;&gt;Batches&lt;/h3&gt;

&lt;p&gt;Four goroutines parse the input files.  Those goroutines create edges just like in the previous example.  But rather than submitting to Dgraph with a request, the edges are added to with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;err := dgraphClient.BatchSet(e)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The client gathers the submitted edges into batches, which are submitted when full.  Set up the batching by starting the client with a &lt;code&gt;BatchMutationOptions&lt;/code&gt; struct.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;bmOpts := client.BatchMutationOptions{
  Size:          *numRdf,       // number of edges in each batch
  Pending:       *concurrent,   // number of concurrent batches to build
  PrintCounters: true,          // if you want the client to print running stats
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The client controls which edges are in which batches and when the batches are submitted to the Dgraph server.  There&amp;rsquo;s no guarantee that sequential calls to &lt;code&gt;BatchSet()&lt;/code&gt; will put edges in the same batch, nor that the order edges are submitted will be the same as the order that mutations reach the database.  Make sure you finish with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dgraphClient.BatchFlush()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to flush out all the buffers.&lt;/p&gt;

&lt;h3 id=&#34;node-maps&#34;&gt;Node maps&lt;/h3&gt;

&lt;p&gt;That&amp;rsquo;s all pretty standard batch updates.  The fun thing here is the client-side, blank-node maps.  As the movie file is parsed, each movie needs to be linked with genres from the genres file.  As the ratings file is parsed, users from the users file need to be linked to movies from the movies file.  We could build a set of data structures to record all this and then read back out of those structures so we ensure that the graph nodes for genres, movies and users link up correctly.&lt;/p&gt;

&lt;p&gt;However, reading from a source and matching up nodes like this is such a common pattern in data uploading that we&amp;rsquo;ve built the client to take care of it.  A call to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;node, err := dgraphClient.NodeBlank(&amp;lt;node-identifier&amp;gt;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;reserves a &lt;code&gt;Node&lt;/code&gt; in the graph and keeps track (client side) of which identifier relates to which &lt;code&gt;Node&lt;/code&gt;.  In the input data, users are given ID numbers, movies have ID numbers and so do genres.  Those IDs aren&amp;rsquo;t important after we&amp;rsquo;ve loaded the data.  The IDs just need to be used to make the right links between users and their ratings of movies.  We can&amp;rsquo;t just use the numbers to keep track because there will be a user 10 and a movie 10.  Instead, the program asks for blank nodes with labels like &lt;code&gt;movie10&lt;/code&gt;.  For example, when it links a movie to a genre, it does so with this pattern&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m, err := dgraphClient.NodeBlank(&amp;quot;movie10&amp;quot;)
...
g, err := dgraphClient.NodeBlank(&amp;quot;genre3&amp;quot;)
...
e = m.ConnectTo(&amp;quot;genre&amp;quot;, g)
dgraphClient.BatchSet(e)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That will give a &lt;code&gt;genre&lt;/code&gt; edge connecting the &lt;code&gt;Node&lt;/code&gt; for movie 10 to the &lt;code&gt;Node&lt;/code&gt; for genre 3.&lt;/p&gt;

&lt;p&gt;It doesn&amp;rsquo;t matter which goroutine gets there first, or what order the edges are committed.  The gorouting parsing the ratings data might read movie 10 before the goroutine reading the movie data gets there, or it might happen the other way around.  The batch containing the mutation for a user&amp;rsquo;s rating of movie 10 might hit the database before the edges with the movie&amp;rsquo;s name and genre get there or even before the user&amp;rsquo;s other data is stored.  Doesn&amp;rsquo;t matter.  The client guarantees that it will hook the nodes up correctly because we consistently called &lt;code&gt;NodeBlank(&amp;quot;movie10&amp;quot;)&lt;/code&gt; every time we wanted to add an edge involving movie 10.&lt;/p&gt;

&lt;p&gt;It gives the code the freedom to read the data in any order and still link up the nodes correctly without any bookkeeping.  So our goroutines don&amp;rsquo;t even need to know about the other goroutines let alone share data or synchronize.&lt;/p&gt;

&lt;p&gt;Compare that with the previous example that had to use mutexes to protect shared data between goroutines.  In that instance we needed some bookkeeping to control the crawl and record what we&amp;rsquo;d seen, but often a client program only needs to read data and add nodes so the pattern from this batch example will be simpler.&lt;/p&gt;

&lt;h4 id=&#34;external-ids&#34;&gt;External IDs&lt;/h4&gt;

&lt;p&gt;Here we are storing blank nodes, meaning that the names picked on the client side to identify them during loading aren&amp;rsquo;t persisted in the store.  If the nodes had identifiers that were important outside of Dgraph, we&amp;rsquo;d do much the same thing, but with what we call &lt;a href=&#34;https://docs.dgraph.io/query-language/#external-ids&#34;&gt;external IDs, or XIDs&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For example, IMDB gives each movie a unique URL.  For &amp;ldquo;Toy Story&amp;rdquo; it&amp;rsquo;s &lt;a href=&#34;http://www.imdb.com/title/tt0114709/&#34;&gt;http://www.imdb.com/title/tt0114709/&lt;/a&gt;.  If you are from the RDF or linked data communities, you might recognize that as a URI.  If our input data used that, or if we needed such external keys for movies, genres and actors (e.g. Tom Hanks gets &lt;a href=&#34;http://www.imdb.com/name/nm0000158&#34;&gt;http://www.imdb.com/name/nm0000158&lt;/a&gt;, while genre comedy gets &lt;a href=&#34;http://www.imdb.com/genre/comedy&#34;&gt;http://www.imdb.com/genre/comedy&lt;/a&gt;).  Then we could load with&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;m, err := c.NodeXid(&amp;quot;http://www.imdb.com/title/tt0114709/&amp;quot;, true)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and the client would give a consistent map to the right node every time the XID for &amp;ldquo;Toy Story&amp;rdquo; was used, and, with the &lt;code&gt;true&lt;/code&gt; flag, the client persists an edge (&lt;code&gt;xid&lt;/code&gt;) in the store linking the node to its XID.&lt;/p&gt;

&lt;h2 id=&#34;now-you-write-some-code&#34;&gt;Now you write some code&lt;/h2&gt;

&lt;p&gt;Well, now you&amp;rsquo;ve got the &lt;a href=&#34;https://docs.dgraph.io/clients/#go&#34;&gt;docs&lt;/a&gt;, the &lt;a href=&#34;https://godoc.org/github.com/dgraph-io/dgraph/client&#34;&gt;GoDocs&lt;/a&gt; with examples for everything in the interface, and &lt;a href=&#34;https://github.com/dgraph-io/dgraph/tree/master/wiki/resources/examples/goclient&#34;&gt;three larger examples&lt;/a&gt; showing how to use the go client in real programs.&lt;/p&gt;

&lt;p&gt;Time to load up your favorite editor and start writing your Dgraph app.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Need more help?  Ask us on &lt;a href=&#34;https://discuss.dgraph.io/&#34;&gt;Discuss&lt;/a&gt; or &lt;a href=&#34;https://slack.dgraph.io/&#34;&gt;Slack&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Not using Go?  Not a problem!  Your app will access Dgraph at the HTTP query endpoint and parse the resulting JSON.  Watch out for upcoming examples.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://images.nasa.gov/#/details-iss047e050978.html&#34;&gt;SpaceX Dragon Spacecraft Grappled by SSRMS&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Orchestrating signal and wait in Go</title>
      <link>https://blog.dgraph.io/post/signal-and-wait/</link>
      <pubDate>Wed, 19 Jul 2017 15:24:00 -0700</pubDate>
      
      <guid>https://blog.dgraph.io/post/signal-and-wait/</guid>
      <description>&lt;p&gt;One of the common use case in Go is to start a few goroutines to do some
work. These goroutines block listening in on a channel, waiting for more work to
arrive. At some point, you want to signal these goroutines to stop accepting
more work and exit, so you can cleanly shut down the program.
&lt;/p&gt;

&lt;p&gt;This is how the code might look:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWork(chanWork chan *work) {
  for w := range chanWork {
    do(w)
  }
}

func main() {
  chanWork := make(chan *work, 100)
  for i := 0; i &amp;lt; N; i++ {
    go doWork(chanWork)
  }

  // Push work to chanWork.
  chanWork &amp;lt;- w

  // All work is done, now stop.
  close(chanWork)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code looks reasonable, &lt;strong&gt;with one caveat.&lt;/strong&gt; Once you close the chanWork
channel, the main exits immediately. Closing the channel only acts as a
signal. You want the program to wait as well.&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;sync.WaitGroup&lt;/code&gt; allows the goroutines to cleanly exit before exiting the main
program, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWork(chanWork chan *work, wg *sync.WaitGroup) {
  defer wg.Done()
  ...
}

func main() {
  var wg sync.WaitGroup
  chanWork := make(chan *work, 100)
  for i := 0; i &amp;lt; N; i++ {
    wg.Add(1)
    go doWork(chanWork, &amp;amp;wg)
  }

  // Push work to chanWork.
  chanWork &amp;lt;- w

  // All work is done, now stop.
  close(chanWork)

  // Now wait.
  wg.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For a Go programmer, this is pretty basic so far. And that&amp;rsquo;s because we had
access to the channel, which controls when the goroutine should exit.&lt;/p&gt;

&lt;p&gt;What happens in case we don&amp;rsquo;t have access to this channel? For, e.g., if we want to run
some execution periodically, we&amp;rsquo;ll have this situation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(wg *sync.WaitGroup) {
  defer wg.Done()
  timeChan := time.Tick(time.Second)

  for _ := range timeChan {
    do()  // some work
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case, we need a way to signal the goroutine to stop doing the work.
Say we use a signal channel like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(wg *sync.WaitGroup, signal chan struct{}) {
  defer wg.Done()
  timeChan := time.Tick(time.Second)

  for {
    select {
      case &amp;lt;- timeChan:
        do() // some work
      case &amp;lt;- signal:
        return
    }
  }
}

func main() {
  signal := make(chan struct{}, 1)

  ...

  signal &amp;lt;- struct{}{}  // To signal the goroutine to stop.
  wg.Wait() // Wait for goroutine to exit.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This code above would indicate to the goroutine to stop doing the work. And also
wait for it so &lt;code&gt;main&lt;/code&gt; can exit cleanly.&lt;/p&gt;

&lt;p&gt;All nice and good so far. Now, &lt;strong&gt;what if we have multiple different such goroutines, and
we need to signal and wait on them in some order.&lt;/strong&gt; For, e.g., we might have a
pipeline of sorts, with multiple stages, each dependent on the previous &lt;code&gt;A -&amp;gt; B
-&amp;gt; C&lt;/code&gt;. In this case, we need to signal and wait on &lt;code&gt;A&lt;/code&gt;, before we do that for
&lt;code&gt;B&lt;/code&gt; and then &lt;code&gt;C&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;With the above code, this would be cumbersome. You&amp;rsquo;d need multiple signal
channels, one for each stage; and similarly, multiple waits, one for each stage.
Would be nice to encapsulate this in a class. That&amp;rsquo;s what we have done in
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type LevelCloser struct {
    Name    string
    running int32
    nomore  int32
    closed  chan struct{}
    waiting sync.WaitGroup
}

func (lc *LevelCloser) Signal() {
    if !atomic.CompareAndSwapInt32(&amp;amp;lc.nomore, 0, 1) {
        // fmt.Printf(&amp;quot;Level %q already got signal\n&amp;quot;, lc.Name)
        return
    }
    running := int(atomic.LoadInt32(&amp;amp;lc.running))
    // fmt.Printf(&amp;quot;Sending signal to %d registered with name %q\n&amp;quot;,
                  running, lc.Name)
    for i := 0; i &amp;lt; running; i++ {
        lc.closed &amp;lt;- struct{}{}
    }
}

func (lc *LevelCloser) HasBeenClosed() &amp;lt;-chan struct{} {
	return lc.closed
}

func (lc *LevelCloser) Done() {
    if atomic.LoadInt32(&amp;amp;lc.running) &amp;lt;= 0 {
        return
    }

    running := atomic.AddInt32(&amp;amp;lc.running, -1)
    if running == 0 {
        lc.waiting.Done()
    }
}

func (lc *LevelCloser) Wait() {
    lc.waiting.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It&amp;rsquo;s a simple class with some basic APIs. The way you&amp;rsquo;d use it is like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func doWorkPeriodically(lc *LevelCloser) {
  defer lc.Done()
  timeChan := time.Tick(time.Second)

  for {
    select {
      case &amp;lt;- timeChan:
        do() // some work
      case &amp;lt;- lc.HasBeenClosed():
        return
    }
  }
}

func main() {
  lc := &amp;amp;LevelCloser{
    Name: name,
    closed: make(chan struct{}, 10),
    running: 1,
  }
  lc.waiting.Add(1)

  doWorkPeriodically(lc)

  lc.Signal()
  lc.Wait()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, to make it work for multiple stages, dependent or not, we wrap it up
into one &lt;code&gt;Closer&lt;/code&gt; class.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type Closer struct {
    sync.RWMutex
    levels map[string]*LevelCloser
}

func NewCloser() *Closer {
    return &amp;amp;Closer{
        levels: make(map[string]*LevelCloser),
    }
}

func (c *Closer) Register(name string) *LevelCloser {
    c.Lock()
    defer c.Unlock()

    lc, has := c.levels[name]
    if !has {
        lc = &amp;amp;LevelCloser{Name: name, closed: make(chan struct{}, 10)}
        lc.waiting.Add(1)
        c.levels[name] = lc
    }

    AssertTruef(atomic.LoadInt32(&amp;amp;lc.nomore) == 0, &amp;quot;Can&#39;t register with closer after signal.&amp;quot;)
    atomic.AddInt32(&amp;amp;lc.running, 1)
    return lc
}

func (c *Closer) Get(name string) *LevelCloser {
    c.RLock()
    defer c.RUnlock()

    lc, has := c.levels[name]
    if !has {
        log.Fatalf(&amp;quot;%q not present in Closer&amp;quot;, name)
        return nil
    }
    return lc
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Using this wrapper class, you can just create one &lt;code&gt;Closer&lt;/code&gt; object, and use that
to create and maintain all &lt;code&gt;LevelCloser&lt;/code&gt;s. This way, you can retrieve, and signal all
the &lt;code&gt;LevelCloser&lt;/code&gt;s individually in order, or just have &lt;code&gt;Closer&lt;/code&gt; signal all of
them, and then wait for all of them.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Closer) SignalAll() {
    c.RLock()
    defer c.RUnlock()

    for _, l := range c.levels {
        l.Signal()
    }
}

func (c *Closer) WaitForAll() {
    c.RLock()
    defer c.RUnlock()

    for _, l := range c.levels {
        l.Wait()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is how you&amp;rsquo;d use this class:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func stageA(lc *LevelCloser) {
  defer lc.Done()
  for {
    select {
      case &amp;lt;- someChan:
      case &amp;lt;- lc.HasBeenClosed():
        return
    }
  }
}

func stageB(lc *LevelCloser) {
  ...
}

func main() {
  closer := NewCloser()
  lc := closer.Register(&amp;quot;stage-a&amp;quot;)
  go stageA(lc)

  lc := closer.Register(&amp;quot;stage-b&amp;quot;)
  go stageB(lc)

  ...

  lc = closer.Get(&amp;quot;stage-b&amp;quot;)
  lc.SignalAndWait()

  closer.SignalAll()
  closer.WaitAll()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This class is being used by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, and
it significantly simplifies the various asynchronous activities going on
internally. We can ensure that our writes are all committed before in-memory
tables are flushed, before we close value log, and so on.&lt;/p&gt;

&lt;p&gt;You can see the entire &lt;a href=&#34;https://github.com/dgraph-io/badger/blob/master/y/y.go#L67-L170&#34;&gt;code
here&lt;/a&gt;. The code
is under &lt;a href=&#34;https://www.apache.org/licenses/LICENSE-2.0&#34;&gt;Apache 2.0&lt;/a&gt; license, so
feel free to copy the code and use it in your project. You can see the class in
&lt;a href=&#34;https://github.com/dgraph-io/badger/blob/master/kv.go#L253-L315&#34;&gt;action here&lt;/a&gt;. Look
for &lt;code&gt;closer.Register&lt;/code&gt; and &lt;code&gt;closer.Get&lt;/code&gt; to track how we create multiple such
&lt;code&gt;LevelCloser&lt;/code&gt;s and use them to maintain a strict opening and closing order
between the various stages.&lt;/p&gt;

&lt;p&gt;Hope you found this useful! Check out other posts to see how
&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34;&gt;Dgraph&lt;/a&gt; and
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can add value to your projects.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: Various stages of a &lt;a href=&#34;http://www.spacex.com/news/2015/06/24/why-and-how-landing-rockets&#34;&gt;SpaceX rocket launch&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Running Stack Overflow on Dgraph</title>
      <link>https://blog.dgraph.io/post/sql-vs-dgraph/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/sql-vs-dgraph/</guid>
      <description>

&lt;p&gt;We have been taught, conditioned, trained to use SQL all our lives as engineers.
It was there in schools, there when we went to college. It was being used at the
company that we joined. It was such a common interview question that it no
longer is. We don&amp;rsquo;t have just one, but an array of SQL databases to choose from.
MySQL was released 22 years ago, in 1995 (youngest engineer at Dgraph was born the
same year). PostgreSQL was released one year later. In contrast, MariaDB was
released in 2009.&lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s amazing about SQL is its sheer simplicity. &lt;em&gt;Select something where
something, order by something, limit by some number.&lt;/em&gt; This query probably
represents most DB queries run on the planet. You can achieve the same thing
with a single bash command over CSV files. &lt;em&gt;I joke that SQL DBs are a sort of
glorified CSV file servers.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;But, that&amp;rsquo;s also where lies its weakness. Its sheer simplicity. &lt;strong&gt;Because SQL
does fewer things, application developers need to write more logic.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-alternative&#34;&gt;The alternative&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Dgraph does joins.&lt;/strong&gt; Being a graph database, join is a &lt;em&gt;first-class&lt;/em&gt; citizen
in Dgraph. It&amp;rsquo;s optimized for expanding, intersecting and combining results from
multiple entity types &lt;em&gt;very fast&lt;/em&gt;. In fact, the internal mechanisms are exactly
how search engines work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph does recursions.&lt;/strong&gt; Recursion is essentially an edge traversal.
Traversing edges is very integral to Dgraph. Expanding out from a node is an
O(1) time complexity operation, a look up in hash map, or a single
read from disk.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dgraph supports flexible schema.&lt;/strong&gt; Dgraph separates storage layer from schema
layer. A developer can choose how much schema enforcement they want. Modifying
data types do not require data rewrite; and because (the equivalent of)
&lt;em&gt;tables&lt;/em&gt; are sparse in a graph database, one does not need to fit everything
into predefined columns, or deal with &lt;code&gt;NULL&lt;/code&gt;s.&lt;/p&gt;

&lt;h3 id=&#34;stack-overflow&#34;&gt;Stack Overflow&lt;/h3&gt;

&lt;p&gt;To put something concrete up for discussion, we&amp;rsquo;ll see how data gets arranged in
SQL and compare that with how it would be arranged in Dgraph. Folks at Stack
Exchange generously provide &lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;dumps of their
data&lt;/a&gt;, and &lt;a href=&#34;https://ia800500.us.archive.org/22/items/stackexchange/readme.txt&#34;&gt;the
schema&lt;/a&gt; that
they use run the site over SQL.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll pick the schema that they use to store and
serve the data that millions of developers browse through every day, and compare
that against how it would be if Dgraph were the underlying database instead of
SQL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s start with the User schema,&lt;/strong&gt; and see how SQL would compare with Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;User&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Reputation&lt;/td&gt;
&lt;td&gt;Reputation&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DisplayName&lt;/td&gt;
&lt;td&gt;DisplayName&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastAccessDate&lt;/td&gt;
&lt;td&gt;LastAccessDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Location&lt;/td&gt;
&lt;td&gt;Location&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AboutMe&lt;/td&gt;
&lt;td&gt;AboutMe&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;td&gt;Age&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Views&lt;/td&gt;
&lt;td&gt;Views&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;UpVotes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DownVotes&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here we have user&amp;rsquo;s reputation, creation date, display name, last access date,
location, about, age (&lt;em&gt;not date of birth?&lt;/em&gt;) and views (not tracking every single
page access, just a counter). All those are base data, i.e. new and unique data
that we must store.&lt;/p&gt;

&lt;p&gt;Then, the table has counts of upvotes and downvotes. But, those are being stored
elsewhere in &lt;code&gt;Vote&lt;/code&gt; table. These fields here are pre-computed counts to avoid
doing joins with &lt;code&gt;Vote&lt;/code&gt; table when querying for a user.&lt;/p&gt;

&lt;p&gt;Dgraph doesn&amp;rsquo;t need to store these. It can do counts and sorts on them via
queries efficiently.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s look at the Versioning and Post table,&lt;/strong&gt; where most of the action happens.
These tables store the questions, answers, tags, ownership, and authorship
information.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Versioning&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TypeId&lt;/td&gt;
&lt;td&gt;Type&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;PostId&lt;/td&gt;
&lt;td&gt;Post (point to Post)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;td&gt;Text&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Post&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;TypeId&lt;/td&gt;
&lt;td&gt;Type&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ParentId&lt;/td&gt;
&lt;td&gt;Has.Answer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AcceptedAnswerId&lt;/td&gt;
&lt;td&gt;Chosen.Answer&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Title (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Title (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Body  (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Body  (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Tags  (duplicate of versioning)&lt;/td&gt;
&lt;td&gt;Tags  (point to Version)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;OwnerUserId&lt;/td&gt;
&lt;td&gt;Owner (point to User)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Score&lt;/td&gt;
&lt;td&gt;Score&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastEditorUserId&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastEditDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;LastActivityDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CommentCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;AnswerCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;FavoriteCount&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CreationDate&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Version table is pretty straightforward. It stores type, post id, creation date,
author, and text. Instead of storing ids, Dgraph creates a relationship
from Version to Post.&lt;/p&gt;

&lt;p&gt;Post table is the interesting one, and &lt;em&gt;shows how much data duplication needed
to happen to avoid joins.&lt;/em&gt; We have the text of title, body, and tags from the latest
version stored in this table. In fact, the latest version isn&amp;rsquo;t even written.
Version only gets created when a user modifies the title, body or tags. And
because of this requirement to proxy for Version table, Post table stores last
editor, last edit date, which would become the author and creation date
respectively when moved to Version table.&lt;/p&gt;

&lt;p&gt;All these fields are unnecessary in Dgraph. Dgraph can directly store an edge to
the Version node which contains the text of title and body. We chose to store
tags differently. For each tag, we create a node and create an edge between the
post and the tag. This allows us to run aggregations over tags, and find the
most popular and most related tags easily.&lt;/p&gt;

&lt;p&gt;Then, we have pre-computed counts of comments, answers, and favorites. Dgraph can
generate all this at query time efficiently; using them to do sorting as well.
So, they don&amp;rsquo;t need to be pre-computed in Dgraph.&lt;/p&gt;

&lt;p&gt;CreationDate and LastActivityDate are both redundant information, that can be
deduced by doing recursion. They form good candidates for optimization later on,
but are not needed and hence are not present in Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Comment, Vote&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;SQL&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PostId (Vote/Comment -&amp;gt; Post)&lt;/td&gt;
&lt;td&gt;(New edge from Post -&amp;gt; Vote/Comment)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Timestamp&lt;/td&gt;
&lt;td&gt;Timestamp&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;td&gt;Author&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;VoteType (for Vote)&lt;/td&gt;
&lt;td&gt;Score (for both Vote and Comment)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Text     (for Comment)&lt;/td&gt;
&lt;td&gt;Text  (for Comment)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Finally, we have the comment and vote tables.&lt;/strong&gt; Because SQL doesn&amp;rsquo;t store
lists of things in a single row, you must create another table and point it back
to the original row.  A post contains comments. But in SQL, it&amp;rsquo;s the reverse. A
comment table row points to the post.  This is such a common hack that it&amp;rsquo;s no
longer considered one.&lt;/p&gt;

&lt;p&gt;In Dgraph, a Post has an edge to the vote or comment, not the other way round.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This is how the final Dgraph schema looks.&lt;/strong&gt; It&amp;rsquo;s a lot simpler than SQL.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/schema.png&#34; alt=&#34;Dgraph Schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In fact, SQL schema complexity increases rapidly as the relationships among
data increase.&lt;/em&gt; Each relationship would inadvertently require joins, which would
then need to be avoided by duplicating more information across tables. All this
adds a significant amount of application logic to deal with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Conversely, in a graph database like Dgraph, schema is a pretty close
representation of your mind map.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;queries&#34;&gt;Queries&lt;/h3&gt;

&lt;p&gt;In the previous section, we saw that Dgraph schema is a lot simpler than the
equivalent SQL schema. In this section, we&amp;rsquo;ll see why that is the case, and how
Dgraph&amp;rsquo;s GraphQL inspired query language makes it easy to render various
Stack Overflow (referred to as SO) components.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: While reading the queries, note that these queries are just our
approximations of how SO works. We don&amp;rsquo;t work there, and thence, certain things
like ranking formulas are just put together to represent the power of the query
language. It&amp;rsquo;s not what SO uses.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Let&amp;rsquo;s start with the home page.&lt;/strong&gt; We want to render 100 questions, and
all the associated meta information that SO shows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Question Div&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is the corresponding query fragment to retrieve the data to render one question div.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-question.png&#34; alt=&#34;Home page question&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_uid_  # Unique identifier

UpvoteCount: count(Upvote)      # Counts the number of Upvote edges.
DownvoteCount: count(Downvote)  # Counts the number of Downvote edges.
AnswerCount: count(Has.Answer)  # Counts the number of Answer edges.

ViewCount  # Retrieves the ViewCount property stored.

Title { # Title points to Version node.
  Text  # Retrieves the text of the title.
}

Owner { # Owner of the question, points to the User node.
  DisplayName  # User&#39;s display name, reputation, and identifier.
  Reputation
  _uid_
}

Tag {  # Points to multiple Tag nodes.
  TagName: Tag.Text  # Retrieves the text of the tag.
}

Has.Answer(orderdesc: Timestamp, first: 1) {  # Picks the most recent answer.
  Timestamp  # Retrieves Timestamp of the Answer.
  Owner {    # Retrieves the Owner of that Answer.
    DisplayName  # Retrieves display name, reputation, and identifier.
    Reputation
    _uid_
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now that we have the question fragment let&amp;rsquo;s see how to retrieve a list of
questions depending upon the various tabs that SO shows.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Latest 100 questions&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# All nodes of type question, in descending order by Timestamp, limit by 100.
questions(func: eq(Type, &amp;quot;Question&amp;quot;), orderdesc: Timestamp, first: 100) {
  ${questionFragment}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Top 100 hot questions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-hot-questions.png&#34; alt=&#34;Home page hot questions&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Get the latest 1000 questions.
var(func: eq(Type, &amp;quot;Question&amp;quot;), orderdesc: Timestamp, first: 1000) {
  Has.Answer {            # Get their answers
    uv as count(Upvote)   # Count the Upvote edges.
    dv as count(Downvote) # Count the number of Downvote edges.
  }
  ac as count(Has.Answer) # Count the number of Answers.
  cc as count(Comment)    # Count the number of Comments.

  uv1 as sum(var(uv))     # Sum up all Upvotes across all Answers.
  dv1 as sum(var(dv))     # Sum up all Downvotes across all Answers.

  # Put together a rough formula to calculate a final score per question.
  score as math(0.7 + ac * 0.2  + (uv1 - dv1) * 0.4 + (cc) * 0.4)
}

# Order the 1000 questions in descending order of score, pick the first 100.
questions(id: var(score), orderdesc: var(score), first: 100) {
  ${questionFragment}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Top Tags&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/homepage-toptags.png&#34; alt=&#34;Top tags&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To get the most frequently used tags, we can run this query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;t as var(func: eq(Type, &amp;quot;Tag&amp;quot;)) {  # Retrieve all tags. Assign it to variable t.
  c as count(~Tag)  # For each tag, count the number of incoming edges.
                    # This gives us the number of times each tag is used.
}

# For all tags in t, order them by count c and pick the first 10.
# This gives us the ten most popular tags.
topTags(id: var(t), orderdesc: var(c), first: 10) {
  _uid_
  TagName: Tag.Text      # Retrieve the text of the tag.
  QuestionCount: var(c)  # Reusing variable c, retrieve the number of times tag is used.
      # Note that only questions have tags. Hence we use QuestionCount alias.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Depending upon the number of tags, this query might be a tad slow. The most
popular tags don&amp;rsquo;t change that often. So, this is a good candidate for caching
in application. But, even so, the amount of application code that needs to go in
to generate the list of most popular tags is very little (run the query, cache
the results).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/question.png&#34; alt=&#34;Question&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Now let&amp;rsquo;s see how to render the question page.&lt;/strong&gt; This is one complex page, with
many components, touching almost all the tables in SQL. We&amp;rsquo;ll see how we can get
all the information in a single query to Dgraph.&lt;/p&gt;

&lt;p&gt;Before we dig into the question query, let&amp;rsquo;s create a bunch of reusable
fragments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Version Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Author {       # Retrieve Author node.
  DisplayName  # Retrieve their display name, reputation, and identifier.
  Reputation
  _uid_
}
Type  # Retrieve type, text and timestamp of Version.
Text
Timestamp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Comment Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;_uid_
Author {       # Retrive Author node.
  _uid_        # Retrieve their display name and identifier.
  DisplayName
}
Text  # Retrieve Text, Score and Timestamp of Comment (no versioning here).
Score
Timestamp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Answer Fragment&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Answer is represented as a Post node.
_uid_

Body {  # Retieve body Version node.
  Text  # Retrieve text of Body.
}

# This is used for &amp;quot;answered x time ago.&amp;quot;
Owner {        # Retrieve owner User node.
  DisplayName  # Retrieve their display name, reputation, and identifier.
  Reputation
  _uid_
}

Timestamp  # Retrieve timestamp and type of Post.
Type

UpvoteCount: count(Upvote)     # Count the number of Upvote and Downvote edges.
DownvoteCount: count(Downvote)

# Post edge takes us from Version -&amp;gt; Post. ~Post is the reverse of that, taking us from Post -&amp;gt; Version. We order the Version nodes in desc order of Timestamp and pick the first 1. In other words, pick the latest Version of Answer.
# This is used for &amp;quot;edited x time ago.&amp;quot;
History: ~Post(orderdesc: Timestamp, first: 1) {
  ${VersionFragment}
}

# These are comments on answer. Question also have comments which are retrieved in the query below.
Comment {             # Get the Comment nodes.
  ${CommentFragment}  # Retrieve further details per Comment using fragment above.
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Question&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var (id: ${questionUID}) {  # Retrieve the question node.
    Has.Answer {              # Retrieve the answers.
      uv as count(Upvote)     # Count the number of Upvote and Downvote edges.
      dv as count(Downvote)
      answer_score as math(uv - dv)  # Calculate an score per answer based on votes.
    }
  }

  question(id: ${questionUID}) {  # Retrieve the question node.
    _uid_
    Title {  # Retrieve the title Version node.
      Text   # Retrieve the text of the title.
    }
    Body {   # Retrieve the body Version node.
      Text   # Retrieve the text of the body.
    }
    Owner {        # Retrieve the owner of the question.
      DisplayName  # Retrieve their display name, reputation, and identifier.
      Reputation
      _uid_
    }

    ViewCount  # Retrieve some question properties.
    Timestamp
    Type

    UpvoteCount: count(Upvote)  # Count the number of Upvote and Downvote edges on question.
    DownvoteCount: count(Downvote)

    questionTags as Tag {  # Retrieve the question Tag nodes.
      TagName: Tag.Text    # Retrieve their text.
    }

    AnswerCount: count(Has.Answer)  # Count the number of answers.

    Has.Answer(orderdesc: var(answer_score)) {  # Retrieve the Answer nodes, and order them by the score calculated above.
      ${AnswerFragment}  # Retrieve answer details using fragment above.
    }

    Comment {  # Retrieve Comment nodes.
      ${CommentFragment}  # Retrieve comment details using fragment above.
    }

    History: ~Post(orderdesc: Timestamp, first: 1) {  # Just like in Answer, retrieve the latest Version of question.
      ${VersionFragment}  # Retrieve Version details using fragment above.
    }
  }

  # In the following query block, we use the tags of this question, to get related questions, and some minimal details about them; essentially title and vote counts.
  tags(id: var(questionTags)) {
    relatedQuestions: ~Tag(first: 10) {
      _uid_
      Title {
        Text
      }
      UpvoteCount: count(Upvote)
      DownvoteCount: count(Downvote)
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the query above looks complex, don&amp;rsquo;t worry about it. Just read the comments, and get a sense for how we retrieve each piece of data that we need to render on the page. SO question page as mentioned before is pretty complex requiring recursions to retrieve all details of questions, comments, votes, owner, last editor. Similarly, we need answers, their comments, votes, owner, last editor. On top of that, we can sort the answers displayed by a score generated from vote counts. We can even limit the number of comments displayed if required.&lt;/p&gt;

&lt;p&gt;With SQL DB, all of this logic would have needed to be baked into the application. But, with Dgraph, the query language is so powerful that it can all be generated right within the database: doing recursions, computing counts, putting them to generate scores and then sort by these scores. This cuts down heavily on the application code, letting a developer focus on the feature set and the best way to render the data. And &lt;strong&gt;that&amp;rsquo;s powerful!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Full Text Search&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Dgraph also supports regular expression and full-text search in many languages.
You can create an index on string edges, to achieve this. In this case, we
created a full-text index on the &lt;code&gt;Text&lt;/code&gt; edge.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;Text: string @index(fulltext) .&lt;/code&gt; line from schema.txt.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: anyoftext(Text, &amp;quot;${searchQuery}&amp;quot;)) @cascade {
  # All Version nodes which have any of the text in search query.
    p as Post {  # Retrieve their Post, assign it to variable p.

      # Pick the latest Version of the Post and check that it does have the search query. This is a bit of a shuffle and can be avoided by having a direct link from Post to its latest version.
      ~Post(orderdesc: Timestamp, first: 1) @filter(anyoftext(Text, &amp;quot;${searchQuery}&amp;quot;))
    }
  }

  # Pick the first 25 such posts.
  posts(id: var(p), first: 25) {
    _uid_

    Type

    question: ~Has.Answer {  # If this post is an answer, retrieve the question by traversing the Has.Answer edge in reverse.
      _uid_
      Title {
        Text
      }
    }

    Title { # Title Version would be present if this Post if Question.
      Text
    }
    Body {  # Body Version would be present if this Post is Answer.
      Text
    }

    # The rest of the fields are as explained before, and are from the perspective of the question Post node.
    Owner {
      DisplayName
      Reputation
      _uid_
    }
    Tag {
      TagName: Tag.Text
    }
    Chosen.Answer {
      Owner {
        DisplayName
        Reputation
        _uid_
      }
      Timestamp
    }
    UpvoteCount: count(Upvote)
    DownvoteCount: count(Downvote)
    AnswerCount: count(Has.Answer)
    ViewCount
    Timestamp
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;In this post, we showed you how a SQL schema compares against the equivalent
schema in Dgraph, basing our analysis on Stack Overflow data. We then picked
pages from Stack Overflow and showed you queries to retrieve all the data
necessary to render those pages.&lt;/p&gt;

&lt;p&gt;As you can see, Dgraph schema is significantly simpler than SQL, utilizing zero
or little schema hacks, pre-computation or duplication of data. Also,
Dgraph query language is way more powerful than SQL, handling most of the
complexity of recursive data retrieval, ranking and sorting within the database,
allowing the application to focus solely on the feature set and rendering of
data.&lt;/p&gt;

&lt;p&gt;Dgraph being a graph database provides sparsely populated fields and easy schema
manipulation, which allows developers to modify data types as they iterate over
their application, removing the need to do complex &lt;em&gt;upgrades&lt;/em&gt; of the entire system.&lt;/p&gt;

&lt;p&gt;Not only that, Dgraph makes it a lot faster for developers to iterate.
Modifying Dgraph queries is a lot cheaper operation for a developer,
than modifying the backend code; and Dgraph provides a nice UI to allow for
this.&lt;/p&gt;

&lt;p&gt;Finally, Dgraph supports regular expressions, term matching, full-text search
and equality matching for string types. All Dgraph edges are unidirectional, but
Dgraph allows you to specify creating reverses automatically, to aid in data
retrieval. It also supports indexing various other data types, like int, float,
datetime, etc.; very useful to build applications today.&lt;/p&gt;

&lt;p&gt;Overall, this post sheds light on why we think a graph database like Dgraph is a
better choice for developers today. It simplifies the data model,
significantly cuts down on the backend code, and allows faster iteration.&lt;/p&gt;

&lt;h3 id=&#34;links&#34;&gt;Links&lt;/h3&gt;

&lt;p&gt;All the data generation, querying and rendering code is located at &lt;a href=&#34;https://github.com/dgraph-io/graphoverflow&#34;&gt;Dgraph&amp;rsquo;s Graph Overflow repository&lt;/a&gt;. Dgraph query language spec is &lt;a href=&#34;https://docs.dgraph.io/query-language/&#34;&gt;located here&lt;/a&gt;. Graph overflow site is still a work in progress, and we&amp;rsquo;ll put it up at dgraph.io soon.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/dragon&#34;&gt;Dragon&lt;/a&gt; is a next-generation spacecraft designed to take humans to Mars.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a Realtime Recommendation Engine: Part 2</title>
      <link>https://blog.dgraph.io/post/recommendation2/</link>
      <pubDate>Fri, 30 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/recommendation2/</guid>
      <description>

&lt;p&gt;&lt;em&gt;This is part 2 of a two-part series on recommendations using Dgraph.  Check our &lt;a href=&#34;https://blog.dgraph.io/post/recommendation/&#34;&gt;part 1 here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In the last post, we looked at how many applications and web apps no longer present static data, but rather generate interesting recommendations to users.  There&amp;rsquo;s a whole field of theory and practice in recommendation engines that we touched on, talking about &lt;strong&gt;content-based&lt;/strong&gt; (based on properties of objects) and &lt;strong&gt;collaborative&lt;/strong&gt; (based on similar users) filtering techniques based on a chapter from Stanford MOOC &lt;a href=&#34;https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about&#34;&gt;Minning Massive Datasets&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We dug deeper into content-based filtering and showed how &lt;em&gt;Jaccard&lt;/em&gt; distance and &lt;em&gt;Cosine&lt;/em&gt; distance can be encoded directly in Dgraph queries using Dgraph&amp;rsquo;s variables and math functions.&lt;/p&gt;

&lt;p&gt;This time we&amp;rsquo;ll look into collaborative filtering and hybrid recommendations in Dgraph queries.  Then we&amp;rsquo;ll look at how to build a real-time scalable recommendation engine for big graphs.&lt;/p&gt;

&lt;p&gt;To start with, we&amp;rsquo;ll continue with our &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;movie data&lt;/a&gt; from last time and then start looking at recommendations over Stack Exchange data.  We&amp;rsquo;ll keep it small in this post and use &lt;a href=&#34;https://lifehacks.stackexchange.com/&#34;&gt;Lifehacks&lt;/a&gt; data, but watch out for upcoming posts on loading all of Stack Overflow (2 Billion edges) into Dgraph and running the website and a recommendation engine with Dgraph as the backend.&lt;/p&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;h2 id=&#34;collaborative-filtering&#34;&gt;Collaborative filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering measures the similarity of objects based on their properties.
&lt;strong&gt;Rather than trying to find similar items, collaborative filtering works by finding similar users and then recommending items that similar users have rated highly.&lt;/strong&gt;  In the movie example from &lt;a href=&#34;https://blog.dgraph.io/post/recommendation/&#34;&gt;part 1&lt;/a&gt;, for a given user we first find the set of users that are similar, find movies those users rated highly and recommend some that our user hasn&amp;rsquo;t seen.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s say we are trying to recommend movies to Bob.&lt;/em&gt; If Bob and Alice have rated a movie highly and they
do this repeatedly for many movies, they are similar. The more movies they have in common this way,
the more similar Bob and Alice are. Once we have more similar users like Alice, we need to find those movies that
these users have rated highly. We then remove the movies that Bob has seen, leaving movies we should recommend to Bob.&lt;/p&gt;

&lt;p&gt;If we represent the movies that user $U_i$ and user $U_j$ have in common as&lt;/p&gt;

&lt;p&gt;$$M_{(u_i,u_j)}$$&lt;/p&gt;

&lt;p&gt;and write $R_{U_i}$ for a user&amp;rsquo;s rating function, then we can represent a distance (or similarity) score between two users as an average of their scores for the movies they both rated.&lt;/p&gt;

&lt;!--$$\frac{\sum{R_{U_i}(M_{(u_i,u_j)})} + \sum{R_{U_j}(M_{(u_i,u_j)})}}{|M_{(u_i,u_j)}|}$$--&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/collab_diff1.png&#34; alt=&#34;collaborative distance 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is how the query would look in Dgraph.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {                             # 1
    a as math(1)
    seen as rated @facets(r as rating) {  # 2
      ~rated @facets(sr as rating) {      # 3
        user_score as math((sr + r)/a)    # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) {  # 5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) {           # 6
      fscore as math(ur/norm)                                      # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note that this query is slightly different from the
formula in MOOC chapter, because although we can write cosine distance for content-based filtering
directly in the query language, the language does not yet support cosine distance when it
involves more than 1 traversal. However, this can be tackled by retrieving the subgraph from Dgraph,
doing the computation and writing the similarity scores back to Dgraph for further processing.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let us look at what different parts of the query do.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with a user whose id is 2 (our Bob)&lt;/li&gt;
&lt;li&gt;Get all the movies that this user has rated and their ratings&lt;/li&gt;
&lt;li&gt;Get all the users who have rated these movies and the corresponding ratings given by them (the Alices)&lt;/li&gt;
&lt;li&gt;Calculate the similarity to those users according to our metric&lt;/li&gt;
&lt;li&gt;Take the top 10 users based on the score calculated in the last step (the similar users)&lt;/li&gt;
&lt;li&gt;Get the ratings by the similar users for movies not seen by the user 2&lt;/li&gt;
&lt;li&gt;Normalize the rating as sum of all the ratings divided by number of ratings&lt;/li&gt;
&lt;li&gt;Get the top 10 movies based on the score calculated in the last step&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Recommendation&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;Hercules (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;How to Be a Player (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Othello (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;U Turn (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Edge, The (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Arrival, The (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Outlaw, The (1943)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Con Air (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;From Dusk Till Dawn (1996)&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;collaborative-filtering-only-with-high-scores&#34;&gt;Collaborative filtering, only with high scores&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s make an improvement.&lt;/em&gt; Consider the case when user A rated &lt;code&gt;movie-a&lt;/code&gt; 1, user B rated &lt;code&gt;movie-a&lt;/code&gt; 5, user A rated &lt;code&gt;movie-b&lt;/code&gt; 3 and user C rated &lt;code&gt;movie-b&lt;/code&gt; 3. Based on the average score for common movies, both user B and C will have a score of 3. But intuitively, we can say that user C is more similar to A than B. One way to avoid this would be by considering only the &lt;em&gt;good&lt;/em&gt; ratings which we can define as &amp;gt;= 3.&lt;/p&gt;

&lt;p&gt;So we can add a filter when we&amp;rsquo;re getting the ratings as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Collaborative filtering
{
  var(func: uid(2)) {  # 1
    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {     # 3
        user_score as math((sr + r)/a) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { # 5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) {          # 6
      fscore as math(ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;Recommendation&amp;quot;: [
    {
      &amp;quot;name&amp;quot;: &amp;quot;Thinner (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Tales from the Hood (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Michael (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Hour of the Pig, The (1993)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Basic Instinct (1992)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Wild Bunch, The (1969)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Bound (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Richard III (1995)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Spitfire Grill, The (1996)&amp;quot;
    },
    {
      &amp;quot;name&amp;quot;: &amp;quot;Garden of Finzi-Contini, The (Giardino dei Finzi-Contini, Il) (1970)&amp;quot;
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try and test how well this is working.  We don&amp;rsquo;t have any live users to test on, but one measure can be how well it predicts the known data.  &lt;em&gt;We removed the following 5 movies that user 2 rated as 5 and ran the query
to predict the ratings.&lt;/em&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e5d&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e6e&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e77&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e79&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;
        },
        {
          &amp;quot;_uid_&amp;quot;: &amp;quot;0x30e7c&amp;quot;,
          &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The predicted ratings are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
          &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 5
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 3
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 5
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 3.833333
        },
        {
          &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
          &amp;quot;var(fscore)&amp;quot;: 4.666667
        }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So 2 of the movies got 5 rating, one got 4.66, one 3.83, and one 3. &lt;em&gt;Not bad for a single query!&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;collaborative-filtering-with-penalty&#34;&gt;Collaborative filtering, with penalty&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Let&amp;rsquo;s tweak it some more.&lt;/em&gt;  If the ratings by two users vary too, much they might not be as similar. For example, taking a straight average, ratings of 3 and 3 by the two users look the same as 5 and 1.  So lets penalize each user by the difference in rating &amp;mdash; as the rating difference grows the penalty increases.&lt;/p&gt;

&lt;p&gt;In the query below we multiply the average by:&lt;/p&gt;

&lt;p&gt;$$1 - {(\frac{sr-r}{5*a})}^2$$&lt;/p&gt;

&lt;p&gt;If the difference between ratings is small, the multiple will be closer to 1.  If the difference is larger, the multiple will be closer to 0, reducing the user&amp;rsquo;s similarity.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {  # 1
    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {     # 3
        user_score as math(
        (sr + r)/a *
        (1 -  pow((sr-r)/(5*a),
        2))) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { #5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) { # 6
      fscore as math(ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    val(fscore)
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Predicated ratings for the ones that were removed from the dataset are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        {
            &amp;quot;name&amp;quot;: &amp;quot;Secrets &amp;amp; Lies (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 5.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;L.A. Confidential (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 2.75
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 5.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Titanic (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 4.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 4.666667
        },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The scores got closer to the removed actual scores, probably indicating that we removed some users from the similar users who didn&amp;rsquo;t vote highly for this movie.  &amp;ldquo;L.A. Confidential&amp;rdquo; was a bit of an outlier, going back slightly, indicating that we removed some users who enjoyed this one.&lt;/p&gt;

&lt;h2 id=&#34;hybrid-filtering&#34;&gt;Hybrid filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering found similar movies, based on a given movie.  Collaborative filtering found similar users and gave a recommendation of movies the similar users rated highly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hybrid filtering is when we combine the collaborative and content-based approaches into a single recommendation algorithm.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For our hybrid filtering, we&amp;rsquo;ll assign a score to each genre as the number of movies watched by user 2 in that genre. Then, after we&amp;rsquo;ve found the similar users, we&amp;rsquo;ll give a boost to the ratings of movies based on the genres that user 2 watches most.  That&amp;rsquo;s collaborative filtering to get the similar users and the movies they enjoy, and then content-based filtering to help order those movies based on genres.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(2)) {  # 1
    rated @groupby(genre) {
      gc as count(_uid_)
    }

    a as math(1)
    seen as rated @facets(r as rating) @facets(ge(rating, 3)) { # 2
      ~rated @facets(sr as rating) @facets(ge(rating, 3)) {   # 3
        user_score as math((sr + r)/a) # 4
      }
    }
  }

  var(func: uid(user_score), first:30, orderdesc: val(user_score)) { #5
    norm as math(1)
    rated @filter(not uid(seen)) @facets(ur as rating) { # 6
      genre {
        q as math(gc)   # 6.1
      }
      x as sum(val(q))  # 6.2
      fscore as math((1+(x/100))*ur/norm) # 7
    }
  }

  Recommendation(func: uid(fscore), orderdesc: val(fscore), first: 10) { # 8
    val(fscore)
    name
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This time, at step &lt;code&gt;#1&lt;/code&gt; the query gets a count of how many times our user has rated movies in each genre using Dgraph&amp;rsquo;s &lt;code&gt;groupby&lt;/code&gt;, so &lt;code&gt;gc&lt;/code&gt; will relate genres to number of movies rated in that genre.  Then, before calculating the score for each movie at step &lt;code&gt;#7&lt;/code&gt;, the query gives each genre in the movie a score, step &lt;code&gt;6.1&lt;/code&gt;, and sums a total score, step &lt;code&gt;6.2&lt;/code&gt;.  At step &lt;code&gt;#7&lt;/code&gt; each movie&amp;rsquo;s average score is multiplied by $1+\frac{x}{100}$.&lt;/p&gt;

&lt;p&gt;If a movie contains genres our user doesn&amp;rsquo;t watch so much, $\frac{x}{100}$ will be small and the movie won&amp;rsquo;t get much of a boost.  If it contains genres our user often rates movies of, then $x$ will be larger and thus $1+\frac{x}{100}$ will give a bigger bonus.&lt;/p&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;Recommendation&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Bound (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 8.15
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Wings of the Dove, The (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.75
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Kiss the Girls (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.45
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Legends of the Fall (1994)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.4
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Jane Eyre (1996)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Crying Game, The (1992)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 7.065
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;To Catch a Thief (1955)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.95
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;American President, The (1995)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.857143
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Sirens (1994)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.813333
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;As Good As It Gets (1997)&amp;quot;,
            &amp;quot;var(fscore)&amp;quot;: 6.813333
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With the collaborative filtering queries, the scores for the test movies were high, but so were many other movies that the similar users enjoyed.  The hybrid approach skews the result back more towards the genres that our user watches most. In the results, two of the 5-star rated movies (&lt;code&gt;Wings of the Dove, The (1997)&lt;/code&gt; and &lt;code&gt;As Good As It Gets (1997)&lt;/code&gt;) showed up in the top 10.&lt;/p&gt;

&lt;h2 id=&#34;scaling-recommendations&#34;&gt;Scaling recommendations&lt;/h2&gt;

&lt;p&gt;If you look carefully at the last query, you can see that the graph size explodes very easily.
Say you rated 50 movies and those movies were rated by 20000 other people on average, you touch 1M nodes every time
you want to run this recommendation query.  If we are running many of these queries for different users or as the graph grows, this could get too much.&lt;/p&gt;

&lt;p&gt;So let&amp;rsquo;s look at how we can make this efficient by storing intermediate results back. In general,
people rate a movie less frequently than they view recommendations. Thus, the frequency of rating
updates is less than the frequency of generating recommendations.  So if we can calculate the
similarity scores only when a user rates a movie, and store it back to Dgraph; we can retrieve the
recommended movies cheaply by using this stored similarity score between users.&lt;/p&gt;

&lt;p&gt;For this, we can run the first part of the query, which calculates the similar users and store the top scores in an edge connecting
the users. Now, when we want to do recommendation, we can directly get the top similar users and then just have to do the 2nd part
of the query which is getting the average ratings for the movies that these similar users rated.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/newedge.png&#34; alt=&#34;Edge creation with score&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that this would require some extra code in the application which creates these edges when an
update happens but can make the recommendation query highly performant even for extremely large
datasets.  Typically user similarity scores are generated as a batch process. With this approach, we
can generate these scores incrementally, triggered by user actions; which would also improve the
freshness of the recommendations.&lt;/p&gt;

&lt;h2 id=&#34;stack-overflow&#34;&gt;Stack Overflow&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s look at a different kind of dataset which has users, posts (questions, answers, comments),
upvotes, downvotes, etc. This has around 450k triples in it and was obtained from Lifehacks Stack Exchange forum.&lt;/p&gt;

&lt;p&gt;Say we want to recommend what a user should read based on their upvotes. This is similar to the
collaborative filtering we saw in the last section.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Find similar users who have upvoted the same content.&lt;/li&gt;
&lt;li&gt;Then find the content similar users have upvoted but the given user has not interacted with.&lt;/li&gt;
&lt;li&gt;Then, to order the content we can see how many of the similar users have upvoted the content.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;First, let&amp;rsquo;s take a look at the schema for a part of the data that is of interest to us.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/soSchema.png&#34; alt=&#34;Stack Overflow schema&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The query to do collaborative filtering on this dataset is as follows:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Recommend similar questions to read based on upvote.
{
  user as var(func: eq(DisplayName, &amp;quot;Mooseman&amp;quot;)) { # 1
    a as math(1)
    ~Author { # 2
      seen as ~Upvote { # 3
        Upvote {    # 4
          Author {  # 5
            sc as math(a)
          }
        }
      }
    }
  }

  var(func: uid(sc), orderdesc: val(sc), first: 50) @filter(not uid(user)) {  # 6
    b as math(1)
    ~Author { # 7
      ~Upvote @filter(not uid(seen) and eq(Type, &amp;quot;Question&amp;quot;)) { # 8
        fsc as math(b)
      }
    }
  }

  topQ(func: uid(fsc), orderdesc: val(fsc), first: 10) {  # 9
    Title {
      Text
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at what the numbered lines in the query represent:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Start with a user whose name is &lt;code&gt;Mooseman&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;~Author&lt;/code&gt; edge which leads to the votes he has created&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;~Upvote&lt;/code&gt; edge which leads us to the posts he has upvoted&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;Upvote&lt;/code&gt; edge to get all the upvotes on these posts&lt;/li&gt;
&lt;li&gt;Traverse the &lt;code&gt;Author&lt;/code&gt; edge to get the users who created these upvotes and store the number of paths between the starting user and this user in a variable &lt;code&gt;sc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Pick the top 50 users by the score we calculated&lt;/li&gt;
&lt;li&gt;Get the upvotes created by these users&lt;/li&gt;
&lt;li&gt;Get the posts which are of type question not seen by &lt;code&gt;Mooseman&lt;/code&gt; and assign them a score which is the number of upvotes by these top (similar) users. This score is store in variable &lt;code&gt;fsc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Use the score we calculated in &lt;code&gt;fsc&lt;/code&gt; to get the top 10 questions&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &amp;quot;topQ&amp;quot;: [
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I keep my cat off my keyboard?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How do I stop my earphones from getting tangled&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Ηow can I keep my jeans&#39; zippers from unzipping on their own?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I work out my girlfriend&#39;s ring size, without asking her or using a ring?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I improvise a magnifying glass?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Sleeping in a noisy environment&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I black out a bright bedroom at night?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How do I stop cars from tailgating?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;Driving into garage where there is little room for error?&amp;quot;
        }
      ]
    },
    {
      &amp;quot;Title&amp;quot;: [
        {
          &amp;quot;Text&amp;quot;: &amp;quot;How can I boost my wifi range?&amp;quot;
        }
      ]
    }
  ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To make this recommendation scalable, we can create an edge between the most similar users
when an update (in this case, an upvote) happens. Then, when a user logs in, we can cheaply compute
their recommendations using these edges directly.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With that, we conclude this post.&lt;/em&gt; In this post, we showed how collaborative filtering based on similar users can be encoded in Dgraph queries.  We showed a couple of approaches so you can get a flavour of the kind of flexibility Dgraph allows. We also combined content-based and collaborative approaches into a hybrid recommendation system that found similar users and then ranked movies with genres our user enjoyed.&lt;/p&gt;

&lt;p&gt;Content-based filtering can be useful when recommending to users who have rated few movies. This is how websites bootstrap recommendation when you join, for example, by asking for your 5 favourite movies and then showing movies that are similar to them. Then, as you start rating movies, a switch to collaborative filtering utilizes user similarity and starts to improve recommendations further.&lt;/p&gt;

&lt;p&gt;We can&amp;rsquo;t tell you what metrics will work best in your case &amp;mdash; that&amp;rsquo;ll be based on your data and users and a fair amount of thinking and experimenting.  But what we&amp;rsquo;ve done here is to show you how you can translate your ideas into reality using Dgraph. &lt;em&gt;Hope this gets you started on the path to adding a recommendation system in your application.&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&#34;coming-up&#34;&gt;Coming up&lt;/h3&gt;

&lt;p&gt;Watch out for an upcoming series of posts where we explore how typical web apps can benefit from Dgraph.  We&amp;rsquo;ll show how we loaded all the data from the &lt;a href=&#34;https://archive.org/details/stackexchange&#34;&gt;Stack Overflow data dumps&lt;/a&gt;, which is more than 2 billion edges, into Dgraph and run Stack Overflow with Dgraph as the sole backend DB.  We&amp;rsquo;ll explore the tradeoffs that are made in doing this in SQL vs a graph database and we&amp;rsquo;ll look at the recommendation engine we&amp;rsquo;re building on top of all that Stack Overflow data.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://3c1703fe8d.site.internapcdn.net/newman/gfx/news/2017/1-amazingspace.jpg&#34;&gt;A stunning view of the Falcon 9 rocket just before landing on a barge&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Build a Realtime Recommendation Engine: Part 1</title>
      <link>https://blog.dgraph.io/post/recommendation/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/recommendation/</guid>
      <description>

&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;

&lt;p&gt;In today&amp;rsquo;s world, user experience is paramount. It&amp;rsquo;s no longer about basic CRUD, just serving user
data; it&amp;rsquo;s about mining the data to generate interesting predictions and suggesting actions to the
user.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the field of recommendations. They&amp;rsquo;re everywhere. In fact, they happen so frequently that you
don&amp;rsquo;t even realize them.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You wake up and open Facebook,&lt;/em&gt; which shows you a feed of articles that it
has chosen for you based on your viewing history.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to buy something?&lt;/em&gt; Amazon would recommend
you things to purchase based on what you&amp;rsquo;ve viewed in the recent past.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to relax and unwind with a movie?&lt;/em&gt; Netflix would recommend you what to watch based on your
interests.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;No time to watch a full movie?&lt;/em&gt; YouTube would recommend you smaller chunk videos.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to listen to music instead?&lt;/em&gt; Spotify would generate a weekly discovery list of songs just for
you.&lt;/p&gt;

&lt;p&gt;All this makes you wonder: &lt;strong&gt;Should recommendations be part of your application?&lt;/strong&gt; While competing
against Netflix might be hard, in this two-part series, we&amp;rsquo;ll explain the basics of a recommendation
engine. We&amp;rsquo;ll show how you can build recommendations via two approaches: Content-based filtering and
Collaborative filtering. And, how you can use Dgraph to bring recommendations to your app without breaking a
sweat.&lt;/p&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;For this, we&amp;rsquo;ll make use of Dgraph&amp;rsquo;s query variables. To learn more about variables, head over to
&lt;a href=&#34;https://tour.dgraph.io/blocksvars/1/&#34;&gt;Dgraph tour&lt;/a&gt; &amp;mdash; &lt;em&gt;if you are new to Dgraph variables, you
really should check them out first before diving in here.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first check out how recommendation systems work, and then we&amp;rsquo;ll look at the support Dgraph queries offer.  We&amp;rsquo;ll use two sample datasets.  One about movies and ratings (&lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;Movielens&lt;/a&gt;) and the other is part of &lt;a href=&#34;https://archive.org/download/stackexchange/lifehacks.stackexchange.com.7z&#34;&gt;Stack Exchange&amp;rsquo;s data archive&lt;/a&gt; &amp;mdash; we&amp;rsquo;ll just use the Lifehacks dataset here, but watch out for a coming series of posts where we show how to load all of Stack Overflow into Dgraph and run the entire website completely off Dgraph.&lt;/p&gt;

&lt;h2 id=&#34;recommendation-systems&#34;&gt;Recommendation Systems&lt;/h2&gt;

&lt;p&gt;Making Recommendations is a subtle art.  There are a number of approaches and a production worthy recommendation system might depend on data, weighting of various features, global user behaviour and maybe recent behaviour of the user we are recommending for.&lt;/p&gt;

&lt;p&gt;Rather than just inventing recommendation queries, let&amp;rsquo;s start somewhere more grounded.  For this post, we started with the Stanford University MOOC &lt;a href=&#34;https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about&#34;&gt;Minning Massive Datasets&lt;/a&gt;.  Part of the course is on recommender systems.  We&amp;rsquo;ll show how the theory in the &lt;em&gt;&amp;ldquo;Recommendation Systems&amp;rdquo;&lt;/em&gt; chapter of the &lt;a href=&#34;http://www.mmds.org&#34;&gt;text&lt;/a&gt; can be translated into practice using Dgraph. We&amp;rsquo;ll also talk about other approaches and how to run one at scale.&lt;/p&gt;

&lt;h3 id=&#34;making-recommendations&#34;&gt;Making Recommendations&lt;/h3&gt;

&lt;p&gt;Making recommendations is about taking past benaviour and preferences and trying to predict a preference for some unknown.  For example, later in the post, we&amp;rsquo;ll talk about movie recommendations.  For this, we know what a user has watched and how they rated movies; how then can we predict what unwatched movies they&amp;rsquo;ll enjoy.&lt;/p&gt;

&lt;p&gt;As briefly mentioned before, broadly speaking, there are two basic approaches:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Content-based:&lt;/strong&gt; Such systems base a recommendation on the properties of an item. Two items that have similar properties are deemed similar; the more properties shared, the more similar. For example, if a user likes movies with certain actors or directors, we can
recommend other movies involving the same people.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Collaborative filtering:&lt;/strong&gt; Such systems base recommendations on the relationship between users and items, and similarity to other users. Users are similar if they have relationships to items in common; the more items in common, the more similar.  For example, if many similar users enjoyed a particular movie, that might be a good one to recommend.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are also classification algorithms based on machine learning.  We&amp;rsquo;ll focus here on how far we can get with Dgraph queries alone.  Machine learning or other algorithms could also be run over the Dgraph output.&lt;/p&gt;

&lt;h3 id=&#34;interpreting-the-data-for-recommendations&#34;&gt;Interpreting the Data for Recommendations&lt;/h3&gt;

&lt;p&gt;Our Stanford reference text represents data as a sparse matrix.  So for our movie data set, we might think of the user&amp;rsquo;s ratings of movies as:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;th&gt;The Matrix&lt;/th&gt;
&lt;th&gt;Toy Story&lt;/th&gt;
&lt;th&gt;Jurassic Park&lt;/th&gt;
&lt;th&gt;Forrest Gump&lt;/th&gt;
&lt;th&gt;Braveheart&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The movies also have other properties such as genres, not shown here.  We&amp;rsquo;ve stored it all as a graph, which in itself is a nice way to store a sparse matrix.&lt;/p&gt;

&lt;p&gt;The matrix (that&amp;rsquo;s the matrix above, not &lt;em&gt;&amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/The_Matrix&#34;&gt;The Matrix&lt;/a&gt;&amp;ldquo;&lt;/em&gt;) is missing values because users haven&amp;rsquo;t seen all movies &amp;mdash; in fact, for the real dataset it&amp;rsquo;s much sparser because users have each only rated a tiny percentage of the movies.&lt;/p&gt;

&lt;p&gt;The challenge of recommendation is to predict values for the missing ratings.  Will user A enjoy Braveheart because it&amp;rsquo;s an action movie and thus similar to movies they enjoyed? (content based filtering)&lt;/p&gt;

&lt;p&gt;But maybe they won&amp;rsquo;t enjoy it because they might have something in common with user B who seems to share similar ratings (collaborative filtering).&lt;/p&gt;

&lt;p&gt;Maybe user A just gives high ratings and isn&amp;rsquo;t very discriminating &amp;mdash; sometimes benaviour rather than rating can be a better predictor. We&amp;rsquo;ll need to combine a number of approaches.&lt;/p&gt;

&lt;p&gt;The theory boils down to finding functions that serve as measures of similarity or distance.  For example, in content-based filtering, the function would take two movies and output a score (the distance or similarity).  If we start with a movie and apply the function repeatedly to it and all other movies, we can find the most similar movies.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll look at some distance measures below as we apply them in queries, but for any of them we&amp;rsquo;ll need to propagate values through our query, so let&amp;rsquo;s look at how that works in Dgraph and then try out some recommendation queries.&lt;/p&gt;

&lt;h2 id=&#34;variable-propagation&#34;&gt;Variable Propagation&lt;/h2&gt;

&lt;p&gt;A Dgraph &lt;a href=&#34;https://docs.dgraph.io/query-language/#value-variables&#34;&gt;value variable&lt;/a&gt; is a mapping from graph nodes to values that have been computed for the nodes during the query.  Value variables can be passed around the query, aggregated etc.  Value variables also sum over paths as we move deeper into a query tree.&lt;/p&gt;

&lt;p&gt;Within a query tree, a value variable defined at one level, propagates such that in a nested level, the variable is the sum of all paths from the definition.&lt;/p&gt;

&lt;p&gt;We call this &lt;strong&gt;variable propagation.&lt;/strong&gt;  Note that the queries in this post we built for our master branch for the upcoming v0.8 release.&lt;/p&gt;

&lt;p&gt;Say you had a query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(func: uid(&amp;lt;...P...&amp;gt;)) {
    myscore as math(1)          # A
    friends {                   # B
      friends {                 # C
        fscore as math(myscore)
      }
    }
  }

  closeFriends(func: uid(fscore), orderdesc: val(fscore)) {
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At line A, nodes are assigned a score of &lt;code&gt;1&lt;/code&gt; (which in this case we&amp;rsquo;ll assume is the single node &lt;code&gt;P&lt;/code&gt;).
Traversing the &lt;code&gt;friend&lt;/code&gt; edge twice reaches the friends of friends.  The variable &lt;code&gt;myscore&lt;/code&gt; gets
propagated, such that the value inside the block marked C is the sum of values from all paths from A to C.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s how that propagation looks in a graph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/vartransform.png&#34; alt=&#34;Variable propagation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In short, the value that a node receives is equal to the sum of values of all its parent nodes.&lt;/strong&gt;
This propagation is useful when we want to normalize a sum across users, find the number of paths
between some nodes or accumulate a sum as we move through the graph.&lt;/p&gt;

&lt;h2 id=&#34;movielens&#34;&gt;Movielens&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with the &lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;ML-100k&lt;/a&gt; dataset of
100,000 ratings from 1000 users on 1700 movies. We converted the dataset to RDF (the dataset and
script can be found at
&lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;github&lt;/a&gt;) and loaded it into
Dgraph.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s about users and movies and user&amp;rsquo;s ratings of movies.  So a user (a node in the graph) has a name and a gender and a &lt;code&gt;rated&lt;/code&gt; edge to a movie.  The &lt;code&gt;rated&lt;/code&gt; edge has a facet &lt;code&gt;rating&lt;/code&gt; that tells us the users numeric 0&amp;ndash;5 rating of the movie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/movilensschema.png&#34; alt=&#34;Movielens schema&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;content-based-filtering&#34;&gt;Content-based filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering ranks items as similar or not based on their properties.  There are a number of measures we could use.  Our reference text from Stanford talks about &lt;strong&gt;Jaccard&lt;/strong&gt; and &lt;strong&gt;Cosine&lt;/strong&gt; distances.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance&#34;&gt;Jaccard Distance&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try some measure functions based on Jaccard distance.  For two sets A and B the Jaccard distance is given by&lt;/p&gt;

&lt;p&gt;$$1-\frac{|A\cap B|}{| A\cup B |}$$&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the ratio of the size of the set intersection to the size of the union.  So if items have many properties in common (compared to how many properties each has) then the items are similar.  For our movie example, let&amp;rsquo;s take $A$ and $B$ as the genre sets for each movie.  We can then express our difference function as:&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = 1-\frac{|M_1.\mathcal{genres} \cap M_2.\mathcal{genres}|}{| M_1.\mathcal{genres}\cup M_2.\mathcal{genres} |}$$&lt;/p&gt;

&lt;p&gt;The closer the result is to 0, the closer the movies &amp;mdash; if the number of genres in common is more, the second term is close to 1, if movies have few genres in common, the second term is closer to 0.&lt;/p&gt;

&lt;p&gt;For movie a $M_1$, we picked &amp;ldquo;The Shawshank Redemption&amp;rdquo; with unique ID &lt;code&gt;0x30d80&lt;/code&gt;, and translated Jaccard distance to this query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Count the genres for every movie that has been rated
  var(func: has(~rated)) {
    M2_num_genres as count(genre)
  }


  # Calculate a Jaccard distance score for every movie that shares
  # at least 1 genre with the given movie.
  var(func: uid(0x30d80)) {    # M1
    norm as math(1)               # 1
    M1_num_genres as count(genre) # 2
    M1genres as genre {           # 3
      ~genre {
        # M2 -- movies reached here share a genre with the initial movie
        # normalize the count to account for multiple paths
        M1_num_genres_norm as math(M1_num_genres / norm)      # 4
        num_genres as count(genre @filter(uid(M1genres))) # 5
        distance as math( 1 - ( num_genres / (M1_num_genres_norm + M2_num_genres - num_genres) )) # 6
      }
    }
  }

  # Sort and return closest movies.
  similarMovies(func: uid(distance), orderasc: val(distance), first: 10) { # 7
    name
    val(distance)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Count the number of genres for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the count of genres set at &lt;code&gt;# 2&lt;/code&gt; would have accumulated for each path, so normalize back to the original count.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the Jaccard distance formula &amp;mdash; &lt;code&gt;distance&lt;/code&gt; is thus a map for each $M_2$ to the Jaccard distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had lowest distance)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here&amp;rsquo;s the results we got for &amp;ldquo;The Shawshank Redemption&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Miracle on 34th Street (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Postman, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Mat&#39; i syn (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Winter Guest, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Chamber, The (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Picnic (1955)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Nell (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Dead Man Walking (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Blue Angel, The (Blaue Engel, Der) (1930)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ouch, there&amp;rsquo;s a bunch of movies with distance 0.  That means all those movies share exactly the same genre set with &amp;ldquo;The Shawshank Redemption&amp;rdquo;, so we can&amp;rsquo;t discriminate between them.  Let&amp;rsquo;s test another movie.  With &amp;ldquo;Toy Story&amp;rdquo; we get.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin and the King of Thieves (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Toy Story (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin (1992)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Goofy Movie, A (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Flintstones, The (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.333333
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s better.  At least similar movies have similar genres. But still, the Jaccard distance function isn&amp;rsquo;t good enough because it can&amp;rsquo;t discriminate a difference between many movies.  Our reference text suggests the same distance function but for data that also has actors and directors, which we don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;As it stands, the Jaccard distance might not be so appropriate because the only items we have to compare are the genres, since the Jaccard distance doesn&amp;rsquo;t take into account the magnitude of the ratings.  So let&amp;rsquo;s play around with it and see how some variations come out.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance-variation&#34;&gt;Jaccard Distance Variation&lt;/h3&gt;

&lt;p&gt;The size of the intersection of the genres seems a reasonable start, but how to bring the magnitude of the ratings into it?  If we are to use the ratings, then the average rating might be appropriate.  Let&amp;rsquo;s try the number of genres in common plus an average rating.  Given a movie $M_1$ we&amp;rsquo;ll find the similarity to all other movies $M_2$ as&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = |M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_2.\overline{\mathcal{rating}}$$&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the Dgraph query for movie $M_1$ having unique ID &lt;code&gt;0x30d72&lt;/code&gt;, that&amp;rsquo;s &amp;ldquo;Star Wars&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # M1 -- Star Wars by its unique ID
  var(func: uid(0x30d72)) {
    g as genre
  }

  # Calculate the average rating for every movie
  var(func: has(rated)) {
    allmovies as rated @facets(a as rating) {
      c as count(~rated)
      avg as math(a / c)
    }
  }

  # Give every movie a score
  var(func: uid(allmovies)) {
    x as count(genre @filter(uid(g)))
    score as math(avg + x)
  }

  # Return the top 10 movies
  fin(func: uid(score), orderdesc: val(score), first: 10) {
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;In terms of variable propagation, the important part is the calculation of average rating.&lt;/strong&gt;  If an edge has a facet and we assign the facet to a variable, we calculate the average. Then for each node reached by the block the variable is the sum of the facets of all such edges reaching the node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/facetsumming.png&#34; alt=&#34;Facet summing&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running the query we get the following results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;fin&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Wars (1977)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.358491
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Empire Strikes Back, The (1980)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.20436
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Return of the Jedi (1983)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.00789
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;African Queen, The (1951)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 8.184211
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Starship Troopers (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.232227
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Princess Bride, The (1987)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.17284
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Kid (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aliens (1986)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.947183
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Trek: The Wrath of Khan (1982)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.815574
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Men in Black (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.745875
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note that we didn&amp;rsquo;t filter out &amp;ldquo;Star Wars&amp;rdquo; and thankfully it came back as the first result.&lt;/em&gt;  Looks like a pretty good distance function, especially given the top three results, but it&amp;rsquo;s probably biased.  &amp;ldquo;Star Wars&amp;rdquo; is highly rated on average, and so we got back other highly rated movies with intersecting genres.  If we searched for a movie that wasn&amp;rsquo;t highly rated on average, the measure would still prefer highly rated movies with intersecting genres.&lt;/p&gt;

&lt;p&gt;That might be fine.  If a user likes certain genres, then maybe highly rated movie in those genres are good recommendations. Maybe it&amp;rsquo;s better to normalize the result so that two movies come out as more similar if they have genres in common and similar average ratings.  That&amp;rsquo;s what cosine distance does.&lt;/p&gt;

&lt;h3 id=&#34;cosine-distance&#34;&gt;Cosine Distance&lt;/h3&gt;

&lt;p&gt;Cosine distance treats our movies as vectors in an n-dimensional space.  The similarity of the movies is then a measure of the difference in angle between the vectors.  The smaller the angle between two vectors, the more similar the movies.  For our movie example, we can express that as follows.&lt;/p&gt;

&lt;p&gt;If we treat our movies as vectors&lt;/p&gt;

&lt;p&gt;$$x_1 &amp;hellip; x_n$$ and $$y_1 &amp;hellip; y_n$$&lt;/p&gt;

&lt;p&gt;the cosine difference between them is computed by calculating the vector dot product divided by the multiple of the distances from the origin.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/cosine_diff.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!--
what&#39;s wrong with this???
$$\frac{\sum_{i=1}^n{x_iy_i}}{\sqrt{\sum_{i=1}^n{x_i^2}}\cdot \sqrt{\sum_{i=1}^n{x_i^2}}}$$
If I paste it into http://www.hostmath.com/ I get what I want
--&gt;

&lt;p&gt;In our case the $x$&amp;rsquo;s up to $x_{n-1}$ will represent the genres, with 1 for genre present and 0 for not present.  While the last term is the average rating.  So for our movie example we can express the cosine difference as.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/cosine_diff_movies.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!-- d(M_1,M_2) = \frac{|M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_1.\overline{\mathcal{rating}} \cdot M_2.\overline{\mathcal{rating}}}{\sqrt{|M_1.\mathcal{genres}| + {M_1.\overline{\mathcal{rating}}}^2}\cdot \sqrt{|M_2.\mathcal{genres}| + {M_2.\overline{\mathcal{rating}}}^2}} --&gt;

&lt;p&gt;That factors in both the intersecting genres as well as the similarity of the average ratings.&lt;/p&gt;

&lt;p&gt;As a single Dgraph query, that looks like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Calculate the average rating of every movie
  var(func: has(rated)) {
    rated @facets(r as rating) {
      c as count(~rated)
      M2_avg_rating as math(r / c)
      M2_num_gen as count(genre)
    }
  }

  # Calculate a cosine difference score for every movie that shares
  # at least 1 genre with M1
  var(func: uid(0x30d80)) {    # movie M1
    norm as math(1)     # 1

    # Find the average rating for M1
    M1_num_ratings as count(~rated)
    ~rated @facets(B as rating)
    M1_ratings_sum as sum(val(B))
    M1_avg_rating as math(M1_ratings_sum / M1_num_ratings) # 2
    M1_num_gen as count(genre)                             # 3

    M1_genres as genre {
      ~genre { # 4
        # M2 -- movies reached here share a genre with the initial movie

        # normalize the M1 count and average to account for multiple paths
        M1_norm_avg as math(M1_avg_rating / norm)
        num_genN as math(M1_num_gen/norm)              # 5
        genint as count(genre @filter(uid(M1_genres))) # 6

        score as math((genint + (M1_norm_avg * M2_avg_rating)) /
          (sqrt(num_genN + (M1_norm_avg*M1_norm_avg)) *
          sqrt(M2_num_gen + (M2_avg_rating*M2_avg_rating))))    # 7

      }
    }
  }

  similarMovies(func: uid(score), first:20, orderdesc: val(score)) { # 8
    name
    val(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Find the average rating for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Count the genres for $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the values from &lt;code&gt;# 2&lt;/code&gt; and &lt;code&gt;# 3&lt;/code&gt; would have accumulated for each path, so normalize back to the originals.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the cosine distance formula &amp;mdash; &lt;code&gt;score&lt;/code&gt; is thus a map for each $M_2$ to the cosine distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had cosine closer to 1, and thus lowest angle)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We searched again for the &amp;ldquo;The Shawshank Redemption&amp;rdquo; and got these results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shawshank Redemption, The (1994)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 1.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Anna (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Some Mother&#39;s Son (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;12 Angry Men (1957)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999988
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Bitter Sugar (Azucar Amargo) (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999985
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Citizen Kane (1941)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;To Kill a Mockingbird (1962)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;One Flew Over the Cuckoo&#39;s Nest (1975)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Pather Panchali (1955)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999965
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Good Will Hunting (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999958
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We didn&amp;rsquo;t filter out &amp;ldquo;The Shawshank Redemption&amp;rdquo; and thus it comes back as the top result &amp;mdash; it has an angle of 0 with itself.  Following that the query returns the results that cosine difference calculates as most similar.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With that, we conclude this post.&lt;/em&gt; In this post, we showcased Jaccard distance, a variation of Jaccard, and finally Cosine
distance. That&amp;rsquo;s three content-based filtering distance metrics and queries for them in Dgraph.  The variables and math function in Dgraph allow us to encode the metrics directly in the query.&lt;/p&gt;

&lt;p&gt;In the next post, we&amp;rsquo;ll take a look at collaborative filtering.  We&amp;rsquo;ll also look at making recommendations for Stack Overflow and how to build a scalable recommendation engine for big graphs.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/media-gallery/detail/149441/9516&#34;&gt;FALCON 9 FIRST STAGE LANDING&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>go get github.com/dgraph-io/dgraph/...</title>
      <link>https://blog.dgraph.io/post/goget/</link>
      <pubDate>Mon, 29 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://blog.dgraph.io/post/goget/</guid>
      <description>&lt;p&gt;Thank you Go community for all the love that you showered on Badger. Within 8 hours of announcing
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, the blog post &lt;a href=&#34;https://news.ycombinator.com/item?id=14335931&#34;&gt;made it to the first
page&lt;/a&gt; of Hacker News. And within three days, the
Github repo received 1250 stars, having crossed 1500 by the time of this post. We have already
merged &lt;a href=&#34;https://github.com/dgraph-io/badger/graphs/contributors&#34;&gt;contributions&lt;/a&gt; and received
&lt;a href=&#34;https://github.com/dgraph-io/badger/issues&#34;&gt;feedback&lt;/a&gt; that we need to work on.&lt;/p&gt;

&lt;p&gt;All this goes to show how much people enjoy Go native libraries. They
make things easier. Any tool, library or system written in Go can now just run &lt;code&gt;go get
github.com/dgraph-io/badger&lt;/code&gt;, and they have a fast, efficient key-value store to use.&lt;/p&gt;

&lt;p&gt;Dgraph users have been asking us about embeddable and go gettable Dgraph for a while. After
hearing from many different users independently, I decided to &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/673&#34;&gt;create a Github
issue&lt;/a&gt; to track it.&lt;/p&gt;

&lt;p&gt;We had two dependencies on Cgo which prevented &lt;code&gt;go get&lt;/code&gt;able Dgraph in the past:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ICU library to do tokenization and full-text search.&lt;/li&gt;
&lt;li&gt;RocksDB as the key-value store.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Back in Q1 2017, we got rid of C based ICU library and switched to using parts of Bleve. Bleve simplified our code base, at the cost of losing &lt;a href=&#34;http://www.blevesearch.com/&#34;&gt;CJK support&lt;/a&gt;. But, we thought that&amp;rsquo;s a trade-off we can live with for the time being.&lt;/p&gt;

&lt;p&gt;The second step of replacing RocksDB was a lot harder, and a lot more interesting journey,
culminating in the release of Badger.&lt;/p&gt;

&lt;p&gt;Today, we &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commit/ed048d5d59248875c55ff5fbf14025e67f1a164c&#34;&gt;pushed a
change&lt;/a&gt; to
Dgraph master branch to switch to Badger. That single change resulted in 450K deleted lines and made Dgraph
&lt;code&gt;go get&lt;/code&gt;able. &lt;strong&gt;This is an exciting day for the Dgraph team, as it simplifies our lives as
developers hugely.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not only would we have simpler, faster builds and releases; we&amp;rsquo;d also have profiles going all the way down to
the disk, and all the way out to the RAM. Every aspect of Dgraph system can now be tweaked for
performance. No hard language boundaries, and that&amp;rsquo;s powerful.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I adore changes which delete more code than they add, while also gaining simplicity and functionality. This change is one of those.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/remove-badger-pr.png&#34; alt=&#34;Dgraph PR to replace Badger&#34; /&gt;
&lt;a href=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5.png&#34; alt=&#34;asciicast&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Happy go getting!&lt;/strong&gt; It needs a bit more work before Dgraph can be embedded in your Go code, but
that is coming soon to master. It would be part of the v0.8 release.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: Dgraph in master branch contains latest changes and isn&amp;rsquo;t thoroughly tested. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://apod.nasa.gov/apod/ap060522.html&#34;&gt;Canadarm aboard the ISS&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Badger: A fast key-value store written purely in Go</title>
      <link>https://blog.dgraph.io/post/badger/</link>
      <pubDate>Sun, 14 May 2017 20:18:15 +1000</pubDate>
      
      <guid>https://blog.dgraph.io/post/badger/</guid>
      <description>

&lt;p&gt;We have built an efficient and persistent log structured merge (LSM) tree based key-value store,
purely in Go language.  It is based upon &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WiscKey paper included in USENIX FAST
2016&lt;/a&gt;. This design is
highly SSD-optimized and separates keys from values to minimize I/O amplification; leveraging both
the sequential and the random performance of SSDs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We call it &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/strong&gt; Based on benchmarks, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is at least &lt;strong&gt;3.5x faster than RocksDB&lt;/strong&gt; when
doing random reads.  For value sizes between 128B to 16KB, data loading is 0.86x - 14x faster
compared to RocksDB, with &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; gaining significant ground as value size increases. On the flip
side, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower for range key-value iteration, but that has a lot of room for
optimization.&lt;/p&gt;

&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;

&lt;h3 id=&#34;word-about-rocksdb&#34;&gt;Word about RocksDB&lt;/h3&gt;

&lt;p&gt;RocksDB is the most popular and probably the most efficient key-value store in the market. It originated
in Google as SSTable which formed the basis for Bigtable, then got released as LevelDB. Facebook
then improved LevelDB to add concurrency and optimizations for SSDs and released that as
RocksDB. Work on RocksDB has been continuously going on for many years now, and it&amp;rsquo;s used in
production at Facebook and many other companies.&lt;/p&gt;

&lt;p&gt;So naturally, if you need a key-value store, you&amp;rsquo;d gravitate towards RocksDB. It&amp;rsquo;s a
solid piece of technology, and it works. The biggest issue with using RocksDB is that it is written in &lt;code&gt;C++&lt;/code&gt;;
requiring the use of Cgo to be called via Go.&lt;/p&gt;

&lt;h3 id=&#34;cgo-the-necessary-evil&#34;&gt;Cgo: The necessary evil&lt;/h3&gt;

&lt;p&gt;At Dgraph, we have been using RocksDB via Cgo since we started. And we&amp;rsquo;ve faced many issues over
time due to this dependency. &lt;a href=&#34;https://dave.cheney.net/2016/01/18/cgo-is-not-go&#34;&gt;Cgo is not Go&lt;/a&gt;, but
when there are better libraries in C++ than Go, Cgo is a necessary evil.&lt;/p&gt;

&lt;p&gt;The problem is, Go CPU profiler doesn&amp;rsquo;t see beyond Cgo calls. Go memory profiler takes it one step
further. Forget about giving you memory usage breakdown in Cgo space, Go memory profiler fails to
even notice the presence of Cgo code. Any memory used by Cgo would not even make it to the memory
profiler. Other tools like Go race detector, don&amp;rsquo;t work either.&lt;/p&gt;

&lt;p&gt;Cgo has caused us &lt;code&gt;pthread_create&lt;/code&gt; issues in Go1.4, and then again in Go1.5, due to a bug
regression. Lightweight goroutines become expensive pthreads when Cgo is involved, and we had to
modify how we were writing data to RocksDB to avoid assigning too many goroutines.&lt;/p&gt;

&lt;p&gt;Cgo has caused us memory leaks. Who owns and manages memory when making calls is just not clear.
Go, and C are at the opposite spectrums. &lt;strong&gt;One doesn&amp;rsquo;t let you free memory, the other
requires it.&lt;/strong&gt; So, you make a Go call, but then forget to &lt;code&gt;Free()&lt;/code&gt;, and nothing breaks. &lt;em&gt;Except much later.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Cgo has given us a unmaintainable code. Cgo makes code ugly. The Cgo layer between RocksDB was the one piece of code no one in the team wanted to touch.&lt;/p&gt;

&lt;p&gt;Surely, we fixed the memory leaks in our API usage over time. In fact, I &lt;em&gt;think&lt;/em&gt; we have fixed them
all by now, but I can&amp;rsquo;t be sure. Go memory profiler would never tell you. And every time someone
complains about Dgraph taking up more memory or crashing due to OOM, it makes me nervous that this
is a memory leak issue.&lt;/p&gt;

&lt;h3 id=&#34;huge-undertaking&#34;&gt;Huge undertaking&lt;/h3&gt;

&lt;p&gt;Everyone I told about our woes with Cgo, told me that we should just work on fixing those issues.
Writing a key-value store which can provide the same performance as RocksDB is a huge undertaking, not
worth our effort. Even my team wasn&amp;rsquo;t sure. I had my doubts as well.&lt;/p&gt;

&lt;p&gt;I have great respect for any piece of technology which has been iterated upon by the smartest
engineers on the face of the planet for years. RocksDB is that. And if I was writing Dgraph in C++,
I&amp;rsquo;d happily use it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But, I just hate ugly code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I hate recurring bugs. No amount of effort would have ensured that we would no longer have any
more issues with using RocksDB via Cgo. I wanted a clean slate, and my profiler tools back. Building
a key-value store in Go from scratch was the only way to achieve it.&lt;/p&gt;

&lt;p&gt;I looked around. The existing key-value stores written in Go didn&amp;rsquo;t even come close to RocksDB&amp;rsquo;s
performance. And that&amp;rsquo;s a deal breaker. &lt;strong&gt;You don&amp;rsquo;t trade performance for cleanliness. You demand
both.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, I decided we will replace our dependency on RocksDB, but given this isn&amp;rsquo;t a priority for Dgraph,
none of the team members should work on it. This would be a side project that only I will
undertake. I started reading up about B+ and LSM trees, recent improvements to their design, and
came across WiscKey paper. It had great promising ideas. I decided to spend a month away from core
Dgraph, building &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;That&amp;rsquo;s not how it went.&lt;/em&gt; I couldn&amp;rsquo;t spend a month away from Dgraph. Between all the founder duties,
I couldn&amp;rsquo;t fully dedicate time to coding either.  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; developed during my spurts of coding
activity, and one of the team members&amp;rsquo; part-time contributions. Work started end January, and now I
think it&amp;rsquo;s in a good state to be trialed by the Go community.&lt;/p&gt;

&lt;h2 id=&#34;lsm-trees&#34;&gt;LSM trees&lt;/h2&gt;

&lt;p&gt;Before we delve into &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, let&amp;rsquo;s understand key-value store
designs. They play an important role in data-intensive applications including databases. Key-value
stores allow efficient updates, point lookups and range queries.&lt;/p&gt;

&lt;p&gt;There are two popular types of implementations: Log-structured merge (LSM) tree based, and B+ tree
based. The main advantage LSM trees have is that all the foreground writes happen in memory, and all
background writes maintain sequential access patterns. Thus they achieve a very high write
thoughput. On the other hand, small updates on B+-trees involve repeated random disk writes, and
hence are unable to maintain high throughput write workload&lt;sup&gt;1&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;To deliver high write performance, LSM-trees batch key-value pairs and write them sequentially.
Then, to enable efficient lookups, LSM-trees continuously read, sort and write key-value pairs in
the background. This is known as a &lt;code&gt;compaction&lt;/code&gt;. LSM-trees do this over many levels, each level
holding a factor more data than the previous, typically &lt;code&gt;size of Li+1 = 10 x size of Li&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Within a single
level, the key-values get written into files of fixed size, in a sorted order. Except level zero,
all other levels have zero overlaps between keys stored in files at the same level.&lt;/p&gt;

&lt;p&gt;Each level has a maximum capacity. As a level &lt;code&gt;Li&lt;/code&gt; fills up, its data gets merged with data from
lower level &lt;code&gt;Li+1&lt;/code&gt; and files in &lt;code&gt;Li&lt;/code&gt; deleted to make space for more incoming data. As data flows
from level zero to level one, two, and so on, the same data is re-written multiple times throughout
its lifetime. Each key update causes many writes until data eventually settles.
This constitutes &lt;em&gt;write amplification&lt;/em&gt;. For a 7 level LSM tree, with 10x size increase factor, this
can be 60; 10 for each transition from L1-&amp;gt;L2, L2-&amp;gt;L3, and so on, ignoring L0 due to special
handling.&lt;/p&gt;

&lt;p&gt;Conversely, to read a key from LSM tree, all the levels need to be checked. If present in multiple
levels, the version of key at level closer to zero is picked (this version is more up to date).
Thus, a single key lookup causes many reads over files, this constitutes &lt;em&gt;read amplification&lt;/em&gt;. WiscKey
paper estimates this to be 336 for a 1-KB key-value pair.&lt;/p&gt;

&lt;p&gt;LSMs were designed around hard drives. In HDDs, random I/Os are over 100x slower than sequential
ones. Thus, running compactions to continually sort keys and enable efficient lookups is an
excellent trade-off.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://blog.dgraph.io/images/nvme-ssd-960pro.jpg&#34; alt=&#34;NVMe SSD Samsung 960 pro&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, SSDs are fundamentally different from HDDs. The difference between their sequential and
random reads are not nearly as large as HDDs. In fact, top of the line SSDs like &lt;a href=&#34;http://www.anandtech.com/show/10754/samsung-960-pro-ssd-review&#34;&gt;Samsung 960
Pro&lt;/a&gt; can provide 440K random read
operations per second, with 4KB block size. Thus, an LSM-tree that performs a large number of
sequential writes to reduce later random reads is wasting bandwidth needlessly.&lt;/p&gt;

&lt;h2 id=&#34;badger&#34;&gt;Badger&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is a simple, efficient, and persistent key-value store.&lt;/strong&gt;  Inspired by the simplicity of
LevelDB, it provides &lt;code&gt;Get&lt;/code&gt;, &lt;code&gt;Set&lt;/code&gt;, &lt;code&gt;Delete&lt;/code&gt;, and &lt;code&gt;Iterate&lt;/code&gt; functions. On top of it, it adds
&lt;code&gt;CompareAndSet&lt;/code&gt; and &lt;code&gt;CompareAndDelete&lt;/code&gt; atomic operations (&lt;a href=&#34;https://godoc.org/github.com/dgraph-io/badger&#34;&gt;see GoDoc&lt;/a&gt;). It does not aim to be a database and hence
does not provide transactions, versioning or snapshots.  Those things can be easily built on top of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; separates keys from values. The keys are stored in LSM tree, while the values are stored in a
write-ahead log called the &lt;em&gt;value log&lt;/em&gt;. Keys tend to be smaller than values. Thus this set up produces
much smaller LSM trees. When required, the values are directly read from the log stored on SSD,
utilizing its vastly superior random read performance.&lt;/p&gt;

&lt;h3 id=&#34;guiding-principles&#34;&gt;Guiding principles&lt;/h3&gt;

&lt;p&gt;These are the guiding principles that decide the design, what goes in and what doesn&amp;rsquo;t in Badger.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write it purely in Go language.&lt;/li&gt;
&lt;li&gt;Use the latest research to build the fastest key-value store.&lt;/li&gt;
&lt;li&gt;Keep it simple, stupid.&lt;/li&gt;
&lt;li&gt;SSD-centric design.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;key-value-separation&#34;&gt;Key-Value separation&lt;/h3&gt;

&lt;p&gt;The major performance cost of LSM-trees is the compaction process. During compactions, multiple
files are read into memory, sorted, and written back. Sorting is essential for efficient retrieval,
for both key lookups and range iterations. With sorting, the key lookups would only require accessing at most one file per level (excluding level zero, where we&amp;rsquo;d need to check all the files).
Iterations would result in sequential access to multiple files.&lt;/p&gt;

&lt;p&gt;Each file is of fixed size, to enhance caching. Values tend to be larger than keys. When you store
values along with the keys, the amount of data that needs to be compacted grows significantly.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, only a pointer to the value in the value log is stored alongside the key. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; employs
&lt;em&gt;delta encoding&lt;/em&gt; for keys to reduce the effective size even further. Assuming 16 bytes per key
and 16 bytes per value pointer, &lt;strong&gt;a single 64MB file can store two million key-value pairs.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;write-amplification&#34;&gt;Write Amplification&lt;/h3&gt;

&lt;p&gt;Thus, the LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller than
that of RocksDB. This smaller LSM-tree reduces the number of levels, and hence number of compactions
required to achieve stability. Also, values are not moved along with keys, because they&amp;rsquo;re elsewhere
in value log. Assuming 1KB value and 16 byte keys, the effective write amplification per level is &lt;code&gt;(10*16 +
1024)/(16 + 1024) ~ 1.14&lt;/code&gt;, a much smaller fraction.&lt;/p&gt;

&lt;p&gt;You can see the performance gains of this approach compared to RocksDB as the value size increases;
where loading data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; takes factors less time (see Benchmarks below).&lt;/p&gt;

&lt;h3 id=&#34;read-amplification&#34;&gt;Read Amplification&lt;/h3&gt;

&lt;p&gt;As mentioned above, the size of LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller. Each file at each
level stores lots more keys than typical LSM trees. Thus, for the same amount of data, fewer levels
get filled up. A typical key lookup requires reading all files in level zero, and one file per level
from level one and onwards. With &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, filling fewer levels means, fewer files need to be read to
lookup a key. Once key (along with value pointer) is fetched, the value can be fetched by doing
random read in value log stored on SSD.&lt;/p&gt;

&lt;p&gt;Furthermore, during benchmarking, we found that &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree is so small, it can easily fit in RAM. For 1KB values and 75 million 22 byte keys, the raw size
of the entire dataset is 72 GB. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree size for
this setup is a mere 1.7G, which can easily fit into RAM.  This is what causes
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s random key lookup performance to be at least 3.5x
faster, and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration to be blazingly
faster than RocksDB.&lt;/p&gt;

&lt;h3 id=&#34;crash-resilience&#34;&gt;Crash resilience&lt;/h3&gt;

&lt;p&gt;LSM trees write all the updates in memory first in memtables. Once they fill up, memtables get
swapped over to immutable memtables, which eventually get written out to files in level zero on
disk.&lt;/p&gt;

&lt;p&gt;In the case of a crash, all the recent updates still in memory tables would be lost.
Key-value stores deal with this issue, by first writing all the updates in a write-ahead log. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;
has a write-ahead log, it&amp;rsquo;s called value log.&lt;/p&gt;

&lt;p&gt;Just like a typical write-ahead log, before any update is applied to LSM tree, it gets written to
value log first. In the case of a crash, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; would iterate over the recent updates in value log, and
apply them back to the LSM tree.&lt;/p&gt;

&lt;p&gt;Instead of iterating over the entire value log, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; puts a pointer to the latest value in each
memtable. Effectively, the latest memtable which made its way to disk would have a value pointer,
before which all the updates have already made their way to disk. Thus, we can replay from this
pointer onwards, and reapply all the updates to LSM tree to get all our updates back.&lt;/p&gt;

&lt;h3 id=&#34;overall-size&#34;&gt;Overall size&lt;/h3&gt;

&lt;p&gt;RocksDB applies block compression to reduce the size of LSM tree. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is much smaller in
comparison and can be stored in RAM entirely, so it doesn&amp;rsquo;t need to do any compression on the tree. However,
the size of value log can grow quite quickly.  Each update is a new entry in the value log, and
therefore multiple updates for the same key take up space multiple times.&lt;/p&gt;

&lt;p&gt;To deal with this, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; does two things. It allows compressing values in value log. Instead of
compressing multiple key-values together, we only compress each key-value individually. This
provides the best possible random read performance. The client can set it so compression is
only done if the key-value size is over an adjustable threshold, set by default to 1KB.&lt;/p&gt;

&lt;p&gt;Secondly, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; runs value garbage collection. This runs periodically and samples a 100MB size of a
randomly selected value log file. It checks if at least a significant chunk of it should be
discarded, due to newer updates in later logs. If so, the valid key-value pairs would be appended to
the log, the older file discarded, and the value pointers updated in the LSM tree. The downside is,
this adds more work for LSM tree; so shouldn&amp;rsquo;t be run when loading a huge data set. More work is
required to only trigger this garbage collection to run during periods of little client
activity.&lt;/p&gt;

&lt;h3 id=&#34;hardware-costs&#34;&gt;Hardware Costs&lt;/h3&gt;

&lt;p&gt;But, given the fact that SSDs are getting cheaper and cheaper, using extra space in SSD is
almost nothing compared to having to store and serve a major chunk of LSM tree from memory. Consider this:&lt;/p&gt;

&lt;p&gt;For 1KB values, 75 million 16 byte keys, RocksDB&amp;rsquo;s LSM tree is 50GB in size. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s value log is
74GB (without value compression), and LSM tree is 1.7GB. Extrapolating it three times, we get 225 million
keys, RocksDB size of 150GB and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; size of 222GB value log, and 5.1GB LSM tree.&lt;/p&gt;

&lt;p&gt;Using Amazon AWS US East (Ohio) datacenter:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To achieve a random read performance equivalent of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (at least 3.5x faster), RocksDB would need to
be run on an &lt;code&gt;r3.4xlarge&lt;/code&gt; instance, which provides 122 GB of RAM for &lt;code&gt;$1.33&lt;/code&gt; per hour; so most of its
LSM tree can fit into memory.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be run on the cheapest storage optimized instance &lt;code&gt;i3.large&lt;/code&gt;, which provides 475GB NVMe SSD
(&lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; test: 100K IOPS for 4KB block size), with 15.25GB RAM for &lt;code&gt;$0.156&lt;/code&gt; per hour.&lt;/li&gt;
&lt;li&gt;The cost of running &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is thus, &lt;strong&gt;8.5x cheaper&lt;/strong&gt; than running RocksDB on EC2, on-demand.&lt;/li&gt;
&lt;li&gt;Going 1-year term all upfront payment, this is $6182 for RocksDB v/s $870 for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, still 7.1x
cheaper. &lt;strong&gt;That&amp;rsquo;s a whopping 86% saving.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;We rented a storage optimized &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/&#34;&gt;i3.large
instance&lt;/a&gt; from Amazon AWS, which provides 450GB NVMe
SSD storage, 2 virtual cores along with 15.25GB RAM. This instance provides local SSD, which we
tested via &lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; to sustain close to 100K random read IOPS for 4KB
block sizes.&lt;/p&gt;

&lt;p&gt;The data sets were chosen to generate sizes too big to fit entirely in RAM, in either RocksDB
or &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Value size&lt;/th&gt;
&lt;th&gt;Number of keys (each key = 22B)&lt;/th&gt;
&lt;th&gt;Raw data size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;128B&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;td&gt;35GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1024B&lt;/td&gt;
&lt;td&gt;75M&lt;/td&gt;
&lt;td&gt;73GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16KB&lt;/td&gt;
&lt;td&gt;5M&lt;/td&gt;
&lt;td&gt;76GB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We then loaded data one by one, first in RocksDB then in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, never running the loaders
concurrently. This gave us the data loading times and output sizes. For random &lt;code&gt;Get&lt;/code&gt; and &lt;code&gt;Iterate&lt;/code&gt;,
we used Go benchmark tests and ran them for 3 minutes, going down to 1 minute for 16KB values.&lt;/p&gt;

&lt;p&gt;All the code for benchmarking is available &lt;a href=&#34;https://github.com/dgraph-io/badger-bench&#34;&gt;in this
repo&lt;/a&gt;. All the commands ran and
their measurements recorded are available in &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/blob/master/BENCH-rocks.txt&#34;&gt;this log
file&lt;/a&gt;. The
charts and their data is &lt;a href=&#34;https://docs.google.com/a/dgraph.io/spreadsheets/d/1x8LUw_85g8Jo9jFtbAwuXrLm_DB1SOG8QCTSjXj8Hk0/edit?usp=sharing&#34;&gt;viewable
here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;In the following benchmarks, we measured 4 things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data loading performance&lt;/li&gt;
&lt;li&gt;Output size&lt;/li&gt;
&lt;li&gt;Random key lookup performance (&lt;code&gt;Get&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Sorted range iteration performance (&lt;code&gt;Iterate&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the 4 measurements are visualized in the following charts.
&lt;img src=&#34;https://blog.dgraph.io/images/badger-benchmarks.png&#34; alt=&#34;[Badger](https://github.com/dgraph-io/badger) benchmarks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data loading performance:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-value separation design shows huge performance gains as
value sizes increase. For value sizes of 1KB and 16KB, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; achieves 4.5x and 11.7x more
throughput than RocksDB. For smaller values, like 16 bytes not shown here, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be 2-3x
slower, due to slower compactions (see further work).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Store size:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; generates much smaller LSM tree, but a larger value size log. The size of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is proportional only to the number of keys, not values. Thus, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree decreases in size as we progress from 128B to 16KB. In all three scenarios, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; produced an
LSM tree which could fit entirely in RAM of the target server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Random read latency:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt; latency is only 18% to 27% of RocksDB&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt;
latency. &lt;strong&gt;In our opinion, this is the biggest win of this design.&lt;/strong&gt; This happens because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s
entire LSM tree can fit into RAM, significantly decreasing the amount of time it takes to find the
right tables, check their bloom filters, pick the right blocks and retrieve the key. Value retrieval is then
a single SSD &lt;code&gt;file.pread&lt;/code&gt; away.&lt;/p&gt;

&lt;p&gt;In contrast, RocksDB can&amp;rsquo;t fit the entire tree in memory. Even assuming it can keep the table index
and bloom filters in memory, it would need to fetch the entire blocks from disk, decompress them,
then do key-value retrieval (&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s smaller LSM tree avoids
the need for compression). This obviously takes longer, and given lack of data access locality,
caching isn&amp;rsquo;t as effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Range iteration latency:&lt;/strong&gt;  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s range iteration is
significantly slower than RocksDB&amp;rsquo;s range iteration, when values are also retrieved from SSD. &lt;em&gt;We
didn&amp;rsquo;t expect this, and still don&amp;rsquo;t quite understand it.&lt;/em&gt; We expected some slowdown due to the need
to do IOPS on SSD, while RocksDB does purely serial reads. But, given the 100K IOPS &lt;code&gt;i3.large&lt;/code&gt;
instance is capable of, we didn&amp;rsquo;t even come close to using that bandwidth, despite pre-fetching.
This needs further work and investigation.&lt;/p&gt;

&lt;p&gt;On the other end of the spectrum, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration is blazingly faster than RocksDB or key-value
iteration (latency is shown by the almost invisible red bar). This is quite useful in certain use
cases we have at Dgraph, where we iterate over the keys, run filters and only retrieve values for a
much smaller subset of keys.&lt;/p&gt;

&lt;h2 id=&#34;further-work&#34;&gt;Further work&lt;/h2&gt;

&lt;h3 id=&#34;speed-of-range-iteration&#34;&gt;Speed of range iteration&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can do key-only iteration blazingly fast, things slow down when it
also needs to do value lookups. Theoretically, this shouldn&amp;rsquo;t be the case. Amazon&amp;rsquo;s i3.large disk
optimized instance can do 100,000 4KB block random reads per second. Based on this, we should be
able to iterate 100K key-value pairs per second, in other terms six million key-value pairs per minute.&lt;/p&gt;

&lt;p&gt;However, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s current implementation doesn&amp;rsquo;t produce SSD
random read requests even close to this limit, and the key-value iteration suffers as a result.
There&amp;rsquo;s a lot of room for optimization in this space.&lt;/p&gt;

&lt;h3 id=&#34;speed-of-compactions&#34;&gt;Speed of compactions&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower when it comes to running
compactions compared to RocksDB. Due to this, for a dataset purely containing smaller values, it is
slower to load data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. This needs more optimization.&lt;/p&gt;

&lt;h3 id=&#34;lsm-tree-compression&#34;&gt;LSM tree compression&lt;/h3&gt;

&lt;p&gt;Again in a dataset purely containing smaller values, the size of LSM tree would be significantly
larger than RocksDB because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; doesn&amp;rsquo;t run compression on LSM tree. This should be easy to add
on if needed, and would make a great first-time contributor project.&lt;/p&gt;

&lt;h3 id=&#34;b-tree-approach&#34;&gt;B+ tree approach&lt;/h3&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Recent improvements to SSDs might make B+-trees a viable option.
Since WiscKey paper was written, SSDs have made huge gains in random write performance. A new
interesting direction would be to combine the value log approach, and keep only keys and value
pointers in the B+-tree. This would trade LSM tree read-sort-merge sequential write compactions with
many random writes per key update and might achieve the same write throughput as LSM for a much
simpler design.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have built an efficient key-value store, which can compete in performance against top of the line
key-value stores in market. It is currently rough around the edges, but provides a solid platform
for any industrial application, be it data storage or building another database.&lt;/p&gt;

&lt;p&gt;We will be replacing Dgraph&amp;rsquo;s dependency on RocksDB soon with
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;; making our builds easier, faster, making Dgraph
cross-platform and paving the way for embeddable Dgraph. The biggest win of using
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is &lt;strong&gt;a performant Go native key-value store.&lt;/strong&gt; The
nice side-effects are &lt;strong&gt;~4 times faster &lt;code&gt;Get&lt;/code&gt; and a potential 86% reduction in AWS bills,&lt;/strong&gt; due to
less reliance on RAM and more reliance on ever faster and cheaper SSDs.&lt;/p&gt;

&lt;p&gt;So try out &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; in your project, and let us know your experience.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. Special thanks to &lt;a href=&#34;https://research.google.com/pubs/SanjayGhemawat.html&#34;&gt;Sanjay Ghemawat&lt;/a&gt; and
&lt;a href=&#34;http://pages.cs.wisc.edu/~ll/&#34;&gt;Lanyue Lu&lt;/a&gt; for responding to my questions about design choices.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: Juno spacecraft is the &lt;a href=&#34;http://www.livescience.com/32655-whats-the-fastest-spacecraft-ever.html&#34;&gt;fastest moving human made
object&lt;/a&gt;, traveling at a
speed of 265,00 kmph relative to Earth.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>String matching in Dgraph v0.7.5</title>
      <link>https://blog.dgraph.io/post/string-matching/</link>
      <pubDate>Mon, 10 Apr 2017 12:10:00 +0200</pubDate>
      
      <guid>https://blog.dgraph.io/post/string-matching/</guid>
      <description>&lt;p&gt;The recent release of Dgraph is packed with new features and improvements.
Many of them are related to strings - full text search (with support for 15 languages!) and regular expression matching have been added, and handling of string values in multiple languages was greatly improved.
All of these changes make Dgraph an excellent tool for working with multilingual applications.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;values-in-many-languages&#34;&gt;Values in Many Languages&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;re working hard to keep the query language easy to use and clean.
Dgraph, in v0.7.5, adopted and extended the language tag syntax from the RDF N-Quads standard.
It is intuitive, well-known, and was partially supported in previous versions (during data loading).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start from the beginning - the data.
Dgraph uses RDF N-Quads for data loading and backup.
String literals in N-Quads may be followed by the &lt;code&gt;@&lt;/code&gt; sign and language tag, e.g. &lt;code&gt;&amp;quot;badger&amp;quot;@en&lt;/code&gt; or &lt;code&gt;&amp;quot;Dachs&amp;quot;@de&lt;/code&gt;.
Multiple such literals may be used as a value for a single entity/attribute pair.&lt;/p&gt;

&lt;p&gt;When querying for a predicate with multiple values, the user is able to use the &lt;code&gt;@lang&lt;/code&gt; notation known from RDF N-Quads.
Many languages can be specified in a list of preference, e.g. &lt;code&gt;@en:de&lt;/code&gt; denotes that preferred language is English, but if such a value is not present, a value in German should be returned.&lt;/p&gt;

&lt;p&gt;Language can also be specified in functions, which is important especially for full text search.&lt;/p&gt;

&lt;h3 id=&#34;example-data&#34;&gt;Example Data&lt;/h3&gt;

&lt;p&gt;The dataset used in all examples is the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/21million.rdf.gz&#34;&gt;Freebase film data&lt;/a&gt;.
As this post is string-oriented, queries are focused on movie titles in multiple languages, and no other information is retrieved.
As we don&amp;rsquo;t have information about type of &lt;code&gt;name&lt;/code&gt;, we use filtering to select only the movie titles, and to limit the number of results a bit - &lt;code&gt;@filter(gt(count(genre), 1))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The schema for &lt;code&gt;name&lt;/code&gt; field is very simple - it defines 3 types of indexes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl localhost:8080/query -XPOST -d $&#39;
mutation {
  schema {
    name: string @index(term, fulltext, exact) .
  }
}&#39; | python -m json.tool | less
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;term&lt;/code&gt; index is used for term matching with the &lt;code&gt;allofterms&lt;/code&gt; and &lt;code&gt;anyofterms&lt;/code&gt; functions.
Note that it was the only string index available in previous releases of Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;fulltext&lt;/code&gt; index uses matching with language specific stemming and stopwords.
One thing worth noting is, that values indexed with &lt;code&gt;fulltext&lt;/code&gt; are processed according to their&amp;rsquo;s language (if they are tagged). If values are untagged, English is used as a default language.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;exact&lt;/code&gt; index is used for regular expression matching.&lt;/p&gt;

&lt;h3 id=&#34;full-text-search-fts&#34;&gt;Full Text Search (FTS)&lt;/h3&gt;

&lt;h5 id=&#34;very-short-introduction-to-natural-language-processing-nlp&#34;&gt;Very Short Introduction to Natural Language Processing (NLP)&lt;/h5&gt;

&lt;p&gt;By definition (from &lt;a href=&#34;https://en.wikipedia.org/wiki/Full-text_search&#34;&gt;Wikipedia&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;In a full-text search, a search engine examines all of the words in every stored document as it tries to match search criteria (for example, text specified by a user).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may sound trivial, but it&amp;rsquo;s not.
Searching for exact form of the word is not always satisfying for the user.
For example, nouns can be singular or plural, verbs have grammatical tenses, etc., and the user may be interested in all values related to the word in any inflected or derived form.&lt;/p&gt;

&lt;p&gt;The simple but powerful idea is to find a method, that can transform all the forms of a word to some common base.
This process is called &lt;strong&gt;stemming&lt;/strong&gt;.
For many natural languages (including English) stemmers may be implemented using a set of well known grammatical rules.
There are also languages (like Polish) where a dictionary based approach is required (i.e. inflected form -&amp;gt; stem mapping).&lt;/p&gt;

&lt;p&gt;Only for languages with well known grammatical rules are stemmers are widely available.&lt;/p&gt;

&lt;p&gt;Another problem with search are the words that are common, like &lt;code&gt;the&lt;/code&gt;, &lt;code&gt;is&lt;/code&gt;, or &lt;code&gt;at&lt;/code&gt;.
In most cases, searching for them gives an enormous amount of results which are useless.
Those words are called &lt;strong&gt;stop words&lt;/strong&gt;.
Again, stop words are language specific.
The common method of handling those words is just to remove them from the search.&lt;/p&gt;

&lt;h5 id=&#34;dgraph-fts-nlp-processing&#34;&gt;Dgraph FTS/NLP Processing&lt;/h5&gt;

&lt;p&gt;The following steps are applied to both data (while indexing), and the query pattern:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Tokenization - text is divided into words.&lt;/li&gt;
&lt;li&gt;Normalization - all letters are transformed to lowercase. &lt;a href=&#34;http://unicode.org/reports/tr15/&#34;&gt;Unicode Normalization&lt;/a&gt; is applied.&lt;/li&gt;
&lt;li&gt;Stop words are removed.&lt;/li&gt;
&lt;li&gt;Stemming is applied.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Since stop words contain inflected forms, they are removed before stemming.&lt;/p&gt;

&lt;h5 id=&#34;full-text-search-functions&#34;&gt;Full Text Search Functions&lt;/h5&gt;

&lt;p&gt;There are two new functions that provide basic support for full text search:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;alloftext&lt;/code&gt; - searches for values that contain all the specified words (using NLP).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;anyoftext&lt;/code&gt; - searches for values that contain one or more of the specified tokens (using NLP).&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;examples&#34;&gt;Examples&lt;/h5&gt;

&lt;p&gt;Let&amp;rsquo;s query for &lt;code&gt;white or maybe black&lt;/code&gt;, using the term matching function &lt;code&gt;allofterms&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;

&lt;div class=&#34;runnable&#34; data-checksum=&#34;a2c60948e744862d6b1a13236ada9dd9&#34; data-initial=&#34;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

The query gives no results.
It may be worth trying less strict match with &lt;code&gt;alloftext&lt;/code&gt; function:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;5d5001b78c162fe12067167cabc9bab5&#34; data-initial=&#34;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;Query returns 59 results.
This example shows that removing a stop word may help in some cases.&lt;/p&gt;

&lt;p&gt;In context of NLP, English is quite easy - there are no diacritics, and inflection is rather simple.
So let&amp;rsquo;s try similar query in German:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;ae14be08ee0c46175f71b7918ee1dcd0&#34; data-initial=&#34;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;Again, the query doesn&amp;rsquo;t return any results.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s try the NLP-enabled version of this query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;3ae8ed3ca59fc7f3927a4ca09377ab47&#34; data-initial=&#34;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;This returns 4 results.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting the inflected forms of &lt;code&gt;schwarz&lt;/code&gt; - &lt;code&gt;schwarzes&lt;/code&gt; and &lt;code&gt;Schwartze&lt;/code&gt;.
Also the &lt;code&gt;Wei\u00dfer&lt;/code&gt; is interesting - &lt;code&gt;\u00df&lt;/code&gt; is the escaped Unicode value of &lt;a href=&#34;https://en.wikipedia.org/wiki/%C3%9F&#34;&gt;grapheme &lt;code&gt;ß&lt;/code&gt;&lt;/a&gt;.
&lt;code&gt;weiss&lt;/code&gt; matched &lt;code&gt;Weißer&lt;/code&gt; - the form is inflected, and grapheme equivalency is preserved.
Like in the English example, the stop word (&lt;code&gt;oder&lt;/code&gt;) is ignored.&lt;/p&gt;

&lt;h5 id=&#34;gotchas&#34;&gt;Gotchas&lt;/h5&gt;

&lt;p&gt;In some cases, natural language processing can lead to surprising results.
Let&amp;rsquo;s search for the answer to the famous question: &lt;code&gt;To be, or not to be?&lt;/code&gt;:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;aadb70fa6d64fde240a20a76965babec&#34; data-initial=&#34;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;The query gives no results, while the term matching query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;dd1fdb51dcb706bd6314b6e67b0d9118&#34; data-initial=&#34;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;gives two results:&lt;/p&gt;

&lt;p&gt;What happened? &lt;code&gt;To be, or not to be?&lt;/code&gt; consists of stop words only.
After FTS/NLP processing, there are no movies that match the query.&lt;/p&gt;

&lt;h3 id=&#34;regular-expressions-regexp&#34;&gt;Regular Expressions (regexp)&lt;/h3&gt;

&lt;p&gt;Regular expressions are extremely useful for creating sophisticated matchers.&lt;/p&gt;

&lt;p&gt;For example, all titles starting with a word containing &lt;code&gt;night&lt;/code&gt; but not &lt;code&gt;knight&lt;/code&gt; may be matched using following query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;23ed524490f96aec36c54a4a839190a0&#34; data-initial=&#34;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:regexp(name@en, /^[a-zA-z]*[^Kk ]?[Nn]ight/)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://blog.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;There are 502 results in the test dataset.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Dgraph supports extensive, and useful methods of string matching.&lt;/p&gt;

&lt;p&gt;Natural language processing, employed for full text search, may be the best choice for lookup based on users input.
If more strict matching is required, term matching should give good results.
And to get the most precise results of complicated text searches, regular expressions can be used.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/jpl/pia21572/the-splitting-of-the-dunes&#34;&gt;The Splitting of the Dunes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building a long lasting company around open-source</title>
      <link>https://blog.dgraph.io/post/licensing/</link>
      <pubDate>Sun, 26 Mar 2017 07:30:00 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/licensing/</guid>
      <description>

&lt;p&gt;Dgraph started with the idea that every startup should be able to have the same level of technology as run by big giants. We designed Dgraph from ground-up to allow data sharding, horizontal scalability, consistent replication, and a fast and distributed architecture.&lt;/p&gt;

&lt;p&gt;We also dream that graph database would no longer run as a secondary database. By building a truly robust piece of technology, we can have our users run only one database, which allows arbitrarily complex queries while providing rock solid performance.&lt;/p&gt;

&lt;p&gt;We have always thought of Dgraph as a company, where we can work for the next ten years. So, instead of hacking our way to market, we invest in good design, aggressive refactoring and a culture of logic and reasoning based decisions. &lt;strong&gt;But, running a company takes more than clean code and good culture. It requires a functioning business model, which can make a profit.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Profit allows providing highly competitive salaries. Competitive salaries make the company attractive to great engineers. Great engineers build and enhance great products.&lt;/p&gt;

&lt;p&gt;To that extent, we&amp;rsquo;ve started working towards a closed-source enterprise version of Dgraph. This version would contain many features useful to companies, namely:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Cluster management and monitoring&lt;/li&gt;
&lt;li&gt;User authentication&lt;/li&gt;
&lt;li&gt;Access control lists&lt;/li&gt;
&lt;li&gt;Data encryption, and more&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Selling enterprise version and support would lead us to the path of revenue.&lt;/p&gt;

&lt;p&gt;But, what about competition? How do we deal with the threat many big companies provide on a daily basis? The threat of duplicate commercial services and enterprise features built by them and others without paying anything back towards the development of the open source version. There is also the looming cautionary tale of &lt;a href=&#34;https://rethinkdb.com/blog/rethinkdb-shutdown/&#34;&gt;RethinkDB ceasing&lt;/a&gt; to develop their database, due to lack of revenue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We need to balance the benefits of open source to the community, against making the company building Dgraph profitable, while also keeping future competition at bay.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-change&#34;&gt;The change&lt;/h3&gt;

&lt;p&gt;One of the ideas was to move the distributed aspect of Dgraph to the enterprise version; like &lt;a href=&#34;https://www.influxdata.com/update-on-influxdb-clustering-high-availability-and-monetization/&#34;&gt;many&lt;/a&gt; &lt;a href=&#34;https://neo4j.com/licensing/&#34;&gt;others&lt;/a&gt; &lt;a href=&#34;https://www.mysql.com/products/enterprise/scalability.html&#34;&gt;are&lt;/a&gt; &lt;a href=&#34;https://www.datastax.com/products/datastax-enterprise-graph&#34;&gt;doing&lt;/a&gt;. The argument goes that by making distributed aspect closed-source, the open source offering would have restricted usage for companies growing fast; and they&amp;rsquo;ll be forced to pay.&lt;/p&gt;

&lt;p&gt;&lt;ul&gt;&lt;em&gt;But, it doesn&amp;rsquo;t feel right!&lt;/em&gt;&lt;/ul&gt; Many users love Dgraph because of it provides scalability without question. This goes against our inception idea that every startup should have the same level of technology run by big giants.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The &amp;ldquo;D&amp;rdquo; in Dgraph stands for distributed; we want to make sure that everyone gets it: big company, small company, pre-revenue, post-revenue, or one guy in a garage.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We don&amp;rsquo;t want companies to &lt;em&gt;have to&lt;/em&gt; pay us just to deal with more query traffic. That should be free. Instead, we want to build features which are so useful to enterprises that &lt;strong&gt;they feel they can save a lot of expensive developer time by using our services.&lt;/strong&gt;
So, after talking to other open source vendors and top open source lawyers, we came to this solution:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relicense the open-source version to GNU AGPLv3 (from Apache 2.0), while keeping the client libraries under Apache 2.0.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Known as the &lt;em&gt;GPL of the web&lt;/em&gt;, GNU Affero General Public License mandates that any modifications made to the source code must be released under the same license. This applies not just to downloadable binaries, but also to code run in the cloud. You can read &lt;a href=&#34;https://tldrlegal.com/license/gnu-affero-general-public-license-v3-(agpl-3.0)&#34;&gt;more about it here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;what-does-this-mean-for-you&#34;&gt;What does this mean for you?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Largely no change.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Most users of Dgraph would never need to modify the server code themselves anyway. We are going to keep the client libraries under Apache 2.0; which would allow users to continue using Dgraph (via client libraries) without any restrictions or mandates on their own codebase. In general terms, any work built on top of Dgraph wouldn&amp;rsquo;t be considered derivative work, as long as Dgraph server code wasn&amp;rsquo;t modified.&lt;/p&gt;

&lt;p&gt;So, if you&amp;rsquo;re a user of Dgraph, nothing changes. If you modify Dgraph server code, you will have to release that modification back to the community under GNU AGPLv3. Thus, the entire Dgraph community would benefit from the contributions made to the server code by other individuals or companies.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This simple change ensures that only Dgraph Labs owns the rights to add proprietary features within Dgraph server code, which in turn allows us to charge for our services and make revenue.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Users of MongoDB would &lt;a href=&#34;https://www.mongodb.com/community/licensing&#34;&gt;instantly recognize&lt;/a&gt; this licensing system. In fact, we were heavily influenced by them. MongoDB is one of the most successful databases and provided a great validation for this new direction we&amp;rsquo;re taking.&lt;/p&gt;

&lt;h3 id=&#34;living-breathing-open-source&#34;&gt;Living, breathing Open-source&lt;/h3&gt;

&lt;p&gt;While there is a talk of money, Dgraph still lives and breathes like an open-source company. In fact, by relicensing our code base under GNU AGPLv3, we can continue providing the distributed aspect of Dgraph under open source license; which gives us great pleasure.&lt;/p&gt;

&lt;p&gt;Graph market is heating up. Every other day, we hear about products ranging from a graph plugin to a graph layer to a graph engine to a graph database. Given the desire to not only serve data but also understand it, there&amp;rsquo;s a need for graphs in companies; and people realize that.&lt;/p&gt;

&lt;p&gt;With Dgraph, we think we&amp;rsquo;re in the right spot at the right time, ready to provide a graph database that scales with your business. And we&amp;rsquo;ll continue to do it in a way that benefits the entire community.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you have any questions or concerns about this switch, please feel free to reach out to me at &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;manish@dgraph.io&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/media-gallery/detail/144751/7441&#34;&gt;People landing on Mars via SpaceX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neo4j vs Dgraph - The numbers speak for themselves</title>
      <link>https://blog.dgraph.io/post/benchmark-neo4j/</link>
      <pubDate>Mon, 23 Jan 2017 18:07:44 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/benchmark-neo4j/</guid>
      <description>&lt;p&gt;As &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is nearing its v0.8 release, we wanted to spend some time comparing it against Neo4j, which is the &lt;a href=&#34;http://db-engines.com/en/ranking/graph+dbms&#34;&gt;most popular graph database&lt;/a&gt;. We have divided this post into five parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Loading data&lt;/li&gt;
&lt;li&gt;Querying&lt;/li&gt;
&lt;li&gt;Issues faced&lt;/li&gt;
&lt;li&gt;Features&lt;/li&gt;
&lt;li&gt;Principles behind Dgraph&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;set-up&#34;&gt;Set up&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Thinkpad T460 laptop running Ubuntu Linux, Intel Core i7, with 16 GB RAM and SSD storage.&lt;/li&gt;
&lt;li&gt;Neo4j v3.1.0&lt;/li&gt;
&lt;li&gt;Dgraph from master branch (commit: 100c104a)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-loading-data&#34;&gt;1. Loading Data&lt;/h3&gt;

&lt;p&gt;We wanted to load a dense graph data set involving real world data. We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 have been using the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/21million.rdf.gz&#34;&gt;Freebase film data&lt;/a&gt; for our development and testing. We feel this data is highly interconnected and makes a good use case for storing in a graph database.&lt;/p&gt;

&lt;p&gt;The first problem we faced was that Neo4j doesn&amp;rsquo;t accept data in RDF format directly &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#1&#34;&gt;3.1&lt;/a&gt;
&lt;/sup&gt;
. The &lt;a href=&#34;https://neo4j.com/developer/guide-import-csv/#_super_fast_batch_importer_for_huge_datasets&#34;&gt;loader&lt;/a&gt; for Neo4j accepts data in CSV format which is essentially what SQL tables have. In our 21 million dataset, we have 50 distinct types of entities and 132 types of relationships between these entities. If we were to try and convert it to CSV format, we would end up with 100s of CSV files. One file for each type of entity, and one file per relationship between two types of entities. While this is okay for relational data, this doesn&amp;rsquo;t work for graph data sets, where each entity can be of multiple types, and relationships between entities are fluid.&lt;/p&gt;

&lt;p&gt;So, we looked into the next best option to load graph data into Neo4j. We wrote a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;small program&lt;/a&gt; similar to the Dgraphloader which reads N-Quads, batches them and tries to load them concurrently into Neo4j. This program used &lt;a href=&#34;https://neo4j.com/blog/neo4j-3-0-milestone-1-release/&#34;&gt;Bolt&lt;/a&gt;, a new protocol by Neo4j. It is the fastest way we could find to load RDF data into Neo4j. In the video below, you can see a comparison of loading 1.1 million N-Quads on &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 vs. Neo4j.&lt;/p&gt;

&lt;p&gt;Note that we only used 20 concurrent connections and batched 200 N-Quads for each request because Neo4j doesn&amp;rsquo;t work well if we increase either the number of connections or N-Quads per connection beyond this. In fact, that&amp;rsquo;s a sure way to make Neo4j data corrupt and hang the system &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#2&#34;&gt;3.2&lt;/a&gt;
&lt;/sup&gt;
. For Dgraph, we typically send 1000 N-Quads per request and have 500 concurrent connections.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/S_DsEMnawwU?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;With the golden data set of 1.1 million N-Quads, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 outperformed Neo4j 46.7k to 280 N-Quads per second. In fact, the Neo4j loader process &lt;em&gt;never finished&lt;/em&gt; (we killed it after a considerable wait).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is 160x faster than Neo4j for loading graph data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;2-querying&#34;&gt;2. Querying&lt;/h3&gt;

&lt;p&gt;We would have ideally liked to load up the entire 21 million RDF dataset so that we could compare the performance of both databases at scale. But given the difficulties we faced loading large amounts of data into Neo4j, we resorted to a subset dataset of 1.3 million N-Quads containing only certain types of entities and relationships. After a &lt;em&gt;painful&lt;/em&gt; process, we converted our data into &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data/neo4j&#34;&gt;five CSV files&lt;/a&gt;, one for each type of entity (film, director, and genre) and two for the relationships between them; so that we could do some queries. We loaded these files into Neo4j using their import tool.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./neo4j start
./neo4j-admin import --database film.db --id-type string --nodes:Film $DATA/films.csv --nodes:Genre $DATA/genres.csv --nodes:Director $DATA/directors.csv --relationships:GENRE $DATA/filmgenre.csv --relationships:FILMS $DATA/directorfilm.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we created some indexes in Neo4j for the best query performance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE INDEX ON :Director(directorId)
CREATE INDEX ON :Director(name)
CREATE INDEX ON :Film(release_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We tested Neo4j twice. Once with query caching turned off, and then with query caching turned on. &lt;strong&gt;Generally, it does not make sense to benchmark queries with caching turned on, but we decided to set it because that&amp;rsquo;s the default behavior Neo4j users see.&lt;/strong&gt; You can set it by modifying the following variable in &lt;code&gt;conf/neo4j.conf&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dbms.query_cache_size=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dgraph does not do any query caching. We loaded an equivalent &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/neo.rdf.gz&#34;&gt;data set&lt;/a&gt; into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 using the following schema and the commands below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
    type.object.name.en: string @index
    film.film.initial_release_date: date @index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The schema file specifies creation of an index on the two predicates.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Start Dgraph with a schema which specifies the predicates to index.
dgraph --schema ~/work/src/github.com/dgraph-io/benchmarks/data/goldendata.schema
# Load the data
dgraphloader -r ~/work/src/github.com/dgraph-io/benchmarks/data/neo4j/neo.rdf.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With data loaded up into both the databases, we &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmarked&lt;/a&gt; both simple and complex queries. The results didn&amp;rsquo;t surprise us.&lt;/p&gt;

&lt;h4 id=&#34;benchmarking-process&#34;&gt;Benchmarking process&lt;/h4&gt;

&lt;p&gt;The benchmarks for Neo4j and &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 were run separately so that both processes could utilize full CPU and RAM resources. Each sub-benchmark was run for 10s so that sufficient iterations could be run. We also monitored the memory usage for both the processes using a simple shell script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go test -v -bench=Dgraph -benchtime=10s .
go test -v -bench=Neo -benchtime=10s .
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Id&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQ&lt;/td&gt;
&lt;td&gt;Get all films and genres of &lt;strong&gt;films directed by Steven Spielberg.&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQM&lt;/td&gt;
&lt;td&gt;Runs the query above and changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and get &lt;strong&gt;their films sorted by release date&lt;/strong&gt;.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their films &lt;strong&gt;released after 1984-08&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their movies &lt;strong&gt;released between 1984-08 and 2000&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If the test id has a &lt;code&gt;P&lt;/code&gt; suffix, it was run in parallel.&lt;/p&gt;

&lt;h4 id=&#34;read-only-benchmarks&#34;&gt;Read-only benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/read-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/read-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Queries to Dgraph took the same amount of time, as expected in the both cases. But, Neo4j query latency was at least &lt;em&gt;halved&lt;/em&gt;. That&amp;rsquo;s not surprising given all the subsequent runs were using query cache. &lt;strong&gt;Thence, Neo4j latency was better than Dgraph with query caching turned on, and worse when off.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;read-write-benchmarks&#34;&gt;Read-write benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/read-write-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://blog.dgraph.io/images/read-write-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For intertwined reads and writes, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is at least 3x to 6x faster.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can see that Neo4j is &lt;strong&gt;even slower with query caching on&lt;/strong&gt; because they have to do the extra work of cache invalidation on writes. Dgraph was designed to achieve low latency querying with real world use cases, where reads are typically followed by writes and vice-versa, and the &lt;strong&gt;performance benefits show in the numbers.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not just that, Neo4j takes up &lt;strong&gt;much more memory&lt;/strong&gt;. At the start of the benchmarks &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumed around 20 MB which increased to 600 MB at the end. In comparison, Neo4j was already consuming 550 MB at the start which increased to 3.2 GB at the end of the benchmarks.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumes 5x lesser memory compared to Neo4j and is at least 3x faster for intertwined reads and writes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-issues-faced&#34;&gt;3. Issues faced&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;div id=&#34;1&#34;&gt;&lt;/div&gt;We couldn&amp;rsquo;t find a convenient way to load large amount of interconnected graph data into Neo4j apart from breaking it into CSV files. We had to write a loader which could concurrently load RDF data into Neo4j.&lt;/li&gt;
&lt;li&gt;&lt;div id=&#34;2&#34;&gt;&lt;/div&gt;We hit data corruption issues on sending more than 20 requests concurrently, which the database could not recover from. In comparison, we typically send 500 concurrent requests to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, each request batching 1000 N-Quads.&lt;/li&gt;
&lt;li&gt;While loading data concurrently and opening 100 connections, Neo4j started returning bad connection error because it hit the limit of maximum open file descriptors which was set to 1024 (the default). We have never witnessed such a problem with Dgraph.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-features&#34;&gt;4. Features&lt;/h3&gt;

&lt;p&gt;We talked about performance and issues. Now, let&amp;rsquo;s see how does Dgraph compare against Neo4j regarding features.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;th&gt;Neo4j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Production Features&lt;/td&gt;
&lt;td&gt;Highly available, Consistent, Fault tolerant&lt;/td&gt;
&lt;td&gt;Master-slave architecture (only full data replicas)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data Sharding&lt;/td&gt;
&lt;td&gt;Yes. Data sharded and replicated across servers, using consensus for writes.&lt;/td&gt;
&lt;td&gt;No data sharding.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Horizontal Scalability&lt;/td&gt;
&lt;td&gt;Yes. Add servers to cluster on the fly to distribute data better.&lt;/td&gt;
&lt;td&gt;Supports only full data replicas&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transactional Model&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.bailis.org/blog/linearizability-versus-serializability/&#34;&gt;Linearizability&lt;/a&gt; aka Atomic Consistency&lt;/td&gt;
&lt;td&gt;ACID transactions&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Backups&lt;/td&gt;
&lt;td&gt;Hot backups in RDF format available using the HTTP interface&lt;/td&gt;
&lt;td&gt;Hot full and incremental backups available only as part of paid enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;HTTP API for queries and mutations&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communication using clients over binary protocol&lt;/td&gt;
&lt;td&gt;Yes, using grpc&lt;/td&gt;
&lt;td&gt;Yes, using bolt protocol&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Bulk loading of graph data&lt;/td&gt;
&lt;td&gt;Yes, can load arbitrarily connected RDF data using dgraphloader&lt;/td&gt;
&lt;td&gt;Only supports loading relational data in CSV format using the loader&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Schema&lt;/td&gt;
&lt;td&gt;Optional (supports int, float, string, bool, date, datetime and geo types)&lt;/td&gt;
&lt;td&gt;Optional (supports byte, short, int, long, float, double, char and string types)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Geospatial Queries&lt;/td&gt;
&lt;td&gt;Yes. Supports near, within, contains, intersects&lt;/td&gt;
&lt;td&gt;No. Not part of core database&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Query language&lt;/td&gt;
&lt;td&gt;GraphQL like which responds in JSON&lt;/td&gt;
&lt;td&gt;Cypher&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Order by, limit, skip and filter queries&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Authorization and authentication&lt;/td&gt;
&lt;td&gt;SSL/TLS and auth token based security (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports basic user authentication and authorization&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Aggregation queries&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports count(), sum(), avg(), distinct and other aggregation queries&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Access Control Lists&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Available based on roles as part of enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Support for plugins and user defined functions&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Browser interface for visualization&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Dgraph (2016) is a lot younger project than Neo4j (2007), so reaching feature parity quickly was a tough job.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Dgraph supports most of the functionality that one &lt;em&gt;needs&lt;/em&gt; to get the job done; though it doesn&amp;rsquo;t have all the functionality one might &lt;em&gt;want&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;5-principles-behind-dgraph&#34;&gt;5. Principles behind Dgraph&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 runs very well on our (Linux) Thinkpads, it is designed to be a graph database for production. As such, it allows the ability to shard and distribute data over many servers. Consistency and fault tolerance are baked deep into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to the point where even our tests need to start a &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query_test.go#L2715&#34;&gt;single-node Raft cluster&lt;/a&gt;. All the writes, irrespective of which replica they end up on, can be read back instantaneously, i.e. linearizable (work in progress, ETA v0.8). A few server crashes would not lose data or affect the end-user queries, making the system highly-available.&lt;/p&gt;

&lt;p&gt;Such features have traditionally been a talk for NoSQL databases or Spanner, not for graph databases. But, we think any production system, on which the entire application stack is based, &lt;strong&gt;must stay up, perform and scale well.&lt;/strong&gt; The system must be able to utilize the server running it well, process a lot of queries per second, and provide a consistent latency.&lt;/p&gt;

&lt;p&gt;Also, given we&amp;rsquo;re building a graph database, the system should be able to handle &lt;strong&gt;arbitrarily dense interconnected data and complex queries.&lt;/strong&gt; It should not be confined by pre-optimization of certain edges, or other tricks to make certain queries run fast.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The speed achieved should be due to a better design and across the entire spectrum.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, running and maintaining such a system should be easy to the engineers. And that&amp;rsquo;s only possible if the system is &lt;strong&gt;as simple as it can be,&lt;/strong&gt; and every piece of complexity introduced to the system is carefully weighted.&lt;/p&gt;

&lt;p&gt;These are the principles which guide us towards building Dgraph. And we&amp;rsquo;re glad that in a short period, we&amp;rsquo;ve been able to achieve many of these. Now we leave it to you, our users to &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;try out Dgraph&lt;/a&gt;, and let us know what you think.&lt;/p&gt;

&lt;hr /&gt;

&lt;h5 id=&#34;criticism-to-these-benchmarks-updated-feb-1-2017&#34;&gt;Criticism to these benchmarks (Updated Feb 1, 2017)&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;This reads like marketing material:&lt;/strong&gt; &lt;em&gt;You&amp;rsquo;re on Dgraph blog!&lt;/em&gt; Having said that, the benchmarking code is &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;open source&lt;/a&gt; and available to any one willing to put some time to verify these benchmarks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Query caching was turned off:&lt;/strong&gt; The benchmarks above showcase results for Neo4j with &lt;em&gt;both caching turned on and off.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j only uses query plan cache, not result cache:&lt;/strong&gt; That&amp;rsquo;s not what we observed. In fact, for the same read-write query, Neo4j latency increased when caching was turned on, compared to when off (as you can see in the read-write benchmarks above). A pure query plan cache shouldn&amp;rsquo;t be affected by data changes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JVM takes time to warm up:&lt;/strong&gt; Each benchmark was run for 10 seconds by Go, which ran thousands of iterations for the same query to get accurate latency per iteration. We think the JVM should be able to warm up by then.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j queries could be optimized:&lt;/strong&gt; Just mentioning it doesn&amp;rsquo;t help. Please send us a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;pull request&lt;/a&gt; to optimize Neo4j data loading and queries. Or, &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;send us&lt;/a&gt; a mail.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Benchmarking on a laptop isn&amp;rsquo;t right:&lt;/strong&gt; We are just looking for relative performance, not absolute performance. It shouldn&amp;rsquo;t matter which machine you run them on.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Manish will be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Gophercon India on 24-25th Feb. If you&amp;rsquo;re attending the conference, find him to talk about all things Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are happy to &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;accept feedback&lt;/a&gt; about any improvements to the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;loader&lt;/a&gt; or the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmark tests&lt;/a&gt; to get better results for Neo4j.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you haven&amp;rsquo;t already tried &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/goddard/2016/hubble-gazes-at-a-cosmic-megamaser&#34;&gt;Hubble Gazes at a Cosmic Megamaser&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Releasing Dgraph v0.7.1</title>
      <link>https://blog.dgraph.io/post/v0.7-release/</link>
      <pubDate>Thu, 05 Jan 2017 20:00:00 +1100</pubDate>
      
      <guid>https://blog.dgraph.io/post/v0.7-release/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 team is super excited to present v0.7.1 of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
. This version is the biggest step we&amp;rsquo;ve taken towards our production aim of v1.0.
We&amp;rsquo;ve implemented &lt;strong&gt;90% of all the features we had planned&lt;/strong&gt; in our &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/1&#34;&gt;product roadmap&lt;/a&gt;, including replication and high-availability using RAFT protocol, indexing, filtering, sorting, geospatial queries, and backups.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Today, I&amp;rsquo;m going to talk about these new features, and what you can expect from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note: This is going to be a long blog post. If you just want to try out &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, you can jump straight to our &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 v0.7.1 is the &lt;em&gt;fastest&lt;/em&gt; version of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 we&amp;rsquo;ve ever released. Live data loading is now so fast that we realized we no longer needed a separate offline batch data loader. So, we removed all that complexity and just wrote a simple script to send mutation queries to live &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 via GRPC.&lt;/p&gt;

&lt;p&gt;You can read more about loading and querying performance &lt;a href=&#34;https://wiki.dgraph.io/Performance&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;data-persistence-sharding-high-availability-and-crash-resilience&#34;&gt;Data Persistence, Sharding, High Availability, and Crash Resilience&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 has been built from ground up to be run in Google scale production environments. To run terabytes of structured data over commodity hardware has been the main aim since the beginning. To achieve that, Dgraph needs to be able to deal with server failures; without losing any data or dropping any queries.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve implemented RAFT, a distributed consensus algorithm within &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to handle such failures. Any writes that happen to go through a group of servers and are only acknowledged to the client once they&amp;rsquo;ve been applied to a majority of servers in the group. Thus, even if some of these servers crash, the data can be accessed, updated and queries can flow without the user getting affected.&lt;/p&gt;

&lt;p&gt;Also, new servers can be introduced into an existing cluster by providing the IP address of any healthy server in the cluster. They will automatically pick up the other members, pull in data shards from healthy nodes, join the groups and become part of the cluster.&lt;/p&gt;

&lt;p&gt;Such functionality has never been an aim for graph databases in the past. But we strongly believe that graph databases can be run as the primary databases; not just add-ons. To that effect, it&amp;rsquo;s important that they be able to survive machine crashes and avoid data loss.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This functionality makes &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 the most production ready graph database in the market.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can read more about running multiple instances of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, sharding and distributing data in a cluster &lt;a href=&#34;https://wiki.dgraph.io/Deploy&#34;&gt;here&lt;/a&gt;. In fact, we created a small video to show you how &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can recover from crashes without losing any data directly after a load.
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/dzTEXxF0TGs?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;h3 id=&#34;backups&#34;&gt;Backups&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 believes in standards. We heartily use the existing RDF NQuad standard for data input. Now, we&amp;rsquo;re making it easy to export data from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 to other systems, by exporting our backups in RDF NQuad format. This makes it easy to feed &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 data into other systems, upgrade &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 versions or to switch over to another graph database. You can read more about backup &lt;a href=&#34;https://wik.dgraph.io/Deploy#Backup&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;indexing&#34;&gt;Indexing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can now index various scalar values to allow sorting,  term matching, and inequality filters. We support these value types: &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;date&lt;/code&gt;, &lt;code&gt;datetime&lt;/code&gt;, &lt;code&gt;geo&lt;/code&gt;, &lt;code&gt;uid&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;String values get tokenized using ICU, and allow &lt;code&gt;allof&lt;/code&gt; and &lt;code&gt;anyof&lt;/code&gt; functions.
&lt;code&gt;geo&lt;/code&gt; values allow for geo-indexing and support the geo functions mentioned below. &lt;code&gt;uid&lt;/code&gt; value is a way to indicate that the predicate edge points to another entity node.
This is useful to generate edges in reverse direction automatically. The rest support sorting, equality and inequality functions.&lt;/p&gt;

&lt;p&gt;If you want to generate the index for a particular predicate, mention its type and specify the &lt;code&gt;@index&lt;/code&gt; keyword.
Similarly, to generate reverses for a uid predicate, you can specify the &lt;code&gt;@reverse&lt;/code&gt; keyword.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example schema file for freebase film data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
  film.director.film             : uid    @ reverse
  film.film.genre                : uid    @ reverse
  film.film.initial_release_date : date   @ index
  film.film.rating               : uid    @ reverse
  loc                            : geo    @ index
  type.object.name.en            : string @ index
  type.object.name.hi            : string @ index
  type.object.name.ta            : string @ index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 schema &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;reverse-edges&#34;&gt;Reverse Edges&lt;/h4&gt;

&lt;p&gt;Each graph edge is unidirectional. But a lot of times, you need to have both the forward and backward edges. For those cases, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now provides a &lt;code&gt;@reverse&lt;/code&gt; keyword, which can be applied to predicates of &lt;code&gt;uid&lt;/code&gt; type. This would trigger automatic generation of the reverse edges, to allow querying in the reverse direction.&lt;/p&gt;

&lt;p&gt;You can read more about reverse edges &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Reverse_Edges&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;sorting&#34;&gt;Sorting&lt;/h3&gt;

&lt;p&gt;You can now sort the results by any indexed predicate (except string and geo, of course). For example, you can now get a list of films directed by Steven Spielberg sorted by initial release date.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film(order: film.film.initial_release_date) {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}

# To sort in descending order, just use orderdesc instead of order.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about sorting &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Sorting&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;functions&#34;&gt;Functions&lt;/h3&gt;

&lt;p&gt;Functions are a great way to provide functionality with a simple and clear interface. &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 functions can be used as both starting points to queries and as filters.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a list of functions we introduced in v0.7.1:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;anyof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has any of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has all of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is less than or equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is greater than or equal to specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both &lt;code&gt;anyof&lt;/code&gt; and &lt;code&gt;allof&lt;/code&gt; functions work based on an index generated by tokenizing string values. We use ICU, which has vast support for human languages and is used by major projects like Google Web Search, Chrome, Mac OSX, Lucene, etc.&lt;/p&gt;

&lt;p&gt;Upcoming in v0.7.2:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;eq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;le(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is less than specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ge(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is greater than specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To enable these functions, a &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;schema providing the scalar type&lt;/a&gt; for the predicates should be provided. For e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar(
  name          : string @ index # anyof, allof
  age           : int    @ index # leq, geq
  date_of_birth : date   @ index # leq, geq
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about functions &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Functions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;geospatial-functions&#34;&gt;Geospatial functions&lt;/h4&gt;

&lt;p&gt;Geospatial queries are important to build location-aware search and recommendations. Being able to find the nearby restaurants who serve sushi, or bars in the city which play Jazz, or friends who are visiting your neighborhood is pretty crucial to such use cases. We couldn&amp;rsquo;t imagine building a database without providing full-fledged support for geo queries, and in v0.7.1, we added geo indexing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports four geospatial functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;near(predicate, geo-location)&lt;/code&gt;      : Finds all entities lying within a specified distance from a point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;within(predicate, geo-polygon)&lt;/code&gt;     : Finds all entities lying within a specified region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;contains(predicate, geo-location)&lt;/code&gt;  : Finds all enclosures for a specified point or region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;intersects(predicate, geo-polygon)&lt;/code&gt; : Finds all entities which intersect a specified region.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:8080/query -XPOST -d $&#39;
{
  tourist( near(&amp;quot;loc&amp;quot;, &amp;quot;{\&#39;type\&#39;:\&#39;Point\&#39;, \&#39;coordinates\&#39;: [-122.469829, 37.771935]}&amp;quot;, &amp;quot;1000&amp;quot; ) ) {
    name
  }
}&#39; | python -m json.tool | grep name

            &amp;quot;name&amp;quot;: &amp;quot;Steinhart Aquarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Spreckels Temple of Music&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Pioneer Log Cabin&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Conservatory of Flowers&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;De Young Museum&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Chinese Pavillion&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Japanese Tea Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Peace Lantern&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;San Francisco Botanical Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Morrison Planetarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;California Academy of Sciences&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Hamon Tower&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;National AIDS Memorial Grove&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;La Rose des Vents&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Strawberry Hill&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Buddha&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Rose Garden&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about Geolocation functionality &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Geolocation&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;filtering&#34;&gt;Filtering&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports pretty advanced and complex filtering operations. We do both &amp;amp;&amp;amp; (and) and || (or) filters, using round brackets to specify the right sequence. For e.g., &lt;code&gt;(A || (B &amp;amp;&amp;amp; C))&lt;/code&gt;, as demonstrated in the following query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film @filter(
      allof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jones indiana&amp;quot;) ||
      (anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jurassic&amp;quot;) &amp;amp;&amp;amp; anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;park&amp;quot;)))  {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that, I&amp;rsquo;ll finish the blog post. &lt;strong&gt;If you found these interesting, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ll be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Go Meetup in Sydney on 19th Jan and in Gophercon India on 24-25th Feb. So, come talk to me about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;</description>
    </item>
    
    <item>
      <title>Dgraph hugo blog theme</title>
      <link>https://blog.dgraph.io/post/hugo/</link>
      <pubDate>Thu, 06 Oct 2016 16:56:08 +0530</pubDate>
      
      <guid>https://blog.dgraph.io/post/hugo/</guid>
      <description>&lt;p&gt;We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 love &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and use it for our blog. It&amp;rsquo;s blazingly fast, supports Markdown is written in Go and is very easy to work with. Initially, we were confused between Hugo vs. having a publication on Medium but later decided to go with Hugo because of the factors mentioned above. One of the things that we found lacking in the Hugo ecosystem was a good theme that we could use for our blog.&lt;/p&gt;

&lt;p&gt;So we got a theme designed which fit well with our website and used the screen estate well. It&amp;rsquo;s now available at &lt;a href=&#34;http://themes.gohugo.io/hugo-dgraph-theme/&#34;&gt;Dgraph theme&lt;/a&gt;. The theme is responsive, supports syntax highlighting for code and &lt;a href=&#34;https://www.discourse.org/&#34;&gt;discourse&lt;/a&gt; for comments. If your project is open source, you can also link to Github. We would encourage you to try out the theme and let us know your experiences with it.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://docs.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://docs.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.nasa.gov/image-feature/jpl/pia20027/infrared-echoes-of-a-black-hole-eating-a-star/&#34;&gt;Infrared Echoes of a Black Hole Eating a Star&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>