<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dgraph Blog</title>
    <link>https://open.dgraph.io/index.xml</link>
    <description>Recent content on Dgraph Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright (c) 2016, Dgraph Labs, Inc. All rights reserved.</copyright>
    <lastBuildDate>Thu, 29 Jun 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://open.dgraph.io/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Build a Realtime Recommendation Engine: Part 1</title>
      <link>https://open.dgraph.io/post/recommendation/</link>
      <pubDate>Thu, 29 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://open.dgraph.io/post/recommendation/</guid>
      <description>

&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;

&lt;p&gt;In today&amp;rsquo;s world, user experience is paramount. It&amp;rsquo;s no longer about basic CRUD, just serving user
data; it&amp;rsquo;s about mining the data to generate interesting predictions and suggesting actions to the
user.&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the field of recommendations. They&amp;rsquo;re everywhere. In fact, they happen so frequently that you
don&amp;rsquo;t even realize them.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;You wake up and open Facebook,&lt;/em&gt; which shows you a feed of articles that it
has chosen for you based on your viewing history.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to buy something?&lt;/em&gt; Amazon would recommend
you things to purchase based on what you&amp;rsquo;ve viewed in the recent past.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to relax and unwind with a movie?&lt;/em&gt; Netflix would recommend you what to watch based on your
interests.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;No time to watch a full movie?&lt;/em&gt; YouTube would recommend you smaller chunk videos.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Want to listen to music instead?&lt;/em&gt; Spotify would generate a weekly discovery list of songs just for
you.&lt;/p&gt;

&lt;p&gt;All this makes you wonder: &lt;strong&gt;Should recommendations be part of your application?&lt;/strong&gt; While competing
against Netflix might be hard, in this two-part series, we&amp;rsquo;ll explain the basics of a recommendation
engine. We&amp;rsquo;ll show how you can build recommendations via two approaches: Content-based filtering and
Collaborative filtering. And, how you can use Dgraph to bring recommendations to your app without breaking a
sweat.&lt;/p&gt;

&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}
});
&lt;/script&gt;
&lt;script type=&#34;text/javascript&#34; async
  src=&#34;https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML&#34;&gt;
&lt;/script&gt;

&lt;p&gt;For this, we&amp;rsquo;ll make use of Dgraph&amp;rsquo;s query variables. To learn more about variables, head over to
&lt;a href=&#34;https://tour.dgraph.io/blocksvars/1/&#34;&gt;Dgraph tour&lt;/a&gt; &amp;mdash; &lt;em&gt;if you are new to Dgraph variables, you
really should check them out first before diving in here.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first check out how recommendation systems work, and then we&amp;rsquo;ll look at the support Dgraph queries offer.  We&amp;rsquo;ll use two sample datasets.  One about movies and ratings (&lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;Movielens&lt;/a&gt;) and the other is part of &lt;a href=&#34;https://archive.org/download/stackexchange/lifehacks.stackexchange.com.7z&#34;&gt;Stack Exchange&amp;rsquo;s data archive&lt;/a&gt; &amp;mdash; we&amp;rsquo;ll just use the Lifehacks dataset here, but watch out for a coming series of posts where we show how to load all of Stack Overflow into Dgraph and run the entire website completely off Dgraph.&lt;/p&gt;

&lt;h2 id=&#34;recommendation-systems&#34;&gt;Recommendation Systems&lt;/h2&gt;

&lt;p&gt;Making Recommendations is a subtle art.  There are a number of approaches and a production worthy recommendation system might depend on data, weighting of various features, global user behaviour and maybe recent behaviour of the user we are recommending for.&lt;/p&gt;

&lt;p&gt;Rather than just inventing recommendation queries, let&amp;rsquo;s start somewhere more grounded.  For this post, we started with the Stanford University MOOC &lt;a href=&#34;https://lagunita.stanford.edu/courses/course-v1:ComputerScience+MMDS+SelfPaced/about&#34;&gt;Minning Massive Datasets&lt;/a&gt;.  Part of the course is on recommender systems.  We&amp;rsquo;ll show how the theory in the &lt;em&gt;&amp;ldquo;Recommendation Systems&amp;rdquo;&lt;/em&gt; chapter of the &lt;a href=&#34;http://www.mmds.org&#34;&gt;text&lt;/a&gt; can be translated into practice using Dgraph. We&amp;rsquo;ll also talk about other approaches and how to run one at scale.&lt;/p&gt;

&lt;h3 id=&#34;making-recommendations&#34;&gt;Making Recommendations&lt;/h3&gt;

&lt;p&gt;Making recommendations is about taking past benaviour and preferences and trying to predict a preference for some unknown.  For example, later in the post, we&amp;rsquo;ll talk about movie recommendations.  For this, we know what a user has watched and how they rated movies; how then can we predict what unwatched movies they&amp;rsquo;ll enjoy.&lt;/p&gt;

&lt;p&gt;As briefly mentioned before, broadly speaking, there are two basic approaches:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Content-based:&lt;/strong&gt; Such systems base a recommendation on the properties of an item. Two items that have similar properties are deemed similar; the more properties shared, the more similar. For example, if a user likes movies with certain actors or directors, we can
recommend other movies involving the same people.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Collaborative filtering:&lt;/strong&gt; Such systems base recommendations on the relationship between users and items, and similarity to other users. Users are similar if they have relationships to items in common; the more items in common, the more similar.  For example, if many similar users enjoyed a particular movie, that might be a good one to recommend.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are also classification algorithms based on machine learning.  We&amp;rsquo;ll focus here on how far we can get with Dgraph queries alone.  Machine learning or other algorithms could also be run over the Dgraph output.&lt;/p&gt;

&lt;h3 id=&#34;interpreting-the-data-for-recommendations&#34;&gt;Interpreting the Data for Recommendations&lt;/h3&gt;

&lt;p&gt;Our Stanford reference text represents data as a sparse matrix.  So for our movie data set, we might think of the user&amp;rsquo;s ratings of movies as:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;User&lt;/th&gt;
&lt;th&gt;The Matrix&lt;/th&gt;
&lt;th&gt;Toy Story&lt;/th&gt;
&lt;th&gt;Jurassic Park&lt;/th&gt;
&lt;th&gt;Forrest Gump&lt;/th&gt;
&lt;th&gt;Braveheart&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;A&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;B&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;C&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The movies also have other properties such as genres, not shown here.  We&amp;rsquo;ve stored it all as a graph, which in itself is a nice way to store a sparse matrix.&lt;/p&gt;

&lt;p&gt;The matrix (that&amp;rsquo;s the matrix above, not &lt;em&gt;&amp;ldquo;&lt;a href=&#34;https://en.wikipedia.org/wiki/The_Matrix&#34;&gt;The Matrix&lt;/a&gt;&amp;ldquo;&lt;/em&gt;) is missing values because users haven&amp;rsquo;t seen all movies &amp;mdash; in fact, for the real dataset it&amp;rsquo;s much sparser because users have each only rated a tiny percentage of the movies.&lt;/p&gt;

&lt;p&gt;The challenge of recommendation is to predict values for the missing ratings.  Will user A enjoy Braveheart because it&amp;rsquo;s an action movie and thus similar to movies they enjoyed? (content based filtering)&lt;/p&gt;

&lt;p&gt;But maybe they won&amp;rsquo;t enjoy it because they might have something in common with user B who seems to share similar ratings (collaborative filtering).&lt;/p&gt;

&lt;p&gt;Maybe user A just gives high ratings and isn&amp;rsquo;t very discriminating &amp;mdash; sometimes benaviour rather than rating can be a better predictor. We&amp;rsquo;ll need to combine a number of approaches.&lt;/p&gt;

&lt;p&gt;The theory boils down to finding functions that serve as measures of similarity or distance.  For example, in content-based filtering, the function would take two movies and output a score (the distance or similarity).  If we start with a movie and apply the function repeatedly to it and all other movies, we can find the most similar movies.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll look at some distance measures below as we apply them in queries, but for any of them we&amp;rsquo;ll need to propagate values through our query, so let&amp;rsquo;s look at how that works in Dgraph and then try out some recommendation queries.&lt;/p&gt;

&lt;h2 id=&#34;variable-propagation&#34;&gt;Variable Propagation&lt;/h2&gt;

&lt;p&gt;A Dgraph &lt;a href=&#34;https://docs.dgraph.io/query-language/#value-variables&#34;&gt;value variable&lt;/a&gt; is a mapping from graph nodes to values that have been computed for the nodes during the query.  Value variables can be passed around the query, aggregated etc.  Value variables also sum over paths as we move deeper into a query tree.&lt;/p&gt;

&lt;p&gt;Within a query tree, a value variable defined at one level, propagates such that in a nested level, the variable is the sum of all paths from the definition.&lt;/p&gt;

&lt;p&gt;We call this &lt;strong&gt;variable propagation.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Say you had a query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  var(id: &amp;lt;...P...&amp;gt;) {
    myscore as math(1)          # A
    friends {                   # B
      friends {                 # C
        fscore as math(myscore)
      }
    }
  }

  closeFriends(id: var(fscore), orderdesc: var(fscore)) {
    name
    var(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At line A, nodes are assigned a score of &lt;code&gt;1&lt;/code&gt; (which in this case we&amp;rsquo;ll assume is the single node &lt;code&gt;P&lt;/code&gt;).
Traversing the &lt;code&gt;friend&lt;/code&gt; edge twice reaches the friends of friends.  The variable &lt;code&gt;myscore&lt;/code&gt; gets
propagated, such that the value inside the block marked C is the sum of values from all paths from A to C.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s how that propagation looks in a graph.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/vartransform.png&#34; alt=&#34;Variable propagation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In short, the value that a node receives is equal to the sum of values of all its parent nodes.&lt;/strong&gt;
This propagation is useful when we want to normalize a sum across users, find the number of paths
between some nodes or accumulate a sum as we move through the graph.&lt;/p&gt;

&lt;h2 id=&#34;movielens&#34;&gt;Movielens&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s start with the &lt;a href=&#34;https://grouplens.org/datasets/movielens/100k/&#34;&gt;ML-100k&lt;/a&gt; dataset of
100,000 ratings from 1000 users on 1700 movies. We converted the dataset to RDF (the dataset and
script can be found at
&lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/movielens/conv100k&#34;&gt;github&lt;/a&gt;) and loaded it into
Dgraph.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s about users and movies and user&amp;rsquo;s ratings of movies.  So a user (a node in the graph) has a name and a gender and a &lt;code&gt;rated&lt;/code&gt; edge to a movie.  The &lt;code&gt;rated&lt;/code&gt; edge has a facet &lt;code&gt;rating&lt;/code&gt; that tells us the users numeric 0&amp;ndash;5 rating of the movie.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/movilensschema.png&#34; alt=&#34;Movielens schema&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;content-based-filtering&#34;&gt;Content-based filtering&lt;/h2&gt;

&lt;p&gt;Content-based filtering ranks items as similar or not based on their properties.  There are a number of measures we could use.  Our reference text from Stanford talks about &lt;strong&gt;Jaccard&lt;/strong&gt; and &lt;strong&gt;Cosine&lt;/strong&gt; distances.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance&#34;&gt;Jaccard Distance&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try some measure functions based on Jaccard distance.  For two sets A and B the Jaccard distance is given by&lt;/p&gt;

&lt;p&gt;$$1-\frac{|A\cap B|}{| A\cup B |}$$&lt;/p&gt;

&lt;p&gt;That&amp;rsquo;s the ratio of the size of the set intersection to the size of the union.  So if items have many properties in common (compared to how many properties each has) then the items are similar.  For our movie example, let&amp;rsquo;s take $A$ and $B$ as the genre sets for each movie.  We can then express our difference function as:&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = 1-\frac{|M_1.\mathcal{genres} \cap M_2.\mathcal{genres}|}{| M_1.\mathcal{genres}\cup M_2.\mathcal{genres} |}$$&lt;/p&gt;

&lt;p&gt;The closer the result is to 0, the closer the movies &amp;mdash; if the number of genres in common is more, the second term is close to 1, if movies have few genres in common, the second term is closer to 0.&lt;/p&gt;

&lt;p&gt;For movie a $M_1$, we picked &amp;ldquo;The Shawshank Redemption&amp;rdquo; with unique ID &lt;code&gt;0x30d80&lt;/code&gt;, and translated Jaccard distance to this query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Count the genres for every movie that has been rated
  var(func: has(~rated)) {
    M2_num_genres as count(genre)
  }


  # Calculate a Jaccard distance score for every movie that shares
  # at least 1 genre with the given movie.
  var(id: 0x30d80) {    # M1
    norm as math(1)               # 1
    M1_num_genres as count(genre) # 2
    M1genres as genre {           # 3
      ~genre {
        # M2 -- movies reached here share a genre with the initial movie
        # normalize the count to account for multiple paths
        M1_num_genres_norm as math(M1_num_genres / norm)      # 4
        num_genres as count(genre @filter(var(M1genres))) # 5
        distance as math( 1 - ( num_genres / (M1_num_genres_norm + M2_num_genres - num_genres) )) # 6
      }
    }
  }

  # Sort and return closest movies.
  similarMovies(id:var(distance), orderasc: var(distance), first: 10) { # 7
    name
    var(distance)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Count the number of genres for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the count of genres set at &lt;code&gt;# 2&lt;/code&gt; would have accumulated for each path, so normalize back to the original count.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the Jaccard distance formula &amp;mdash; &lt;code&gt;distance&lt;/code&gt; is thus a map for each $M_2$ to the Jaccard distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had lowest distance)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Here&amp;rsquo;s the results we got for &amp;ldquo;The Shawshank Redemption&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Miracle on 34th Street (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Postman, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Mat&#39; i syn (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Winter Guest, The (1997)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Chamber, The (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Picnic (1955)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Nell (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Dead Man Walking (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Blue Angel, The (Blaue Engel, Der) (1930)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ouch, there&amp;rsquo;s a bunch of movies with distance 0.  That means all those movies share exactly the same genre set with &amp;ldquo;The Shawshank Redemption&amp;rdquo;, so we can&amp;rsquo;t discriminate between them.  Let&amp;rsquo;s test another movie.  With &amp;ldquo;Toy Story&amp;rdquo; we get.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin and the King of Thieves (1996)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Toy Story (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aladdin (1992)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Goofy Movie, A (1995)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.25
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Flintstones, The (1994)&amp;quot;,
            &amp;quot;var(distance)&amp;quot;: 0.333333
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s better.  At least similar movies have similar genres. But still, the Jaccard distance function isn&amp;rsquo;t good enough because it can&amp;rsquo;t discriminate a difference between many movies.  Our reference text suggests the same distance function but for data that also has actors and directors, which we don&amp;rsquo;t.&lt;/p&gt;

&lt;p&gt;As it stands, the Jaccard distance might not be so appropriate because the only items we have to compare are the genres, since the Jaccard distance doesn&amp;rsquo;t take into account the magnitude of the ratings.  So let&amp;rsquo;s play around with it and see how some variations come out.&lt;/p&gt;

&lt;h3 id=&#34;jaccard-distance-variation&#34;&gt;Jaccard Distance Variation&lt;/h3&gt;

&lt;p&gt;The size of the intersection of the genres seems a reasonable start, but how to bring the magnitude of the ratings into it?  If we are to use the ratings, then the average rating might be appropriate.  Let&amp;rsquo;s try the number of genres in common plus an average rating.  Given a movie $M_1$ we&amp;rsquo;ll find the similarity to all other movies $M_2$ as&lt;/p&gt;

&lt;p&gt;$$d(M_1, M_2) = |M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_2.\overline{\mathcal{rating}}$$&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s the Dgraph query for movie $M_1$ having unique ID &lt;code&gt;0x30d72&lt;/code&gt;, that&amp;rsquo;s &amp;ldquo;Star Wars&amp;rdquo;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # M1 -- Star Wars by its unique ID
  var(id: 0x30d72) {
    g as genre
  }

  # Calculate the average rating for every movie
  var(func: has(rated)) {
    allmovies as rated @facets(a as rating) {
      c as count(~rated)
      avg as math(a / c)
    }
  }

  # Give every movie a score
  var(id: var(allmovies)) {
    x as count(genre @filter(var(g)))
    score as math(avg + x)
  }

  # Return the top 10 movies
  fin(id: var(score), orderdesc: var(score), first: 10) {
    name
    var(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;In terms of variable propagation, the important part is the calculation of average rating.&lt;/strong&gt;  If an edge has a facet and we assign the facet to a variable, we calculate the average. Then for each node reached by the block the variable is the sum of the facets of all such edges reaching the node.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/facetsumming.png&#34; alt=&#34;Facet summing&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running the query we get the following results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;fin&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Wars (1977)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.358491
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Empire Strikes Back, The (1980)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.20436
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Return of the Jedi (1983)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 9.00789
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;African Queen, The (1951)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 8.184211
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Starship Troopers (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.232227
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Princess Bride, The (1987)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.17284
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Kid (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 7.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Aliens (1986)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.947183
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Star Trek: The Wrath of Khan (1982)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.815574
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Men in Black (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 6.745875
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;em&gt;Note that we didn&amp;rsquo;t filter out &amp;ldquo;Star Wars&amp;rdquo; and thankfully it came back as the first result.&lt;/em&gt;  Looks like a pretty good distance function, especially given the top three results, but it&amp;rsquo;s probably biased.  &amp;ldquo;Star Wars&amp;rdquo; is highly rated on average, and so we got back other highly rated movies with intersecting genres.  If we searched for a movie that wasn&amp;rsquo;t highly rated on average, the measure would still prefer highly rated movies with intersecting genres.&lt;/p&gt;

&lt;p&gt;That might be fine.  If a user likes certain genres, then maybe highly rated movie in those genres are good recommendations. Maybe it&amp;rsquo;s better to normalize the result so that two movies come out as more similar if they have genres in common and similar average ratings.  That&amp;rsquo;s what cosine distance does.&lt;/p&gt;

&lt;h3 id=&#34;cosine-distance&#34;&gt;Cosine Distance&lt;/h3&gt;

&lt;p&gt;Cosine distance treats our movies as vectors in an n-dimensional space.  The similarity of the movies is then a measure of the difference in angle between the vectors.  The smaller the angle between two vectors, the more similar the movies.  For our movie example, we can express that as follows.&lt;/p&gt;

&lt;p&gt;If we treat our movies as vectors&lt;/p&gt;

&lt;p&gt;$$x_1 &amp;hellip; x_n$$ and $$y_1 &amp;hellip; y_n$$&lt;/p&gt;

&lt;p&gt;the cosine difference between them is computed by calculating the vector dot product divided by the multiple of the distances from the origin.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cosine_diff.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!--
what&#39;s wrong with this???
$$\frac{\sum_{i=1}^n{x_iy_i}}{\sqrt{\sum_{i=1}^n{x_i^2}}\cdot \sqrt{\sum_{i=1}^n{x_i^2}}}$$
If I paste it into http://www.hostmath.com/ I get what I want
--&gt;

&lt;p&gt;In our case the $x$&amp;rsquo;s up to $x_{n-1}$ will represent the genres, with 1 for genre present and 0 for not present.  While the last term is the average rating.  So for our movie example we can express the cosine difference as.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cosine_diff_movies.png&#34; alt=&#34;cosine difference&#34; /&gt;&lt;/p&gt;

&lt;!-- d(M_1,M_2) = \frac{|M_1.\mathcal{genres}\cap M_2.\mathcal{genres}| + M_1.\overline{\mathcal{rating}} \cdot M_2.\overline{\mathcal{rating}}}{\sqrt{|M_1.\mathcal{genres}| + {M_1.\overline{\mathcal{rating}}}^2}\cdot \sqrt{|M_2.\mathcal{genres}| + {M_2.\overline{\mathcal{rating}}}^2}} --&gt;

&lt;p&gt;That factors in both the intersecting genres as well as the similarity of the average ratings.&lt;/p&gt;

&lt;p&gt;As a single Dgraph query, that looks like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  # Calculate the average rating of every movie
  var(func: has(rated)) {
    rated @facets(r as rating) {
      c as count(~rated)
      M2_avg_rating as math(r / c)
      M2_num_gen as count(genre)
    }
  }

  # Calculate a cosine difference score for every movie that shares
  # at least 1 genre with M1
  var(id: 0x30d80) {    # movie M1
    norm as math(1)     # 1

    # Find the average rating for M1
    M1_num_ratings as count(~rated)
    ~rated @facets(B as rating)
    M1_ratings_sum as sum(var(B))
    M1_avg_rating as math(M1_ratings_sum / M1_num_ratings) # 2
    M1_num_gen as count(genre)                             # 3

    M1_genres as genre {
      ~genre { # 4
        # M2 -- movies reached here share a genre with the initial movie

        # normalize the M1 count and average to account for multiple paths
        M1_norm_avg as math(M1_avg_rating / norm)
        num_genN as math(M1_num_gen/norm)              # 5
        genint as count(genre @filter(var(M1_genres))) # 6

        score as math((genint + (M1_norm_avg * M2_avg_rating)) / 
          (sqrt(num_genN + (M1_norm_avg*M1_norm_avg)) * 
          sqrt(M2_num_gen + (M2_avg_rating*M2_avg_rating))))    # 7

      }
    }
  }

  similarMovies(id:var(score), first:20, orderdesc: var(score)) { # 8
    name
    var(score)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The query works as follows.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;We are going to need to normalize some results, so begin by setting &lt;code&gt;norm&lt;/code&gt; to 1.&lt;/li&gt;
&lt;li&gt;Find the average rating for movie $M_1$.&lt;/li&gt;
&lt;li&gt;Count the genres for $M_1$.&lt;/li&gt;
&lt;li&gt;Follow &lt;code&gt;genre&lt;/code&gt; paths to find all movies $M_2$ that share a genre with $M_1$.&lt;/li&gt;
&lt;li&gt;We may have reached this $M_2$ via multiple genre paths and the values from &lt;code&gt;# 2&lt;/code&gt; and &lt;code&gt;# 3&lt;/code&gt; would have accumulated for each path, so normalize back to the originals.&lt;/li&gt;
&lt;li&gt;Find the number of intersecting genres.&lt;/li&gt;
&lt;li&gt;Apply the cosine distance formula &amp;mdash; &lt;code&gt;score&lt;/code&gt; is thus a map for each $M_2$ to the cosine distance between $M_1$ and $M_2$.&lt;/li&gt;
&lt;li&gt;Filter out the movies that were closest (had cosine closer to 1, and thus lowest angle)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We searched again for the &amp;ldquo;The Shawshank Redemption&amp;rdquo; and got these results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
    &amp;quot;similarMovies&amp;quot;: [
        {
            &amp;quot;name&amp;quot;: &amp;quot;Shawshank Redemption, The (1994)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 1.0
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Anna (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Some Mother&#39;s Son (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999997
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;12 Angry Men (1957)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999988
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Bitter Sugar (Azucar Amargo) (1996)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999985
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Citizen Kane (1941)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;To Kill a Mockingbird (1962)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;One Flew Over the Cuckoo&#39;s Nest (1975)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999971
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Pather Panchali (1955)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999965
        },
        {
            &amp;quot;name&amp;quot;: &amp;quot;Good Will Hunting (1997)&amp;quot;,
            &amp;quot;var(score)&amp;quot;: 0.999958
        }
    ]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We didn&amp;rsquo;t filter out &amp;ldquo;The Shawshank Redemption&amp;rdquo; and thus it comes back as the top result &amp;mdash; it has an angle of 0 with itself.  Following that the query returns the results that cosine difference calculates as most similar.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With that, we conclude this post.&lt;/em&gt; In this post, we showcased Jaccard distance, a variation of Jaccard, and finally Cosine
distance. That&amp;rsquo;s three content-based filtering distance metrics and queries for them in Dgraph.  The variables and math function in Dgraph allow us to encode the metrics directly in the query.&lt;/p&gt;

&lt;p&gt;In the next post, we&amp;rsquo;ll take a look at collaborative filtering.  We&amp;rsquo;ll also look at making recommendations for Stack Overflow and how to build a scalable recommendation engine for big graphs.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/media-gallery/detail/149441/9516&#34;&gt;FALCON 9 FIRST STAGE LANDING&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>go get github.com/dgraph-io/dgraph/...</title>
      <link>https://open.dgraph.io/post/goget/</link>
      <pubDate>Mon, 29 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://open.dgraph.io/post/goget/</guid>
      <description>&lt;p&gt;Thank you Go community for all the love that you showered on Badger. Within 8 hours of announcing
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, the blog post &lt;a href=&#34;https://news.ycombinator.com/item?id=14335931&#34;&gt;made it to the first
page&lt;/a&gt; of Hacker News. And within three days, the
Github repo received 1250 stars, having crossed 1500 by the time of this post. We have already
merged &lt;a href=&#34;https://github.com/dgraph-io/badger/graphs/contributors&#34;&gt;contributions&lt;/a&gt; and received
&lt;a href=&#34;https://github.com/dgraph-io/badger/issues&#34;&gt;feedback&lt;/a&gt; that we need to work on.&lt;/p&gt;

&lt;p&gt;All this goes to show how much people enjoy Go native libraries. They
make things easier. Any tool, library or system written in Go can now just run &lt;code&gt;go get
github.com/dgraph-io/badger&lt;/code&gt;, and they have a fast, efficient key-value store to use.&lt;/p&gt;

&lt;p&gt;Dgraph users have been asking us about embeddable and go gettable Dgraph for a while. After
hearing from many different users independently, I decided to &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/673&#34;&gt;create a Github
issue&lt;/a&gt; to track it.&lt;/p&gt;

&lt;p&gt;We had two dependencies on Cgo which prevented &lt;code&gt;go get&lt;/code&gt;able Dgraph in the past:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;ICU library to do tokenization and full-text search.&lt;/li&gt;
&lt;li&gt;RocksDB as the key-value store.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Back in Q1 2017, we got rid of C based ICU library and switched to using parts of Bleve. Bleve simplified our code base, at the cost of losing &lt;a href=&#34;http://www.blevesearch.com/&#34;&gt;CJK support&lt;/a&gt;. But, we thought that&amp;rsquo;s a trade-off we can live with for the time being.&lt;/p&gt;

&lt;p&gt;The second step of replacing RocksDB was a lot harder, and a lot more interesting journey,
culminating in the release of Badger.&lt;/p&gt;

&lt;p&gt;Today, we &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commit/ed048d5d59248875c55ff5fbf14025e67f1a164c&#34;&gt;pushed a
change&lt;/a&gt; to
Dgraph master branch to switch to Badger. That single change resulted in 450K deleted lines and made Dgraph
&lt;code&gt;go get&lt;/code&gt;able. &lt;strong&gt;This is an exciting day for the Dgraph team, as it simplifies our lives as
developers hugely.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not only would we have simpler, faster builds and releases; we&amp;rsquo;d also have profiles going all the way down to
the disk, and all the way out to the RAM. Every aspect of Dgraph system can now be tweaked for
performance. No hard language boundaries, and that&amp;rsquo;s powerful.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I adore changes which delete more code than they add, while also gaining simplicity and functionality. This change is one of those.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/remove-badger-pr.png&#34; alt=&#34;Dgraph PR to replace Badger&#34; /&gt;
&lt;a href=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5&#34;&gt;&lt;img src=&#34;https://asciinema.org/a/1867dtpl8qp2hy0igtok7vgy5.png&#34; alt=&#34;asciicast&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Happy go getting!&lt;/strong&gt; It needs a bit more work before Dgraph can be embedded in your Go code, but
that is coming soon to master. It would be part of the v0.8 release.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Disclaimer: Dgraph in master branch contains latest changes and isn&amp;rsquo;t thoroughly tested. Use it at your own risk.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://apod.nasa.gov/apod/ap060522.html&#34;&gt;Canadarm aboard the ISS&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Badger: A fast key-value store written natively in Go</title>
      <link>https://open.dgraph.io/post/badger/</link>
      <pubDate>Sun, 14 May 2017 20:18:15 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/badger/</guid>
      <description>

&lt;p&gt;We have built an efficient and persistent log structured merge (LSM) tree based key-value store,
natively in Go language.  It is based upon &lt;a href=&#34;https://www.usenix.org/system/files/conference/fast16/fast16-papers-lu.pdf&#34;&gt;WiscKey paper included in USENIX FAST
2016&lt;/a&gt;. This design is
highly SSD-optimized and separates keys from values to minimize I/O amplification; leveraging both
the sequential and the random performance of SSDs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We call it &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/strong&gt; Based on benchmarks, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is at least &lt;strong&gt;3.5x faster than RocksDB&lt;/strong&gt; when
doing random reads.  For value sizes between 128B to 16KB, data loading is 0.86x - 14x faster
compared to RocksDB, with &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; gaining significant ground as value size increases. On the flip
side, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower for range key-value iteration, but that has a lot of room for
optimization.&lt;/p&gt;

&lt;h2 id=&#34;background-and-motivation&#34;&gt;Background and Motivation&lt;/h2&gt;

&lt;h3 id=&#34;word-about-rocksdb&#34;&gt;Word about RocksDB&lt;/h3&gt;

&lt;p&gt;RocksDB is the most popular and probably the most efficient key-value store in the market. It originated
in Google as SSTable which formed the basis for Bigtable, then got released as LevelDB. Facebook
then improved LevelDB to add concurrency and optimizations for SSDs and released that as
RocksDB. Work on RocksDB has been continuously going on for many years now, and it&amp;rsquo;s used in
production at Facebook and many other companies.&lt;/p&gt;

&lt;p&gt;So naturally, if you need a key-value store, you&amp;rsquo;d gravitate towards RocksDB. It&amp;rsquo;s a
solid piece of technology, and it works. The biggest issue with using RocksDB is that it is written in &lt;code&gt;C++&lt;/code&gt;;
requiring the use of Cgo to be called via Go.&lt;/p&gt;

&lt;h3 id=&#34;cgo-the-necessary-evil&#34;&gt;Cgo: The necessary evil&lt;/h3&gt;

&lt;p&gt;At Dgraph, we have been using RocksDB via Cgo since we started. And we&amp;rsquo;ve faced many issues over
time due to this dependency. &lt;a href=&#34;https://dave.cheney.net/2016/01/18/cgo-is-not-go&#34;&gt;Cgo is not Go&lt;/a&gt;, but
when there are better libraries in C++ than Go, Cgo is a necessary evil.&lt;/p&gt;

&lt;p&gt;The problem is, Go CPU profiler doesn&amp;rsquo;t see beyond Cgo calls. Go memory profiler takes it one step
further. Forget about giving you memory usage breakdown in Cgo space, Go memory profiler fails to
even notice the presence of Cgo code. Any memory used by Cgo would not even make it to the memory
profiler. Other tools like Go race detector, don&amp;rsquo;t work either.&lt;/p&gt;

&lt;p&gt;Cgo has caused us &lt;code&gt;pthread_create&lt;/code&gt; issues in Go1.4, and then again in Go1.5, due to a bug
regression. Lightweight goroutines become expensive pthreads when Cgo is involved, and we had to
modify how we were writing data to RocksDB to avoid assigning too many goroutines.&lt;/p&gt;

&lt;p&gt;Cgo has caused us memory leaks. Who owns and manages memory when making calls is just not clear.
Go, and C are at the opposite spectrums. &lt;strong&gt;One doesn&amp;rsquo;t let you free memory, the other
requires it.&lt;/strong&gt; So, you make a Go call, but then forget to &lt;code&gt;Free()&lt;/code&gt;, and nothing breaks. &lt;em&gt;Except much later.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Cgo has given us a unmaintainable code. Cgo makes code ugly. The Cgo layer between RocksDB was the one piece of code no one in the team wanted to touch.&lt;/p&gt;

&lt;p&gt;Surely, we fixed the memory leaks in our API usage over time. In fact, I &lt;em&gt;think&lt;/em&gt; we have fixed them
all by now, but I can&amp;rsquo;t be sure. Go memory profiler would never tell you. And every time someone
complains about Dgraph taking up more memory or crashing due to OOM, it makes me nervous that this
is a memory leak issue.&lt;/p&gt;

&lt;h3 id=&#34;huge-undertaking&#34;&gt;Huge undertaking&lt;/h3&gt;

&lt;p&gt;Everyone I told about our woes with Cgo, told me that we should just work on fixing those issues.
Writing a key-value store which can provide the same performance as RocksDB is a huge undertaking, not
worth our effort. Even my team wasn&amp;rsquo;t sure. I had my doubts as well.&lt;/p&gt;

&lt;p&gt;I have great respect for any piece of technology which has been iterated upon by the smartest
engineers on the face of the planet for years. RocksDB is that. And if I was writing Dgraph in C++,
I&amp;rsquo;d happily use it.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;But, I just hate ugly code.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And I hate recurring bugs. No amount of effort would have ensured that we would no longer have any
more issues with using RocksDB via Cgo. I wanted a clean slate, and my profiler tools back. Building
a key-value store in Go from scratch was the only way to achieve it.&lt;/p&gt;

&lt;p&gt;I looked around. The existing key-value stores written in Go didn&amp;rsquo;t even come close to RocksDB&amp;rsquo;s
performance. And that&amp;rsquo;s a deal breaker. &lt;strong&gt;You don&amp;rsquo;t trade performance for cleanliness. You demand
both.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;So, I decided we will replace our dependency on RocksDB, but given this isn&amp;rsquo;t a priority for Dgraph,
none of the team members should work on it. This would be a side project that only I will
undertake. I started reading up about B+ and LSM trees, recent improvements to their design, and
came across WiscKey paper. It had great promising ideas. I decided to spend a month away from core
Dgraph, building &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;That&amp;rsquo;s not how it went.&lt;/em&gt; I couldn&amp;rsquo;t spend a month away from Dgraph. Between all the founder duties,
I couldn&amp;rsquo;t fully dedicate time to coding either.  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; developed during my spurts of coding
activity, and one of the team members&amp;rsquo; part-time contributions. Work started end January, and now I
think it&amp;rsquo;s in a good state to be trialed by the Go community.&lt;/p&gt;

&lt;h2 id=&#34;lsm-trees&#34;&gt;LSM trees&lt;/h2&gt;

&lt;p&gt;Before we delve into &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, let&amp;rsquo;s understand key-value store
designs. They play an important role in data-intensive applications including databases. Key-value
stores allow efficient updates, point lookups and range queries.&lt;/p&gt;

&lt;p&gt;There are two popular types of implementations: Log-structured merge (LSM) tree based, and B+ tree
based. The main advantage LSM trees have is that all the foreground writes happen in memory, and all
background writes maintain sequential access patterns. Thus they achieve a very high write
thoughput. On the other hand, small updates on B+-trees involve repeated random disk writes, and
hence are unable to maintain high throughput write workload&lt;sup&gt;1&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;To deliver high write performance, LSM-trees batch key-value pairs and write them sequentially.
Then, to enable efficient lookups, LSM-trees continuously read, sort and write key-value pairs in
the background. This is known as a &lt;code&gt;compaction&lt;/code&gt;. LSM-trees do this over many levels, each level
holding a factor more data than the previous, typically &lt;code&gt;size of Li+1 = 10 x size of Li&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Within a single
level, the key-values get written into files of fixed size, in a sorted order. Except level zero,
all other levels have zero overlaps between keys stored in files at the same level.&lt;/p&gt;

&lt;p&gt;Each level has a maximum capacity. As a level &lt;code&gt;Li&lt;/code&gt; fills up, its data gets merged with data from
lower level &lt;code&gt;Li+1&lt;/code&gt; and files in &lt;code&gt;Li&lt;/code&gt; deleted to make space for more incoming data. As data flows
from level zero to level one, two, and so on, the same data is re-written multiple times throughout
its lifetime. Each key update causes many writes until data eventually settles.
This constitutes &lt;em&gt;write amplification&lt;/em&gt;. For a 7 level LSM tree, with 10x size increase factor, this
can be 60; 10 for each transition from L1-&amp;gt;L2, L2-&amp;gt;L3, and so on, ignoring L0 due to special
handling.&lt;/p&gt;

&lt;p&gt;Conversely, to read a key from LSM tree, all the levels need to be checked. If present in multiple
levels, the version of key at level closer to zero is picked (this version is more up to date).
Thus, a single key lookup causes many reads over files, this constitutes &lt;em&gt;read amplification&lt;/em&gt;. WiscKey
paper estimates this to be 336 for a 1-KB key-value pair.&lt;/p&gt;

&lt;p&gt;LSMs were designed around hard drives. In HDDs, random I/Os are over 100x slower than sequential
ones. Thus, running compactions to continually sort keys and enable efficient lookups is an
excellent trade-off.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/nvme-ssd-960pro.jpg&#34; alt=&#34;NVMe SSD Samsung 960 pro&#34; /&gt;&lt;/p&gt;

&lt;p&gt;However, SSDs are fundamentally different from HDDs. The difference between their sequential and
random reads are not nearly as large as HDDs. In fact, top of the line SSDs like &lt;a href=&#34;http://www.anandtech.com/show/10754/samsung-960-pro-ssd-review&#34;&gt;Samsung 960
Pro&lt;/a&gt; can provide 440K random read
operations per second, with 4KB block size. Thus, an LSM-tree that performs a large number of
sequential writes to reduce later random reads is wasting bandwidth needlessly.&lt;/p&gt;

&lt;h2 id=&#34;badger&#34;&gt;Badger&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is a simple, efficient, and persistent key-value store.&lt;/strong&gt;  Inspired by the simplicity of
LevelDB, it provides &lt;code&gt;Get&lt;/code&gt;, &lt;code&gt;Set&lt;/code&gt;, &lt;code&gt;Delete&lt;/code&gt;, and &lt;code&gt;Iterate&lt;/code&gt; functions. On top of it, it adds
&lt;code&gt;CompareAndSet&lt;/code&gt; and &lt;code&gt;CompareAndDelete&lt;/code&gt; atomic operations (&lt;a href=&#34;https://godoc.org/github.com/dgraph-io/badger&#34;&gt;see GoDoc&lt;/a&gt;). It does not aim to be a database and hence
does not provide transactions, versioning or snapshots.  Those things can be easily built on top of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; separates keys from values. The keys are stored in LSM tree, while the values are stored in a
write-ahead log called the &lt;em&gt;value log&lt;/em&gt;. Keys tend to be smaller than values. Thus this set up produces
much smaller LSM trees. When required, the values are directly read from the log stored on SSD,
utilizing its vastly superior random read performance.&lt;/p&gt;

&lt;h3 id=&#34;guiding-principles&#34;&gt;Guiding principles&lt;/h3&gt;

&lt;p&gt;These are the guiding principles that decide the design, what goes in and what doesn&amp;rsquo;t in Badger.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Write it natively in Go language.&lt;/li&gt;
&lt;li&gt;Use the latest research to build the fastest key-value store.&lt;/li&gt;
&lt;li&gt;Keep it simple, stupid.&lt;/li&gt;
&lt;li&gt;SSD-centric design.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;key-value-separation&#34;&gt;Key-Value separation&lt;/h3&gt;

&lt;p&gt;The major performance cost of LSM-trees is the compaction process. During compactions, multiple
files are read into memory, sorted, and written back. Sorting is essential for efficient retrieval,
for both key lookups and range iterations. With sorting, the key lookups would only require accessing at most one file per level (excluding level zero, where we&amp;rsquo;d need to check all the files).
Iterations would result in sequential access to multiple files.&lt;/p&gt;

&lt;p&gt;Each file is of fixed size, to enhance caching. Values tend to be larger than keys. When you store
values along with the keys, the amount of data that needs to be compacted grows significantly.&lt;/p&gt;

&lt;p&gt;In &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, only a pointer to the value in the value log is stored alongside the key. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; employs
&lt;em&gt;delta encoding&lt;/em&gt; for keys to reduce the effective size even further. Assuming 16 bytes per key
and 16 bytes per value pointer, &lt;strong&gt;a single 64MB file can store two million key-value pairs.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;write-amplification&#34;&gt;Write Amplification&lt;/h3&gt;

&lt;p&gt;Thus, the LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller than
that of RocksDB. This smaller LSM-tree reduces the number of levels, and hence number of compactions
required to achieve stability. Also, values are not moved along with keys, because they&amp;rsquo;re elsewhere
in value log. Assuming 1KB value and 16 byte keys, the effective write amplification per level is &lt;code&gt;(10*16 +
1024)/(16 + 1024) ~ 1.14&lt;/code&gt;, a much smaller fraction.&lt;/p&gt;

&lt;p&gt;You can see the performance gains of this approach compared to RocksDB as the value size increases;
where loading data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; takes factors less time (see Benchmarks below).&lt;/p&gt;

&lt;h3 id=&#34;read-amplification&#34;&gt;Read Amplification&lt;/h3&gt;

&lt;p&gt;As mentioned above, the size of LSM tree generated by &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is much smaller. Each file at each
level stores lots more keys than typical LSM trees. Thus, for the same amount of data, fewer levels
get filled up. A typical key lookup requires reading all files in level zero, and one file per level
from level one and onwards. With &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, filling fewer levels means, fewer files need to be read to
lookup a key. Once key (along with value pointer) is fetched, the value can be fetched by doing
random read in value log stored on SSD.&lt;/p&gt;

&lt;p&gt;Furthermore, during benchmarking, we found that &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree is so small, it can easily fit in RAM. For 1KB values and 75 million 22 byte keys, the raw size
of the entire dataset is 72 GB. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree size for
this setup is a mere 1.7G, which can easily fit into RAM.  This is what causes
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s random key lookup performance to be at least 3.5x
faster, and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration to be blazingly
faster than RocksDB.&lt;/p&gt;

&lt;h3 id=&#34;crash-resilience&#34;&gt;Crash resilience&lt;/h3&gt;

&lt;p&gt;LSM trees write all the updates in memory first in memtables. Once they fill up, memtables get
swapped over to immutable memtables, which eventually get written out to files in level zero on
disk.&lt;/p&gt;

&lt;p&gt;In the case of a crash, all the recent updates still in memory tables would be lost.
Key-value stores deal with this issue, by first writing all the updates in a write-ahead log. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;
has a write-ahead log, it&amp;rsquo;s called value log.&lt;/p&gt;

&lt;p&gt;Just like a typical write-ahead log, before any update is applied to LSM tree, it gets written to
value log first. In the case of a crash, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; would iterate over the recent updates in value log, and
apply them back to the LSM tree.&lt;/p&gt;

&lt;p&gt;Instead of iterating over the entire value log, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; puts a pointer to the latest value in each
memtable. Effectively, the latest memtable which made its way to disk would have a value pointer,
before which all the updates have already made their way to disk. Thus, we can replay from this
pointer onwards, and reapply all the updates to LSM tree to get all our updates back.&lt;/p&gt;

&lt;h3 id=&#34;overall-size&#34;&gt;Overall size&lt;/h3&gt;

&lt;p&gt;RocksDB applies block compression to reduce the size of LSM tree. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is much smaller in
comparison and can be stored in RAM entirely, so it doesn&amp;rsquo;t need to do any compression on the tree. However,
the size of value log can grow quite quickly.  Each update is a new entry in the value log, and
therefore multiple updates for the same key take up space multiple times.&lt;/p&gt;

&lt;p&gt;To deal with this, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; does two things. It allows compressing values in value log. Instead of
compressing multiple key-values together, we only compress each key-value individually. This
provides the best possible random read performance. The client can set it so compression is
only done if the key-value size is over an adjustable threshold, set by default to 1KB.&lt;/p&gt;

&lt;p&gt;Secondly, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; runs value garbage collection. This runs periodically and samples a 100MB size of a
randomly selected value log file. It checks if at least a significant chunk of it should be
discarded, due to newer updates in later logs. If so, the valid key-value pairs would be appended to
the log, the older file discarded, and the value pointers updated in the LSM tree. The downside is,
this adds more work for LSM tree; so shouldn&amp;rsquo;t be run when loading a huge data set. More work is
required to only trigger this garbage collection to run during periods of little client
activity.&lt;/p&gt;

&lt;h3 id=&#34;hardware-costs&#34;&gt;Hardware Costs&lt;/h3&gt;

&lt;p&gt;But, given the fact that SSDs are getting cheaper and cheaper, using extra space in SSD is
almost nothing compared to having to store and serve a major chunk of LSM tree from memory. Consider this:&lt;/p&gt;

&lt;p&gt;For 1KB values, 75 million 16 byte keys, RocksDB&amp;rsquo;s LSM tree is 50GB in size. &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s value log is
74GB (without value compression), and LSM tree is 1.7GB. Extrapolating it three times, we get 225 million
keys, RocksDB size of 150GB and &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; size of 222GB value log, and 5.1GB LSM tree.&lt;/p&gt;

&lt;p&gt;Using Amazon AWS US East (Ohio) datacenter:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;To achieve a random read performance equivalent of &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; (at least 3.5x faster), RocksDB would need to
be run on an &lt;code&gt;r3.4xlarge&lt;/code&gt; instance, which provides 122 GB of RAM for &lt;code&gt;$1.33&lt;/code&gt; per hour; so most of its
LSM tree can fit into memory.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be run on the cheapest storage optimized instance &lt;code&gt;i3.large&lt;/code&gt;, which provides 475GB NVMe SSD
(&lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; test: 100K IOPS for 4KB block size), with 15.25GB RAM for &lt;code&gt;$0.156&lt;/code&gt; per hour.&lt;/li&gt;
&lt;li&gt;The cost of running &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is thus, &lt;strong&gt;8.5x cheaper&lt;/strong&gt; than running RocksDB on EC2, on-demand.&lt;/li&gt;
&lt;li&gt;Going 1-year term all upfront payment, this is $6182 for RocksDB v/s $870 for &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, still 7.1x
cheaper. &lt;strong&gt;That&amp;rsquo;s a whopping 86% saving.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;

&lt;h3 id=&#34;setup&#34;&gt;Setup&lt;/h3&gt;

&lt;p&gt;We rented a storage optimized &lt;a href=&#34;https://aws.amazon.com/ec2/instance-types/&#34;&gt;i3.large
instance&lt;/a&gt; from Amazon AWS, which provides 450GB NVMe
SSD storage, 2 virtual cores along with 15.25GB RAM. This instance provides local SSD, which we
tested via &lt;a href=&#34;https://linux.die.net/man/1/fio&#34;&gt;&lt;code&gt;fio&lt;/code&gt;&lt;/a&gt; to sustain close to 100K random read IOPS for 4KB
block sizes.&lt;/p&gt;

&lt;p&gt;The data sets were chosen to generate sizes too big to fit entirely in RAM, in either RocksDB
or &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Value size&lt;/th&gt;
&lt;th&gt;Number of keys (each key = 22B)&lt;/th&gt;
&lt;th&gt;Raw data size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;128B&lt;/td&gt;
&lt;td&gt;250M&lt;/td&gt;
&lt;td&gt;35GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;1024B&lt;/td&gt;
&lt;td&gt;75M&lt;/td&gt;
&lt;td&gt;73GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;16KB&lt;/td&gt;
&lt;td&gt;5M&lt;/td&gt;
&lt;td&gt;76GB&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We then loaded data one by one, first in RocksDB then in &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;, never running the loaders
concurrently. This gave us the data loading times and output sizes. For random &lt;code&gt;Get&lt;/code&gt; and &lt;code&gt;Iterate&lt;/code&gt;,
we used Go benchmark tests and ran them for 3 minutes, going down to 1 minute for 16KB values.&lt;/p&gt;

&lt;p&gt;All the code for benchmarking is available &lt;a href=&#34;https://github.com/dgraph-io/badger-bench&#34;&gt;in this
repo&lt;/a&gt;. All the commands ran and
their measurements recorded are available in &lt;a href=&#34;https://github.com/dgraph-io/badger-bench/blob/master/BENCH.md&#34;&gt;this log
file&lt;/a&gt;. The
charts and their data is &lt;a href=&#34;https://docs.google.com/a/dgraph.io/spreadsheets/d/1x8LUw_85g8Jo9jFtbAwuXrLm_DB1SOG8QCTSjXj8Hk0/edit?usp=sharing&#34;&gt;viewable
here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;

&lt;p&gt;In the following benchmarks, we measured 4 things:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data loading performance&lt;/li&gt;
&lt;li&gt;Output size&lt;/li&gt;
&lt;li&gt;Random key lookup performance (&lt;code&gt;Get&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Sorted range iteration performance (&lt;code&gt;Iterate&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All the 4 measurements are visualized in the following charts.
&lt;img src=&#34;https://open.dgraph.io/images/badger-benchmarks.png&#34; alt=&#34;[Badger](https://github.com/dgraph-io/badger) benchmarks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data loading performance:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-value separation design shows huge performance gains as
value sizes increase. For value sizes of 1KB and 16KB, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; achieves 4.5x and 11.7x more
throughput than RocksDB. For smaller values, like 16 bytes not shown here, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can be 2-3x
slower, due to slower compactions (see further work).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Store size:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; generates much smaller LSM tree, but a larger value size log. The size of
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM tree is proportional only to the number of keys, not values. Thus, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s LSM
tree decreases in size as we progress from 128B to 16KB. In all three scenarios, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; produced an
LSM tree which could fit entirely in RAM of the target server.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Random read latency:&lt;/strong&gt; &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt; latency is only 18% to 27% of RocksDB&amp;rsquo;s &lt;code&gt;Get&lt;/code&gt;
latency. &lt;strong&gt;In our opinion, this is the biggest win of this design.&lt;/strong&gt; This happens because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s
entire LSM tree can fit into RAM, significantly decreasing the amount of time it takes to find the
right tables, check their bloom filters, pick the right blocks and retrieve the key. Value retrieval is then
a single SSD &lt;code&gt;file.pread&lt;/code&gt; away.&lt;/p&gt;

&lt;p&gt;In contrast, RocksDB can&amp;rsquo;t fit the entire tree in memory. Even assuming it can keep the table index
and bloom filters in memory, it would need to fetch the entire blocks from disk, decompress them,
then do key-value retrieval (&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s smaller LSM tree avoids
the need for compression). This obviously takes longer, and given lack of data access locality,
caching isn&amp;rsquo;t as effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Range iteration latency:&lt;/strong&gt;  &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s range iteration is
significantly slower than RocksDB&amp;rsquo;s range iteration, when values are also retrieved from SSD. &lt;em&gt;We
didn&amp;rsquo;t expect this, and still don&amp;rsquo;t quite understand it.&lt;/em&gt; We expected some slowdown due to the need
to do IOPS on SSD, while RocksDB does purely serial reads. But, given the 100K IOPS &lt;code&gt;i3.large&lt;/code&gt;
instance is capable of, we didn&amp;rsquo;t even come close to using that bandwidth, despite pre-fetching.
This needs further work and investigation.&lt;/p&gt;

&lt;p&gt;On the other end of the spectrum, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s key-only iteration is blazingly faster than RocksDB or key-value
iteration (latency is shown by the almost invisible red bar). This is quite useful in certain use
cases we have at Dgraph, where we iterate over the keys, run filters and only retrieve values for a
much smaller subset of keys.&lt;/p&gt;

&lt;h2 id=&#34;further-work&#34;&gt;Further work&lt;/h2&gt;

&lt;h3 id=&#34;speed-of-range-iteration&#34;&gt;Speed of range iteration&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; can do key-only iteration blazingly fast, things slow down when it
also needs to do value lookups. Theoretically, this shouldn&amp;rsquo;t be the case. Amazon&amp;rsquo;s i3.large disk
optimized instance can do 100,000 4KB block random reads per second. Based on this, we should be
able to iterate 100K key-value pairs per second, in other terms six million key-value pairs per minute.&lt;/p&gt;

&lt;p&gt;However, &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;&amp;rsquo;s current implementation doesn&amp;rsquo;t produce SSD
random read requests even close to this limit, and the key-value iteration suffers as a result.
There&amp;rsquo;s a lot of room for optimization in this space.&lt;/p&gt;

&lt;h3 id=&#34;speed-of-compactions&#34;&gt;Speed of compactions&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is currently slower when it comes to running
compactions compared to RocksDB. Due to this, for a dataset purely containing smaller values, it is
slower to load data to &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;. This needs more optimization.&lt;/p&gt;

&lt;h3 id=&#34;lsm-tree-compression&#34;&gt;LSM tree compression&lt;/h3&gt;

&lt;p&gt;Again in a dataset purely containing smaller values, the size of LSM tree would be significantly
larger than RocksDB because &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; doesn&amp;rsquo;t run compression on LSM tree. This should be easy to add
on if needed, and would make a great first-time contributor project.&lt;/p&gt;

&lt;h3 id=&#34;b-tree-approach&#34;&gt;B+ tree approach&lt;/h3&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt; Recent improvements to SSDs might make B+-trees a viable option.
Since WiscKey paper was written, SSDs have made huge gains in random write performance. A new
interesting direction would be to combine the value log approach, and keep only keys and value
pointers in the B+-tree. This would trade LSM tree read-sort-merge sequential write compactions with
many random writes per key update and might achieve the same write throughput as LSM for a much
simpler design.&lt;/p&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;We have built an efficient key-value store, which can compete in performance against top of the line
key-value stores in market. It is currently rough around the edges, but provides a solid platform
for any industrial application, be it data storage or building another database.&lt;/p&gt;

&lt;p&gt;We will be replacing Dgraph&amp;rsquo;s dependency on RocksDB soon with
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt;; making our builds easier, faster, making Dgraph
cross-platform and paving the way for embeddable Dgraph. The biggest win of using
&lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; is &lt;strong&gt;a performant Go native key-value store.&lt;/strong&gt; The
nice side-effects are &lt;strong&gt;~4 times faster &lt;code&gt;Get&lt;/code&gt; and a potential 86% reduction in AWS bills,&lt;/strong&gt; due to
less reliance on RAM and more reliance on ever faster and cheaper SSDs.&lt;/p&gt;

&lt;p&gt;So try out &lt;a href=&#34;https://github.com/dgraph-io/badger&#34;&gt;Badger&lt;/a&gt; in your project, and let us know your experience.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;P.S. Special thanks to &lt;a href=&#34;https://research.google.com/pubs/SanjayGhemawat.html&#34;&gt;Sanjay Ghemawat&lt;/a&gt; and
&lt;a href=&#34;http://pages.cs.wisc.edu/~ll/&#34;&gt;Lanyue Lu&lt;/a&gt; for responding to my questions about design choices.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: Juno spacecraft is the &lt;a href=&#34;http://www.livescience.com/32655-whats-the-fastest-spacecraft-ever.html&#34;&gt;fastest moving human made
object&lt;/a&gt;, traveling at a
speed of 265,00 kmph relative to Earth.&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>String matching in Dgraph v0.7.5</title>
      <link>https://open.dgraph.io/post/string-matching/</link>
      <pubDate>Mon, 10 Apr 2017 12:10:00 +0200</pubDate>
      
      <guid>https://open.dgraph.io/post/string-matching/</guid>
      <description>&lt;p&gt;The recent release of Dgraph is packed with new features and improvements.
Many of them are related to strings - full text search (with support for 15 languages!) and regular expression matching have been added, and handling of string values in multiple languages was greatly improved.
All of these changes make Dgraph an excellent tool for working with multilingual applications.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;values-in-many-languages&#34;&gt;Values in Many Languages&lt;/h3&gt;

&lt;p&gt;We&amp;rsquo;re working hard to keep the query language easy to use and clean.
Dgraph, in v0.7.5, adopted and extended the language tag syntax from the RDF N-Quads standard.
It is intuitive, well-known, and was partially supported in previous versions (during data loading).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s start from the beginning - the data.
Dgraph uses RDF N-Quads for data loading and backup.
String literals in N-Quads may be followed by the &lt;code&gt;@&lt;/code&gt; sign and language tag, e.g. &lt;code&gt;&amp;quot;badger&amp;quot;@en&lt;/code&gt; or &lt;code&gt;&amp;quot;Dachs&amp;quot;@de&lt;/code&gt;.
Multiple such literals may be used as a value for a single entity/attribute pair.&lt;/p&gt;

&lt;p&gt;When querying for a predicate with multiple values, the user is able to use the &lt;code&gt;@lang&lt;/code&gt; notation known from RDF N-Quads.
Many languages can be specified in a list of preference, e.g. &lt;code&gt;@en:de&lt;/code&gt; denotes that preferred language is English, but if such a value is not present, a value in German should be returned.&lt;/p&gt;

&lt;p&gt;Language can also be specified in functions, which is important especially for full text search.&lt;/p&gt;

&lt;h3 id=&#34;example-data&#34;&gt;Example Data&lt;/h3&gt;

&lt;p&gt;The dataset used in all examples is the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/21million.rdf.gz&#34;&gt;Freebase film data&lt;/a&gt;.
As this post is string-oriented, queries are focused on movie titles in multiple languages, and no other information is retrieved.
As we don&amp;rsquo;t have information about type of &lt;code&gt;name&lt;/code&gt;, we use filtering to select only the movie titles, and to limit the number of results a bit - &lt;code&gt;@filter(gt(count(genre), 1))&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The schema for &lt;code&gt;name&lt;/code&gt; field is very simple - it defines 3 types of indexes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl localhost:8080/query -XPOST -d $&#39;
mutation {
  schema {
    name: string @index(term, fulltext, exact) .
  }
}&#39; | python -m json.tool | less
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;term&lt;/code&gt; index is used for term matching with the &lt;code&gt;allofterms&lt;/code&gt; and &lt;code&gt;anyofterms&lt;/code&gt; functions.
Note that it was the only string index available in previous releases of Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;fulltext&lt;/code&gt; index uses matching with language specific stemming and stopwords.
One thing worth noting is, that values indexed with &lt;code&gt;fulltext&lt;/code&gt; are processed according to their&amp;rsquo;s language (if they are tagged). If values are untagged, English is used as a default language.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;exact&lt;/code&gt; index is used for regular expression matching.&lt;/p&gt;

&lt;h3 id=&#34;full-text-search-fts&#34;&gt;Full Text Search (FTS)&lt;/h3&gt;

&lt;h5 id=&#34;very-short-introduction-to-natural-language-processing-nlp&#34;&gt;Very Short Introduction to Natural Language Processing (NLP)&lt;/h5&gt;

&lt;p&gt;By definition (from &lt;a href=&#34;https://en.wikipedia.org/wiki/Full-text_search&#34;&gt;Wikipedia&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-html&#34;&gt;In a full-text search, a search engine examines all of the words in every stored document as it tries to match search criteria (for example, text specified by a user).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This may sound trivial, but it&amp;rsquo;s not.
Searching for exact form of the word is not always satisfying for the user.
For example, nouns can be singular or plural, verbs have grammatical tenses, etc., and the user may be interested in all values related to the word in any inflected or derived form.&lt;/p&gt;

&lt;p&gt;The simple but powerful idea is to find a method, that can transform all the forms of a word to some common base.
This process is called &lt;strong&gt;stemming&lt;/strong&gt;.
For many natural languages (including English) stemmers may be implemented using a set of well known grammatical rules.
There are also languages (like Polish) where a dictionary based approach is required (i.e. inflected form -&amp;gt; stem mapping).&lt;/p&gt;

&lt;p&gt;Only for languages with well known grammatical rules are stemmers are widely available.&lt;/p&gt;

&lt;p&gt;Another problem with search are the words that are common, like &lt;code&gt;the&lt;/code&gt;, &lt;code&gt;is&lt;/code&gt;, or &lt;code&gt;at&lt;/code&gt;.
In most cases, searching for them gives an enormous amount of results which are useless.
Those words are called &lt;strong&gt;stop words&lt;/strong&gt;.
Again, stop words are language specific.
The common method of handling those words is just to remove them from the search.&lt;/p&gt;

&lt;h5 id=&#34;dgraph-fts-nlp-processing&#34;&gt;Dgraph FTS/NLP Processing&lt;/h5&gt;

&lt;p&gt;The following steps are applied to both data (while indexing), and the query pattern:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Tokenization - text is divided into words.&lt;/li&gt;
&lt;li&gt;Normalization - all letters are transformed to lowercase. &lt;a href=&#34;http://unicode.org/reports/tr15/&#34;&gt;Unicode Normalization&lt;/a&gt; is applied.&lt;/li&gt;
&lt;li&gt;Stop words are removed.&lt;/li&gt;
&lt;li&gt;Stemming is applied.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Since stop words contain inflected forms, they are removed before stemming.&lt;/p&gt;

&lt;h5 id=&#34;full-text-search-functions&#34;&gt;Full Text Search Functions&lt;/h5&gt;

&lt;p&gt;There are two new functions that provide basic support for full text search:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;alloftext&lt;/code&gt; - searches for values that contain all the specified words (using NLP).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;anyoftext&lt;/code&gt; - searches for values that contain one or more of the specified tokens (using NLP).&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&#34;examples&#34;&gt;Examples&lt;/h5&gt;

&lt;p&gt;Let&amp;rsquo;s query for &lt;code&gt;white or maybe black&lt;/code&gt;, using the term matching function &lt;code&gt;allofterms&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;

&lt;div class=&#34;runnable&#34; data-checksum=&#34;a2c60948e744862d6b1a13236ada9dd9&#34; data-initial=&#34;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

The query gives no results.
It may be worth trying less strict match with &lt;code&gt;alloftext&lt;/code&gt; function:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;5d5001b78c162fe12067167cabc9bab5&#34; data-initial=&#34;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@en, &amp;#34;white or maybe black&amp;#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@en, &#34;white or maybe black&#34;)) @filter(gt(count(genre), 1)) {
    name@en
    name@de
    name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;Query returns 59 results.
This example shows that removing a stop word may help in some cases.&lt;/p&gt;

&lt;p&gt;In context of NLP, English is quite easy - there are no diacritics, and inflection is rather simple.
So let&amp;rsquo;s try similar query in German:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;ae14be08ee0c46175f71b7918ee1dcd0&#34; data-initial=&#34;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;Again, the query doesn&amp;rsquo;t return any results.&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s try the NLP-enabled version of this query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;3ae8ed3ca59fc7f3927a4ca09377ab47&#34; data-initial=&#34;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@de, &amp;#34;weiss oder vielleicht schwarz&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@de, &#34;weiss oder vielleicht schwarz&#34;)) @filter(gt(count(genre), 1)) {
	name@de
	name@en
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;This returns 4 results.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s worth noting the inflected forms of &lt;code&gt;schwarz&lt;/code&gt; - &lt;code&gt;schwarzes&lt;/code&gt; and &lt;code&gt;Schwartze&lt;/code&gt;.
Also the &lt;code&gt;Wei\u00dfer&lt;/code&gt; is interesting - &lt;code&gt;\u00df&lt;/code&gt; is the escaped Unicode value of &lt;a href=&#34;https://en.wikipedia.org/wiki/%C3%9F&#34;&gt;grapheme &lt;code&gt;ß&lt;/code&gt;&lt;/a&gt;.
&lt;code&gt;weiss&lt;/code&gt; matched &lt;code&gt;Weißer&lt;/code&gt; - the form is inflected, and grapheme equivalency is preserved.
Like in the English example, the stop word (&lt;code&gt;oder&lt;/code&gt;) is ignored.&lt;/p&gt;

&lt;h5 id=&#34;gotchas&#34;&gt;Gotchas&lt;/h5&gt;

&lt;p&gt;In some cases, natural language processing can lead to surprising results.
Let&amp;rsquo;s search for the answer to the famous question: &lt;code&gt;To be, or not to be?&lt;/code&gt;:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;aadb70fa6d64fde240a20a76965babec&#34; data-initial=&#34;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-current=&#34;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:alloftext(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:alloftext(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;The query gives no results, while the term matching query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;dd1fdb51dcb706bd6314b6e67b0d9118&#34; data-initial=&#34;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-current=&#34;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:allofterms(name@en, &amp;#34;To be, or not to be?&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:allofterms(name@en, &#34;To be, or not to be?&#34;)) @filter(gt(count(genre), 1)) {
	name@en
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;gives two results:&lt;/p&gt;

&lt;p&gt;What happened? &lt;code&gt;To be, or not to be?&lt;/code&gt; consists of stop words only.
After FTS/NLP processing, there are no movies that match the query.&lt;/p&gt;

&lt;h3 id=&#34;regular-expressions-regexp&#34;&gt;Regular Expressions (regexp)&lt;/h3&gt;

&lt;p&gt;Regular expressions are extremely useful for creating sophisticated matchers.&lt;/p&gt;

&lt;p&gt;For example, all titles starting with a word containing &lt;code&gt;night&lt;/code&gt; but not &lt;code&gt;knight&lt;/code&gt; may be matched using following query:&lt;/p&gt;



&lt;div class=&#34;runnable&#34; data-checksum=&#34;8734f0b7c65b1d74a521a67d4a77522c&#34; data-initial=&#34;{
  movie(func:regexp(name, &amp;#34;^[a-zA-z]*[^Kk ]?[Nn]ight&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&#34; data-current=&#34;{
  movie(func:regexp(name, &amp;#34;^[a-zA-z]*[^Kk ]?[Nn]ight&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&#34; data-dirty=&#34;false&#34;&gt;
  &lt;div class=&#34;container-fluid&#34;&gt;
    &lt;div class=&#34;row&#34;&gt;
      &lt;div class=&#34;runnable-col runnable-col-code col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;topbar&#34;&gt;

            &lt;div class=&#34;normal-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-10&#34;&gt;
                  &lt;nav class=&#34;nav-languages&#34;&gt;
                    &lt;a class=&#34;language active&#34; data-action=&#34;nav-lang&#34; data-target=&#34;query&#34; href=&#34;#&#34;&gt;Query&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;curl&#34; href=&#34;#&#34;&gt;Curl&lt;/a&gt;
                    &lt;a class=&#34;language&#34; data-action=&#34;nav-lang&#34; data-target=&#34;java&#34; href=&#34;#&#34;&gt;Java&lt;/a&gt;
                  &lt;/nav&gt;
                &lt;/div&gt;
                &lt;div class=&#34;col-2&#34;&gt;
                  &lt;div class=&#34;actions pull-right&#34;&gt;
                    &lt;a class=&#34;code-btn&#34; data-action=&#34;run&#34; href=&#34;#&#34;&gt;Run&lt;/a&gt;
                  &lt;/div&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

            &lt;div class=&#34;editing-header&#34;&gt;
              &lt;div class=&#34;row&#34;&gt;
                &lt;div class=&#34;col-12&#34;&gt;
                  &lt;span class=&#34;pane-title&#34;&gt;
                    Editing query...
                  &lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;

          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-code&#34;&gt;
            &lt;div class=&#34;runnable-tab-content active&#34; data-tab=&#34;query&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34;&gt;&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:regexp(name, &#34;^[a-zA-z]*[^Kk ]?[Nn]ight&#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;edit&#34;&gt;
              &lt;textarea class=&#34;query-content-editable&#34;&gt;{
  movie(func:regexp(name, &amp;#34;^[a-zA-z]*[^Kk ]?[Nn]ight&amp;#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/textarea&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;curl&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;curl localhost:8080/query -XPOST -d &#39;
&lt;span class=&#34;query-content&#34;&gt;{
  movie(func:regexp(name, &#34;^[a-zA-z]*[^Kk ]?[Nn]ight&#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&#39; | python -m json.tool | less&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;

            &lt;div class=&#34;runnable-tab-content&#34; data-tab=&#34;java&#34;&gt;
              &lt;pre&gt;&lt;code class=&#34;no-copy&#34; tabindex=&#34;-1&#34;&gt;import io.dgraph.client.DgraphClient;
import io.dgraph.client.GrpcDgraphClient;
import io.dgraph.client.DgraphResult;

public class DgraphMain {
  public static void main(final String[] args) {
    final DgraphClient dgraphClient = GrpcDgraphClient.newInstance(&#34;localhost&#34;, 8080);
    final DgraphResult result = dgraphClient.query(&#34;&lt;span class=&#34;query-content java&#34;&gt;{
  movie(func:regexp(name, &#34;^[a-zA-z]*[^Kk ]?[Nn]ight&#34;)) @filter(gt(count(genre), 1)) {
	name@en
	name@de
	name@it
  }
}
&lt;/span&gt;&#34;);
    System.out.println(result.toJsonObject().toString());
  }
}&lt;/code&gt;&lt;/pre&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;div class=&#34;edit-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;reset&#34; href=&#34;#&#34;&gt;Reset&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;discard&#34; href=&#34;#&#34;&gt;Discard&lt;/a&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;save&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-save&#34;&gt;&lt;/i&gt; Save&lt;/a&gt;
                &lt;/div&gt;
                &lt;div class=&#34;normal-actions&#34;&gt;
                  &lt;a class=&#34;code-btn&#34; data-action=&#34;edit&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-edit&#34;&gt;&lt;/i&gt; Edit query&lt;/a&gt;
                  &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-code&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;
        &lt;/div&gt;
      &lt;/div&gt;

      &lt;div class=&#34;runnable-col runnable-col-output col-12 col-sm-12 col-md-12 col-lg-6 nopadding&#34;&gt;
        &lt;div class=&#34;runnable-pane&#34;&gt;
          &lt;div class=&#34;row topbar&#34;&gt;
            &lt;div class=&#34;col-12&#34;&gt;
              &lt;span class=&#34;pane-title&#34;&gt;
                Response
              &lt;/span&gt;
            &lt;/div&gt;
          &lt;/div&gt;

          &lt;div class=&#34;runnable-content runnable-output&#34; style=&#34;background: url(&#39;https://open.dgraph.io/images/dgraph-black.png&#39;); background-repeat: no-repeat; background-position: center; background-color: #fff;&#34;&gt;
            &lt;pre class=&#34;output-container empty&#34;&gt;&lt;code class=&#34;output&#34; tabindex=&#34;-1&#34;&gt;&lt;/code&gt;&lt;/pre&gt;
          &lt;/div&gt;

          &lt;div class=&#34;row footer&#34;&gt;
            &lt;div class=&#34;col-12 col-sm-8&#34;&gt;
              &lt;div class=&#34;latency-info hidden&#34;&gt;
                &lt;div class=&#34;stat server-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Server latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt; &lt;i class=&#34;fa fa-question-circle server-latency-tooltip-trigger&#34; data-toggle=&#34;tooltip&#34; data-placement=&#34;bottom&#34; data-html=&#34;true&#34; title=&#34;Latency information&#34; data-animation=&#34;false&#34;&gt;&lt;/i&gt;
                &lt;/div&gt;
                &lt;div class=&#34;stat network-latency&#34;&gt;
                  &lt;span class=&#34;label&#34;&gt;Network latency:&lt;/span&gt; &lt;span class=&#34;number&#34;&gt;&lt;/span&gt;
                &lt;/div&gt;
              &lt;/div&gt;
            &lt;/div&gt;
            &lt;div class=&#34;col-12 col-sm-4&#34;&gt;
              &lt;div class=&#34;actions pull-right&#34;&gt;
                &lt;a class=&#34;code-btn hidden-sm-down&#34; data-action=&#34;expand&#34; href=&#34;#&#34;&gt;&lt;i class=&#34;fa fa-expand&#34;&gt;&lt;/i&gt;&lt;/a&gt;
                &lt;span class=&#34;code-btn&#34; data-action=&#34;copy-output&#34; href=&#34;#&#34;&gt;Copy&lt;/span&gt;
              &lt;/div&gt;
            &lt;/div&gt;
          &lt;/div&gt;

        &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;


&lt;p&gt;There are 502 results in the test dataset.&lt;/p&gt;

&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;

&lt;p&gt;Dgraph supports extensive, and useful methods of string matching.&lt;/p&gt;

&lt;p&gt;Natural language processing, employed for full text search, may be the best choice for lookup based on users input.
If more strict matching is required, term matching should give good results.
And to get the most precise results of complicated text searches, regular expressions can be used.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/jpl/pia21572/the-splitting-of-the-dunes&#34;&gt;The Splitting of the Dunes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Building a long lasting company around open-source</title>
      <link>https://open.dgraph.io/post/licensing/</link>
      <pubDate>Sun, 26 Mar 2017 07:30:00 +1100</pubDate>
      
      <guid>https://open.dgraph.io/post/licensing/</guid>
      <description>

&lt;p&gt;Dgraph started with the idea that every startup should be able to have the same level of technology as run by big giants. We designed Dgraph from ground-up to allow data sharding, horizontal scalability, consistent replication, and a fast and distributed architecture.&lt;/p&gt;

&lt;p&gt;We also dream that graph database would no longer run as a secondary database. By building a truly robust piece of technology, we can have our users run only one database, which allows arbitrarily complex queries while providing rock solid performance.&lt;/p&gt;

&lt;p&gt;We have always thought of Dgraph as a company, where we can work for the next ten years. So, instead of hacking our way to market, we invest in good design, aggressive refactoring and a culture of logic and reasoning based decisions. &lt;strong&gt;But, running a company takes more than clean code and good culture. It requires a functioning business model, which can make a profit.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Profit allows providing highly competitive salaries. Competitive salaries make the company attractive to great engineers. Great engineers build and enhance great products.&lt;/p&gt;

&lt;p&gt;To that extent, we&amp;rsquo;ve started working towards a closed-source enterprise version of Dgraph. This version would contain many features useful to companies, namely:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Cluster management and monitoring&lt;/li&gt;
&lt;li&gt;User authentication&lt;/li&gt;
&lt;li&gt;Access control lists&lt;/li&gt;
&lt;li&gt;Data encryption, and more&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Selling enterprise version and support would lead us to the path of revenue.&lt;/p&gt;

&lt;p&gt;But, what about competition? How do we deal with the threat many big companies provide on a daily basis? The threat of duplicate commercial services and enterprise features built by them and others without paying anything back towards the development of the open source version. There is also the looming cautionary tale of &lt;a href=&#34;https://rethinkdb.com/blog/rethinkdb-shutdown/&#34;&gt;RethinkDB ceasing&lt;/a&gt; to develop their database, due to lack of revenue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;We need to balance the benefits of open source to the community, against making the company building Dgraph profitable, while also keeping future competition at bay.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;the-change&#34;&gt;The change&lt;/h3&gt;

&lt;p&gt;One of the ideas was to move the distributed aspect of Dgraph to the enterprise version; like &lt;a href=&#34;https://www.influxdata.com/update-on-influxdb-clustering-high-availability-and-monetization/&#34;&gt;many&lt;/a&gt; &lt;a href=&#34;https://neo4j.com/licensing/&#34;&gt;others&lt;/a&gt; &lt;a href=&#34;https://www.mysql.com/products/enterprise/scalability.html&#34;&gt;are&lt;/a&gt; &lt;a href=&#34;https://www.datastax.com/products/datastax-enterprise-graph&#34;&gt;doing&lt;/a&gt;. The argument goes that by making distributed aspect closed-source, the open source offering would have restricted usage for companies growing fast; and they&amp;rsquo;ll be forced to pay.&lt;/p&gt;

&lt;p&gt;&lt;ul&gt;&lt;em&gt;But, it doesn&amp;rsquo;t feel right!&lt;/em&gt;&lt;/ul&gt; Many users love Dgraph because of it provides scalability without question. This goes against our inception idea that every startup should have the same level of technology run by big giants.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The &amp;ldquo;D&amp;rdquo; in Dgraph stands for distributed; we want to make sure that everyone gets it: big company, small company, pre-revenue, post-revenue, or one guy in a garage.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We don&amp;rsquo;t want companies to &lt;em&gt;have to&lt;/em&gt; pay us just to deal with more query traffic. That should be free. Instead, we want to build features which are so useful to enterprises that &lt;strong&gt;they feel they can save a lot of expensive developer time by using our services.&lt;/strong&gt;
So, after talking to other open source vendors and top open source lawyers, we came to this solution:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relicense the open-source version to GNU AGPLv3 (from Apache 2.0), while keeping the client libraries under Apache 2.0.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Known as the &lt;em&gt;GPL of the web&lt;/em&gt;, GNU Affero General Public License mandates that any modifications made to the source code must be released under the same license. This applies not just to downloadable binaries, but also to code run in the cloud. You can read &lt;a href=&#34;https://tldrlegal.com/license/gnu-affero-general-public-license-v3-(agpl-3.0)&#34;&gt;more about it here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;what-does-this-mean-for-you&#34;&gt;What does this mean for you?&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Largely no change.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Most users of Dgraph would never need to modify the server code themselves anyway. We are going to keep the client libraries under Apache 2.0; which would allow users to continue using Dgraph (via client libraries) without any restrictions or mandates on their own codebase. In general terms, any work built on top of Dgraph wouldn&amp;rsquo;t be considered derivative work, as long as Dgraph server code wasn&amp;rsquo;t modified.&lt;/p&gt;

&lt;p&gt;So, if you&amp;rsquo;re a user of Dgraph, nothing changes. If you modify Dgraph server code, you will have to release that modification back to the community under GNU AGPLv3. Thus, the entire Dgraph community would benefit from the contributions made to the server code by other individuals or companies.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;This simple change ensures that only Dgraph Labs owns the rights to add proprietary features within Dgraph server code, which in turn allows us to charge for our services and make revenue.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Users of MongoDB would &lt;a href=&#34;https://www.mongodb.com/community/licensing&#34;&gt;instantly recognize&lt;/a&gt; this licensing system. In fact, we were heavily influenced by them. MongoDB is one of the most successful databases and provided a great validation for this new direction we&amp;rsquo;re taking.&lt;/p&gt;

&lt;h3 id=&#34;living-breathing-open-source&#34;&gt;Living, breathing Open-source&lt;/h3&gt;

&lt;p&gt;While there is a talk of money, Dgraph still lives and breathes like an open-source company. In fact, by relicensing our code base under GNU AGPLv3, we can continue providing the distributed aspect of Dgraph under open source license; which gives us great pleasure.&lt;/p&gt;

&lt;p&gt;Graph market is heating up. Every other day, we hear about products ranging from a graph plugin to a graph layer to a graph engine to a graph database. Given the desire to not only serve data but also understand it, there&amp;rsquo;s a need for graphs in companies; and people realize that.&lt;/p&gt;

&lt;p&gt;With Dgraph, we think we&amp;rsquo;re in the right spot at the right time, ready to provide a graph database that scales with your business. And we&amp;rsquo;ll continue to do it in a way that benefits the entire community.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you have any questions or concerns about this switch, please feel free to reach out to me at &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;manish@dgraph.io&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.spacex.com/media-gallery/detail/144751/7441&#34;&gt;People landing on Mars via SpaceX&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Neo4j vs Dgraph - The numbers speak for themselves</title>
      <link>https://open.dgraph.io/post/benchmark-neo4j/</link>
      <pubDate>Mon, 23 Jan 2017 18:07:44 +1100</pubDate>
      
      <guid>https://open.dgraph.io/post/benchmark-neo4j/</guid>
      <description>&lt;p&gt;As &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is nearing its v0.8 release, we wanted to spend some time comparing it against Neo4j, which is the &lt;a href=&#34;http://db-engines.com/en/ranking/graph+dbms&#34;&gt;most popular graph database&lt;/a&gt;. We have divided this post into five parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Loading data&lt;/li&gt;
&lt;li&gt;Querying&lt;/li&gt;
&lt;li&gt;Issues faced&lt;/li&gt;
&lt;li&gt;Features&lt;/li&gt;
&lt;li&gt;Principles behind Dgraph&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h3 id=&#34;set-up&#34;&gt;Set up&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Thinkpad T460 laptop running Ubuntu Linux, Intel Core i7, with 16 GB RAM and SSD storage.&lt;/li&gt;
&lt;li&gt;Neo4j v3.1.0&lt;/li&gt;
&lt;li&gt;Dgraph from master branch (commit: 100c104a)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;1-loading-data&#34;&gt;1. Loading Data&lt;/h3&gt;

&lt;p&gt;We wanted to load a dense graph data set involving real world data. We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 have been using the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/21million.rdf.gz&#34;&gt;Freebase film data&lt;/a&gt; for our development and testing. We feel this data is highly interconnected and makes a good use case for storing in a graph database.&lt;/p&gt;

&lt;p&gt;The first problem we faced was that Neo4j doesn&amp;rsquo;t accept data in RDF format directly &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#1&#34;&gt;3.1&lt;/a&gt;
&lt;/sup&gt;
. The &lt;a href=&#34;https://neo4j.com/developer/guide-import-csv/#_super_fast_batch_importer_for_huge_datasets&#34;&gt;loader&lt;/a&gt; for Neo4j accepts data in CSV format which is essentially what SQL tables have. In our 21 million dataset, we have 50 distinct types of entities and 132 types of relationships between these entities. If we were to try and convert it to CSV format, we would end up with 100s of CSV files. One file for each type of entity, and one file per relationship between two types of entities. While this is okay for relational data, this doesn&amp;rsquo;t work for graph data sets, where each entity can be of multiple types, and relationships between entities are fluid.&lt;/p&gt;

&lt;p&gt;So, we looked into the next best option to load graph data into Neo4j. We wrote a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;small program&lt;/a&gt; similar to the Dgraphloader which reads N-Quads, batches them and tries to load them concurrently into Neo4j. This program used &lt;a href=&#34;https://neo4j.com/blog/neo4j-3-0-milestone-1-release/&#34;&gt;Bolt&lt;/a&gt;, a new protocol by Neo4j. It is the fastest way we could find to load RDF data into Neo4j. In the video below, you can see a comparison of loading 1.1 million N-Quads on &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 vs. Neo4j.&lt;/p&gt;

&lt;p&gt;Note that we only used 20 concurrent connections and batched 200 N-Quads for each request because Neo4j doesn&amp;rsquo;t work well if we increase either the number of connections or N-Quads per connection beyond this. In fact, that&amp;rsquo;s a sure way to make Neo4j data corrupt and hang the system &lt;sup&gt;
    &lt;a class=&#34;internal&#34; href=&#34;#2&#34;&gt;3.2&lt;/a&gt;
&lt;/sup&gt;
. For Dgraph, we typically send 1000 N-Quads per request and have 500 concurrent connections.&lt;/p&gt;

&lt;p&gt;&lt;br/&gt;
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/S_DsEMnawwU?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;br/&gt;&lt;/p&gt;

&lt;p&gt;With the golden data set of 1.1 million N-Quads, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 outperformed Neo4j 46.7k to 280 N-Quads per second. In fact, the Neo4j loader process &lt;em&gt;never finished&lt;/em&gt; (we killed it after a considerable wait).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is 160x faster than Neo4j for loading graph data.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;2-querying&#34;&gt;2. Querying&lt;/h3&gt;

&lt;p&gt;We would have ideally liked to load up the entire 21 million RDF dataset so that we could compare the performance of both databases at scale. But given the difficulties we faced loading large amounts of data into Neo4j, we resorted to a subset dataset of 1.3 million N-Quads containing only certain types of entities and relationships. After a &lt;em&gt;painful&lt;/em&gt; process, we converted our data into &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data/neo4j&#34;&gt;five CSV files&lt;/a&gt;, one for each type of entity (film, director, and genre) and two for the relationships between them; so that we could do some queries. We loaded these files into Neo4j using their import tool.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./neo4j start
./neo4j-admin import --database film.db --id-type string --nodes:Film $DATA/films.csv --nodes:Genre $DATA/genres.csv --nodes:Director $DATA/directors.csv --relationships:GENRE $DATA/filmgenre.csv --relationships:FILMS $DATA/directorfilm.csv
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we created some indexes in Neo4j for the best query performance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;CREATE INDEX ON :Director(directorId)
CREATE INDEX ON :Director(name)
CREATE INDEX ON :Film(release_date)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We tested Neo4j twice. Once with query caching turned off, and then with query caching turned on. &lt;strong&gt;Generally, it does not make sense to benchmark queries with caching turned on, but we decided to set it because that&amp;rsquo;s the default behavior Neo4j users see.&lt;/strong&gt; You can set it by modifying the following variable in &lt;code&gt;conf/neo4j.conf&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;dbms.query_cache_size=0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Dgraph does not do any query caching. We loaded an equivalent &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/neo.rdf.gz&#34;&gt;data set&lt;/a&gt; into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 using the following schema and the commands below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
    type.object.name.en: string @index
    film.film.initial_release_date: date @index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The schema file specifies creation of an index on the two predicates.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Start Dgraph with a schema which specifies the predicates to index.
dgraph --schema ~/work/src/github.com/dgraph-io/benchmarks/data/goldendata.schema
# Load the data
dgraphloader -r ~/work/src/github.com/dgraph-io/benchmarks/data/neo4j/neo.rdf.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With data loaded up into both the databases, we &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmarked&lt;/a&gt; both simple and complex queries. The results didn&amp;rsquo;t surprise us.&lt;/p&gt;

&lt;h4 id=&#34;benchmarking-process&#34;&gt;Benchmarking process&lt;/h4&gt;

&lt;p&gt;The benchmarks for Neo4j and &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 were run separately so that both processes could utilize full CPU and RAM resources. Each sub-benchmark was run for 10s so that sufficient iterations could be run. We also monitored the memory usage for both the processes using a simple shell script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go test -v -bench=Dgraph -benchtime=10s .
go test -v -bench=Neo -benchtime=10s .
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;queries&#34;&gt;Queries&lt;/h4&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Id&lt;/th&gt;
&lt;th&gt;Description&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQ&lt;/td&gt;
&lt;td&gt;Get all films and genres of &lt;strong&gt;films directed by Steven Spielberg.&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;SQM&lt;/td&gt;
&lt;td&gt;Runs the query above and changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and get &lt;strong&gt;their films sorted by release date&lt;/strong&gt;.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS1QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their films &lt;strong&gt;released after 1984-08&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS2QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3Q&lt;/td&gt;
&lt;td&gt;Search for directors with name Steven Spielberg and only their movies &lt;strong&gt;released between 1984-08 and 2000&lt;/strong&gt; sorted by release date.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;GS3QM&lt;/td&gt;
&lt;td&gt;Runs the query above and also changes the name of one of the films.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If the test id has a &lt;code&gt;P&lt;/code&gt; suffix, it was run in parallel.&lt;/p&gt;

&lt;h4 id=&#34;read-only-benchmarks&#34;&gt;Read-only benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Queries to Dgraph took the same amount of time, as expected in the both cases. But, Neo4j query latency was at least &lt;em&gt;halved&lt;/em&gt;. That&amp;rsquo;s not surprising given all the subsequent runs were using query cache. &lt;strong&gt;Thence, Neo4j latency was better than Dgraph with query caching turned on, and worse when off.&lt;/strong&gt;&lt;/p&gt;

&lt;h4 id=&#34;read-write-benchmarks&#34;&gt;Read-write benchmarks&lt;/h4&gt;

&lt;p&gt;&lt;em&gt;Query caching turned off for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-write-no-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Query caching on for Neo4j&lt;/em&gt;
&lt;img src=&#34;https://open.dgraph.io/images/read-write-cache.png&#34; alt=&#34;Dgraph vs Neo4j Read-write&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For intertwined reads and writes, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is at least 3x to 6x faster.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We can see that Neo4j is &lt;strong&gt;even slower with query caching on&lt;/strong&gt; because they have to do the extra work of cache invalidation on writes. Dgraph was designed to achieve low latency querying with real world use cases, where reads are typically followed by writes and vice-versa, and the &lt;strong&gt;performance benefits show in the numbers.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Not just that, Neo4j takes up &lt;strong&gt;much more memory&lt;/strong&gt;. At the start of the benchmarks &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumed around 20 MB which increased to 600 MB at the end. In comparison, Neo4j was already consuming 550 MB at the start which increased to 3.2 GB at the end of the benchmarks.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 consumes 5x lesser memory compared to Neo4j and is at least 3x faster for intertwined reads and writes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;3-issues-faced&#34;&gt;3. Issues faced&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;div id=&#34;1&#34;&gt;&lt;/div&gt;We couldn&amp;rsquo;t find a convenient way to load large amount of interconnected graph data into Neo4j apart from breaking it into CSV files. We had to write a loader which could concurrently load RDF data into Neo4j.&lt;/li&gt;
&lt;li&gt;&lt;div id=&#34;2&#34;&gt;&lt;/div&gt;We hit data corruption issues on sending more than 20 requests concurrently, which the database could not recover from. In comparison, we typically send 500 concurrent requests to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, each request batching 1000 N-Quads.&lt;/li&gt;
&lt;li&gt;While loading data concurrently and opening 100 connections, Neo4j started returning bad connection error because it hit the limit of maximum open file descriptors which was set to 1024 (the default). We have never witnessed such a problem with Dgraph.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;4-features&#34;&gt;4. Features&lt;/h3&gt;

&lt;p&gt;We talked about performance and issues. Now, let&amp;rsquo;s see how does Dgraph compare against Neo4j regarding features.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Feature&lt;/th&gt;
&lt;th&gt;Dgraph&lt;/th&gt;
&lt;th&gt;Neo4j&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Production Features&lt;/td&gt;
&lt;td&gt;Highly available, Consistent, Fault tolerant&lt;/td&gt;
&lt;td&gt;Master-slave architecture (only full data replicas)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Data Sharding&lt;/td&gt;
&lt;td&gt;Yes. Data sharded and replicated across servers, using consensus for writes.&lt;/td&gt;
&lt;td&gt;No data sharding.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Horizontal Scalability&lt;/td&gt;
&lt;td&gt;Yes. Add servers to cluster on the fly to distribute data better.&lt;/td&gt;
&lt;td&gt;Supports only full data replicas&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Transactional Model&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://www.bailis.org/blog/linearizability-versus-serializability/&#34;&gt;Linearizability&lt;/a&gt; aka Atomic Consistency&lt;/td&gt;
&lt;td&gt;ACID transactions&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Backups&lt;/td&gt;
&lt;td&gt;Hot backups in RDF format available using the HTTP interface&lt;/td&gt;
&lt;td&gt;Hot full and incremental backups available only as part of paid enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;HTTP API for queries and mutations&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Communication using clients over binary protocol&lt;/td&gt;
&lt;td&gt;Yes, using grpc&lt;/td&gt;
&lt;td&gt;Yes, using bolt protocol&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Bulk loading of graph data&lt;/td&gt;
&lt;td&gt;Yes, can load arbitrarily connected RDF data using dgraphloader&lt;/td&gt;
&lt;td&gt;Only supports loading relational data in CSV format using the loader&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Schema&lt;/td&gt;
&lt;td&gt;Optional (supports int, float, string, bool, date, datetime and geo types)&lt;/td&gt;
&lt;td&gt;Optional (supports byte, short, int, long, float, double, char and string types)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Geospatial Queries&lt;/td&gt;
&lt;td&gt;Yes. Supports near, within, contains, intersects&lt;/td&gt;
&lt;td&gt;No. Not part of core database&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Query language&lt;/td&gt;
&lt;td&gt;GraphQL like which responds in JSON&lt;/td&gt;
&lt;td&gt;Cypher&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Order by, limit, skip and filter queries&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Authorization and authentication&lt;/td&gt;
&lt;td&gt;SSL/TLS and auth token based security (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports basic user authentication and authorization&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Aggregation queries&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Supports count(), sum(), avg(), distinct and other aggregation queries&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Access Control Lists&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Available based on roles as part of enterprise edition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Support for plugins and user defined functions&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Browser interface for visualization&lt;/td&gt;
&lt;td&gt;Work in progress (support by v1.0)&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Dgraph (2016) is a lot younger project than Neo4j (2007), so reaching feature parity quickly was a tough job.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Dgraph supports most of the functionality that one &lt;em&gt;needs&lt;/em&gt; to get the job done; though it doesn&amp;rsquo;t have all the functionality one might &lt;em&gt;want&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;5-principles-behind-dgraph&#34;&gt;5. Principles behind Dgraph&lt;/h3&gt;

&lt;p&gt;While &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 runs very well on our (Linux) Thinkpads, it is designed to be a graph database for production. As such, it allows the ability to shard and distribute data over many servers. Consistency and fault tolerance are baked deep into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to the point where even our tests need to start a &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query_test.go#L2715&#34;&gt;single-node Raft cluster&lt;/a&gt;. All the writes, irrespective of which replica they end up on, can be read back instantaneously, i.e. linearizable (work in progress, ETA v0.8). A few server crashes would not lose data or affect the end-user queries, making the system highly-available.&lt;/p&gt;

&lt;p&gt;Such features have traditionally been a talk for NoSQL databases or Spanner, not for graph databases. But, we think any production system, on which the entire application stack is based, &lt;strong&gt;must stay up, perform and scale well.&lt;/strong&gt; The system must be able to utilize the server running it well, process a lot of queries per second, and provide a consistent latency.&lt;/p&gt;

&lt;p&gt;Also, given we&amp;rsquo;re building a graph database, the system should be able to handle &lt;strong&gt;arbitrarily dense interconnected data and complex queries.&lt;/strong&gt; It should not be confined by pre-optimization of certain edges, or other tricks to make certain queries run fast.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The speed achieved should be due to a better design and across the entire spectrum.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, running and maintaining such a system should be easy to the engineers. And that&amp;rsquo;s only possible if the system is &lt;strong&gt;as simple as it can be,&lt;/strong&gt; and every piece of complexity introduced to the system is carefully weighted.&lt;/p&gt;

&lt;p&gt;These are the principles which guide us towards building Dgraph. And we&amp;rsquo;re glad that in a short period, we&amp;rsquo;ve been able to achieve many of these. Now we leave it to you, our users to &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;try out Dgraph&lt;/a&gt;, and let us know what you think.&lt;/p&gt;

&lt;hr /&gt;

&lt;h5 id=&#34;criticism-to-these-benchmarks-updated-feb-1-2017&#34;&gt;Criticism to these benchmarks (Updated Feb 1, 2017)&lt;/h5&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;This reads like marketing material:&lt;/strong&gt; &lt;em&gt;You&amp;rsquo;re on Dgraph blog!&lt;/em&gt; Having said that, the benchmarking code is &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;open source&lt;/a&gt; and available to any one willing to put some time to verify these benchmarks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Query caching was turned off:&lt;/strong&gt; The benchmarks above showcase results for Neo4j with &lt;em&gt;both caching turned on and off.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j only uses query plan cache, not result cache:&lt;/strong&gt; That&amp;rsquo;s not what we observed. In fact, for the same read-write query, Neo4j latency increased when caching was turned on, compared to when off (as you can see in the read-write benchmarks above). A pure query plan cache shouldn&amp;rsquo;t be affected by data changes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;JVM takes time to warm up:&lt;/strong&gt; Each benchmark was run for 10 seconds by Go, which ran thousands of iterations for the same query to get accurate latency per iteration. We think the JVM should be able to warm up by then.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Neo4j queries could be optimized:&lt;/strong&gt; Just mentioning it doesn&amp;rsquo;t help. Please send us a &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;pull request&lt;/a&gt; to optimize Neo4j data loading and queries. Or, &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;send us&lt;/a&gt; a mail.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Benchmarking on a laptop isn&amp;rsquo;t right:&lt;/strong&gt; We are just looking for relative performance, not absolute performance. It shouldn&amp;rsquo;t matter which machine you run them on.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;Manish will be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Gophercon India on 24-25th Feb. If you&amp;rsquo;re attending the conference, find him to talk about all things Dgraph.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We are happy to &lt;a href=&#34;mailto:contact@dgraph.io&#34;&gt;accept feedback&lt;/a&gt; about any improvements to the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/main.go&#34;&gt;loader&lt;/a&gt; or the &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/blob/master/data/neo4j/query_test.go&#34;&gt;benchmark tests&lt;/a&gt; to get better results for Neo4j.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;If you haven&amp;rsquo;t already tried &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/goddard/2016/hubble-gazes-at-a-cosmic-megamaser&#34;&gt;Hubble Gazes at a Cosmic Megamaser&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Releasing Dgraph v0.7.1</title>
      <link>https://open.dgraph.io/post/v0.7-release/</link>
      <pubDate>Thu, 05 Jan 2017 20:00:00 +1100</pubDate>
      
      <guid>https://open.dgraph.io/post/v0.7-release/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 team is super excited to present v0.7.1 of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
. This version is the biggest step we&amp;rsquo;ve taken towards our production aim of v1.0.
We&amp;rsquo;ve implemented &lt;strong&gt;90% of all the features we had planned&lt;/strong&gt; in our &lt;a href=&#34;https://github.com/dgraph-io/dgraph/issues/1&#34;&gt;product roadmap&lt;/a&gt;, including replication and high-availability using RAFT protocol, indexing, filtering, sorting, geospatial queries, and backups.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;Today, I&amp;rsquo;m going to talk about these new features, and what you can expect from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note: This is going to be a long blog post. If you just want to try out &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, you can jump straight to our &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&#34;speed&#34;&gt;Speed&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 v0.7.1 is the &lt;em&gt;fastest&lt;/em&gt; version of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 we&amp;rsquo;ve ever released. Live data loading is now so fast that we realized we no longer needed a separate offline batch data loader. So, we removed all that complexity and just wrote a simple script to send mutation queries to live &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 via GRPC.&lt;/p&gt;

&lt;p&gt;You can read more about loading and querying performance &lt;a href=&#34;https://wiki.dgraph.io/Performance&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;data-persistence-sharding-high-availability-and-crash-resilience&#34;&gt;Data Persistence, Sharding, High Availability, and Crash Resilience&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 has been built from ground up to be run in Google scale production environments. To run terabytes of structured data over commodity hardware has been the main aim since the beginning. To achieve that, Dgraph needs to be able to deal with server failures; without losing any data or dropping any queries.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ve implemented RAFT, a distributed consensus algorithm within &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, to handle such failures. Any writes that happen to go through a group of servers and are only acknowledged to the client once they&amp;rsquo;ve been applied to a majority of servers in the group. Thus, even if some of these servers crash, the data can be accessed, updated and queries can flow without the user getting affected.&lt;/p&gt;

&lt;p&gt;Also, new servers can be introduced into an existing cluster by providing the IP address of any healthy server in the cluster. They will automatically pick up the other members, pull in data shards from healthy nodes, join the groups and become part of the cluster.&lt;/p&gt;

&lt;p&gt;Such functionality has never been an aim for graph databases in the past. But we strongly believe that graph databases can be run as the primary databases; not just add-ons. To that effect, it&amp;rsquo;s important that they be able to survive machine crashes and avoid data loss.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This functionality makes &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 the most production ready graph database in the market.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You can read more about running multiple instances of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, sharding and distributing data in a cluster &lt;a href=&#34;https://wiki.dgraph.io/Deploy&#34;&gt;here&lt;/a&gt;. In fact, we created a small video to show you how &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can recover from crashes without losing any data directly after a load.
&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
    &lt;iframe src=&#34;//www.youtube.com/embed/dzTEXxF0TGs?rel=0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen=&#34;&#34; frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/p&gt;

&lt;h3 id=&#34;backups&#34;&gt;Backups&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 believes in standards. We heartily use the existing RDF NQuad standard for data input. Now, we&amp;rsquo;re making it easy to export data from &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 to other systems, by exporting our backups in RDF NQuad format. This makes it easy to feed &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 data into other systems, upgrade &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 versions or to switch over to another graph database. You can read more about backup &lt;a href=&#34;https://wik.dgraph.io/Deploy#Backup&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;indexing&#34;&gt;Indexing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 can now index various scalar values to allow sorting,  term matching, and inequality filters. We support these value types: &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;date&lt;/code&gt;, &lt;code&gt;datetime&lt;/code&gt;, &lt;code&gt;geo&lt;/code&gt;, &lt;code&gt;uid&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;String values get tokenized using ICU, and allow &lt;code&gt;allof&lt;/code&gt; and &lt;code&gt;anyof&lt;/code&gt; functions.
&lt;code&gt;geo&lt;/code&gt; values allow for geo-indexing and support the geo functions mentioned below. &lt;code&gt;uid&lt;/code&gt; value is a way to indicate that the predicate edge points to another entity node.
This is useful to generate edges in reverse direction automatically. The rest support sorting, equality and inequality functions.&lt;/p&gt;

&lt;p&gt;If you want to generate the index for a particular predicate, mention its type and specify the &lt;code&gt;@index&lt;/code&gt; keyword.
Similarly, to generate reverses for a uid predicate, you can specify the &lt;code&gt;@reverse&lt;/code&gt; keyword.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example schema file for freebase film data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar (
  film.director.film             : uid    @ reverse
  film.film.genre                : uid    @ reverse
  film.film.initial_release_date : date   @ index
  film.film.rating               : uid    @ reverse
  loc                            : geo    @ index
  type.object.name.en            : string @ index
  type.object.name.hi            : string @ index
  type.object.name.ta            : string @ index
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 schema &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;reverse-edges&#34;&gt;Reverse Edges&lt;/h4&gt;

&lt;p&gt;Each graph edge is unidirectional. But a lot of times, you need to have both the forward and backward edges. For those cases, &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now provides a &lt;code&gt;@reverse&lt;/code&gt; keyword, which can be applied to predicates of &lt;code&gt;uid&lt;/code&gt; type. This would trigger automatic generation of the reverse edges, to allow querying in the reverse direction.&lt;/p&gt;

&lt;p&gt;You can read more about reverse edges &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Reverse_Edges&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;sorting&#34;&gt;Sorting&lt;/h3&gt;

&lt;p&gt;You can now sort the results by any indexed predicate (except string and geo, of course). For example, you can now get a list of films directed by Steven Spielberg sorted by initial release date.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film(order: film.film.initial_release_date) {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}

# To sort in descending order, just use orderdesc instead of order.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about sorting &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Sorting&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;functions&#34;&gt;Functions&lt;/h3&gt;

&lt;p&gt;Functions are a great way to provide functionality with a simple and clear interface. &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 functions can be used as both starting points to queries and as filters.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s a list of functions we introduced in v0.7.1:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;anyof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has any of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allof(predicate, &amp;quot;space separated list of terms&amp;quot;)&lt;/code&gt; : Entities whose value for the predicate has all of the terms specified.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;leq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is less than or equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;geq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;                           : Entities whose value for the predicate is greater than or equal to specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both &lt;code&gt;anyof&lt;/code&gt; and &lt;code&gt;allof&lt;/code&gt; functions work based on an index generated by tokenizing string values. We use ICU, which has vast support for human languages and is used by major projects like Google Web Search, Chrome, Mac OSX, Lucene, etc.&lt;/p&gt;

&lt;p&gt;Upcoming in v0.7.2:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;eq(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is equal to specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;le(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is less than specified value.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ge(predicate, &amp;quot;value&amp;quot;)&lt;/code&gt;: Entities whose value for predicate is greater than specified value.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To enable these functions, a &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Schema&#34;&gt;schema providing the scalar type&lt;/a&gt; for the predicates should be provided. For e.g.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;scalar(
  name          : string @ index # anyof, allof
  age           : int    @ index # leq, geq
  date_of_birth : date   @ index # leq, geq
)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about functions &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Functions&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;geospatial-functions&#34;&gt;Geospatial functions&lt;/h4&gt;

&lt;p&gt;Geospatial queries are important to build location-aware search and recommendations. Being able to find the nearby restaurants who serve sushi, or bars in the city which play Jazz, or friends who are visiting your neighborhood is pretty crucial to such use cases. We couldn&amp;rsquo;t imagine building a database without providing full-fledged support for geo queries, and in v0.7.1, we added geo indexing.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports four geospatial functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;near(predicate, geo-location)&lt;/code&gt;      : Finds all entities lying within a specified distance from a point.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;within(predicate, geo-polygon)&lt;/code&gt;     : Finds all entities lying within a specified region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;contains(predicate, geo-location)&lt;/code&gt;  : Finds all enclosures for a specified point or region.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;intersects(predicate, geo-polygon)&lt;/code&gt; : Finds all entities which intersect a specified region.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;$ curl localhost:8080/query -XPOST -d $&#39;
{
  tourist( near(&amp;quot;loc&amp;quot;, &amp;quot;{\&#39;type\&#39;:\&#39;Point\&#39;, \&#39;coordinates\&#39;: [-122.469829, 37.771935]}&amp;quot;, &amp;quot;1000&amp;quot; ) ) {
    name
  }
}&#39; | python -m json.tool | grep name

            &amp;quot;name&amp;quot;: &amp;quot;Steinhart Aquarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Spreckels Temple of Music&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Pioneer Log Cabin&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Conservatory of Flowers&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;De Young Museum&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Chinese Pavillion&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Japanese Tea Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Peace Lantern&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;San Francisco Botanical Garden&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Morrison Planetarium&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;California Academy of Sciences&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Hamon Tower&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;National AIDS Memorial Grove&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;La Rose des Vents&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Strawberry Hill&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Buddha&amp;quot;
            &amp;quot;name&amp;quot;: &amp;quot;Rose Garden&amp;quot;

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about Geolocation functionality &lt;a href=&#34;https://wiki.dgraph.io/Query_Language#Geolocation&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;filtering&#34;&gt;Filtering&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 now supports pretty advanced and complex filtering operations. We do both &amp;amp;&amp;amp; (and) and || (or) filters, using round brackets to specify the right sequence. For e.g., &lt;code&gt;(A || (B &amp;amp;&amp;amp; C))&lt;/code&gt;, as demonstrated in the following query.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  me(_xid_: m.06pj8) {
    type.object.name.en
    film.director.film @filter(
      allof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jones indiana&amp;quot;) ||
      (anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;jurassic&amp;quot;) &amp;amp;&amp;amp; anyof(&amp;quot;type.object.name.en&amp;quot;, &amp;quot;park&amp;quot;)))  {
      type.object.name.en
      film.film.initial_release_date
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With that, I&amp;rsquo;ll finish the blog post. &lt;strong&gt;If you found these interesting, try out the &lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34;&gt;5 step tutorial to get started with Dgraph&lt;/a&gt;.&lt;/strong&gt; Let us know what you think!&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;I&amp;rsquo;ll be giving a talk about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 at Go Meetup in Sydney on 19th Jan and in Gophercon India on 24-25th Feb. So, come talk to me about &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;</description>
    </item>
    
    <item>
      <title>Dgraph hugo blog theme</title>
      <link>https://open.dgraph.io/post/hugo/</link>
      <pubDate>Thu, 06 Oct 2016 16:56:08 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/hugo/</guid>
      <description>&lt;p&gt;We at &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 love &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; and use it for our blog. It&amp;rsquo;s blazingly fast, supports Markdown is written in Go and is very easy to work with. Initially, we were confused between Hugo vs. having a publication on Medium but later decided to go with Hugo because of the factors mentioned above. One of the things that we found lacking in the Hugo ecosystem was a good theme that we could use for our blog.&lt;/p&gt;

&lt;p&gt;So we got a theme designed which fit well with our website and used the screen estate well. It&amp;rsquo;s now available at &lt;a href=&#34;http://themes.gohugo.io/hugo-dgraph-theme/&#34;&gt;Dgraph theme&lt;/a&gt;. The theme is responsive, supports syntax highlighting for code and &lt;a href=&#34;https://www.discourse.org/&#34;&gt;discourse&lt;/a&gt; for comments. If your project is open source, you can also link to Github. We would encourage you to try out the theme and let us know your experiences with it.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.nasa.gov/image-feature/jpl/pia20027/infrared-echoes-of-a-black-hole-eating-a-star/&#34;&gt;Infrared Echoes of a Black Hole Eating a Star&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Golang: Run multiple services on one port</title>
      <link>https://open.dgraph.io/post/cmux/</link>
      <pubDate>Tue, 04 Oct 2016 11:59:57 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/cmux/</guid>
      <description>&lt;p&gt;Ever faced the problem of having multiple ports in an application, one for each service?
In this post, I&amp;rsquo;m going to brief about how to run multiple services via the same listener port.
&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we used to have one port to serve HTTP requests, one for gRPC and one more for internal communication among the servers.
But now we just use one port for all the outside facing services and one for internal server communications.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/soheilhy/cmux&#34;&gt;Cmux&lt;/a&gt; is a connection multiplexing library for Go. It allows you to differentiate services based on the payload. Hence, you can serve HTTP, HTTPS, gRPC, etc on the same port. For complete information on the protocols supported, refer to their &lt;a href=&#34;https://godoc.org/github.com/soheilhy/cmux&#34;&gt;godoc&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Let us jump into the three simple steps with some code sample and get this working in a jiffy.&lt;/p&gt;

&lt;p&gt;First setup the different services as you would usually do. In our case we setup a gRPC service and an HTTP handler function.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Setup gRPC server.
type grpcServer struct{}

func (s *grpcServer) Query(ctx context.Context,
  req *graph.Request) (*graph.Response, error) {
  .
  .
  .
}

// Handler function for http/https queries.
func queryHandler(w http.ResponseWriter, r *http.Request) {
  addCorsHeaders(w)
  .
  .
  .

}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Second, write separate functions to start each service using a net.Listener object as if it is the only service using that listener.
Later we&amp;rsquo;ll multiplex a single TCP listener into multiple listeners.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Wrapper functions to start serving different services.

func serveGRPC(l net.Listener) {
  s := grpc.NewServer(grpc.CustomCodec(&amp;amp;query.Codec{}))
  graph.RegisterDgraphServer(s, &amp;amp;grpcServer{})
  if err := s.Serve(l); err != nil {
    log.Fatalf(&amp;quot;While serving gRpc request: %v&amp;quot;, err)
  }
}

func serveHTTP(l net.Listener) {
  if err := http.Serve(l, nil); err != nil {
    log.Fatalf(&amp;quot;While serving http request: %v&amp;quot;, err)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Third, create a listener object and multiplex it using a cmux matcher.
It&amp;rsquo;ll read the header bytes of exchanges and figure out which service to trigger by giving us a new sub-listener (We just call it that, though it&amp;rsquo;s actually just net.Listener) for every match.
We then call the services that we wrote earlier with these corresponding sub-listeners.
Look at the following code sample to get a better hang of the above-mentioned steps.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func setupServer() {
  go worker.RunServer(*workerPort) // For internal communication.

  // Create a listener at the desired port.
  l, err := net.Listen(&amp;quot;tcp&amp;quot;, fmt.Sprintf(&amp;quot;:%d&amp;quot;, *port))
  if err != nil {
    log.Fatal(err)
  }

  // Create a cmux object.
  tcpm := cmux.New(l)

  // Declare the match for different services required.
  httpl := tcpm.Match(cmux.HTTP1Fast())
  grpcl := tcpm.MatchWithWriters(
    cmux.HTTP2MatchHeaderFieldSendSettings(&amp;quot;content-type&amp;quot;, &amp;quot;application/grpc&amp;quot;))
  http2 := tcpm.Match(cmux.HTTP2())

  // Link the endpoint to the handler function.
  http.HandleFunc(&amp;quot;/query&amp;quot;, queryHandler)

  // Initialize the servers by passing in the custom listeners (sub-listeners).
  go serveGRPC(grpcl)
  go serveHTTP(httpl)
  go serveHTTP(http2)

  // Close the listener when done.
  go func() {
    &amp;lt;-closeCh
    // Stops listening further but already accepted connections are not closed.
    l.Close()
  }()

  log.Println(&amp;quot;grpc server started.&amp;quot;)
  log.Println(&amp;quot;http server started.&amp;quot;)
  log.Println(&amp;quot;Server listening on port&amp;quot;, *port)

  // Start cmux serving.
  if err := tcpm.Serve(); !strings.Contains(err.Error(),
    &amp;quot;use of closed network connection&amp;quot;) {
    log.Fatal(err)
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So, there we have it. A single port to cater to many services that you might be using.&lt;/p&gt;

&lt;p&gt;Hope you had fun with this post and learnt something new. Thanks for reading and do let us know your thoughts and how it works out for you.&lt;/p&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://mars.nasa.gov/mars2020/images/Mars-2020-Artist-Concept-Instrument-SuperCam-br2.jpg&#34;&gt;Mars 2020, Artist Concept Instrument&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Dgraph: JSON vs. Binary clients</title>
      <link>https://open.dgraph.io/post/protobuf/</link>
      <pubDate>Mon, 12 Sep 2016 10:54:15 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/protobuf/</guid>
      <description>&lt;p&gt;When I started building the initial version of the &lt;a href=&#34;https://github.com/dgraph-io/dgraphgoclient&#34;&gt;Dgraph Go client&lt;/a&gt;, we were looking for a serialization format which was fast, easy to use and supported multiple language runtimes. We finally implemented our client using &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt; which &lt;strong&gt;gave twice the speed and consumed two-third memory&lt;/strong&gt; compared to JSON according to our benchmarks.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 v0.2 already supported serialization to JSON for the HTTP client. For our language specific drivers, we wanted something that would give us some performance improvement over JSON. Though we use &lt;a href=&#34;https://google.github.io/flatbuffers/&#34;&gt;Flatbuffers&lt;/a&gt; for everything internally, they lacked support for encoding recursive data structures. Protocol buffers seemed the right choice because they worked with most of the &lt;a href=&#34;https://github.com/google/protobuf#protobuf-runtime-installation&#34;&gt;modern languages&lt;/a&gt; and could encode recursive data structures efficiently.&lt;/p&gt;

&lt;h2 id=&#34;how-to-use-protocol-buffers&#34;&gt;How to use Protocol Buffers&lt;/h2&gt;

&lt;p&gt;To use protocol buffers, you define the message (data structures that form the basis of communication) in a &lt;code&gt;.proto&lt;/code&gt; file and then compile it using the protocol buffer &lt;a href=&#34;https://github.com/google/protobuf/releases&#34;&gt;compiler&lt;/a&gt;. For communication, we use &lt;a href=&#34;http://www.grpc.io/&#34;&gt;gRPC&lt;/a&gt; which is an open-source RPC framework by Google. gRPC requires services to be defined in the same &lt;code&gt;.proto&lt;/code&gt; file. Using gRPC allows us to communicate in binary format which is faster than retrieving JSON formatted results.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// The Node object which can have other children node and properties.

message Node {
    uint64 uid = 1;
    string xid = 2;
    string attribute = 3;
    repeated Property properties = 4;
    repeated Node children = 5; // Each node can have multiple children
}

message Request {
    string query = 1;
    // and other fields
}

message Response {
    Node n = 1;
    // and other fields
}

// &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 service used for communication between the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 server and client over gRPC.

service Dgraph {
    rpc Query (Request) returns (Response) {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find the full &lt;code&gt;.proto&lt;/code&gt; file &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/graph/graphresponse.proto&#34;&gt;here&lt;/a&gt;. The &lt;code&gt;.proto&lt;/code&gt; file can be used to generate the corresponding Go code using the &lt;code&gt;protoc&lt;/code&gt; compiler and the runtime library.&lt;/p&gt;

&lt;h2 id=&#34;benchmarks&#34;&gt;Benchmarks&lt;/h2&gt;

&lt;p&gt;In Go, you can easily measure how your algorithm does (in terms of time and space) by writing benchmarks. Go benchmarks are unique in that they&amp;rsquo;d iterate over the test code &lt;code&gt;b.N&lt;/code&gt; number of times, where &lt;code&gt;b.N&lt;/code&gt; is adjusted until the benchmark function lasts long enough to be timed reliably.
To test how our implementation was doing against our JSON implementation we wrote benchmarks for it. But first, let&amp;rsquo;s understand what a benchmark is and how can we interpret its results.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s write a simple function, which just adds integers to a list.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func addToList() {
    list := make([]int, 10)
    for i := 0; i &amp;lt; 1000; i++ {
        list = append(list, i)
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s benchmarking code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func BenchmarkAddToList(b *testing.B) {
    b.ReportAllocs()
    for i := 0; i &amp;lt; b.N; i++ {
        addToList()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can run the above benchmark using &lt;code&gt;go test -bench=.&lt;/code&gt; Here, Go benchmark would repeatedly call the function with different values for &lt;code&gt;b.N&lt;/code&gt; until it can be timed reliably.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ go test -bench=.

BenchmarkAddToList-4  200000  8153 ns/op  22624 B/op  7 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here&amp;rsquo;s what the output means:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;200000 is the number of times the benchmark loop ran.&lt;/li&gt;
&lt;li&gt;8153 ns/op represents the time it took on average for an iteration of the loop to finish.&lt;/li&gt;
&lt;li&gt;22624 B/op is the number of bytes allocated per iteration.&lt;/li&gt;
&lt;li&gt;7 allocs/op is the number of distinct memory allocations per iteration.&lt;/li&gt;
&lt;li&gt;Note that we get B/op and allocs/op only if we call b.ReportAllocs() as part of the benchmark.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we change the line which initializes the slice to
&lt;code&gt;list := make([]int, 0, 1000)&lt;/code&gt; and run the benchmarks again, we get better results:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkAddToList-4  1000000  1618 ns/op  0 B/op  0 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The allocs/op reduced because we had already initialized the list with the appropriate size and the runtime doesn&amp;rsquo;t have to reallocate it when we append elements. Also the B/op reduced because the list is not initialized with 0 for all its elements.&lt;/p&gt;

&lt;h2 id=&#34;benchmarking-topb-against-tojson&#34;&gt;Benchmarking ToPB against ToJSON&lt;/h2&gt;

&lt;p&gt;After implementing serialization using the protocol buffers, to get exact metrics we wrote benchmark tests for our ToJson and ToProtocolBuffer methods. These methods convert the internal SubGraph data structure to a byte array which is transferred over the network. Benchmark tests are an excellent way to compare different implementations or to measure if new code leads to any improvements.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// Benchmark test for ToProtocolBuffer method.

func benchmarkToPB(file string, b *testing.B) {
    b.ReportAllocs()
    var sg SubGraph
    var l Latency

    // Reading the SubGraph data structure from a file.
    f, err := ioutil.ReadFile(file)
    if err != nil {
        b.Error(err)
    }

    buf := bytes.NewBuffer(f)
    dec := gob.NewDecoder(buf)
    err = dec.Decode(&amp;amp;sg)
    if err != nil {
        b.Error(err)
    }

    b.ResetTimer()
    // Running the benchmark tests.
    for i := 0; i &amp;lt; b.N; i++ {
        pb, err := sg.ToProtocolBuffer(&amp;amp;l)
        if err != nil {
            b.Fatal(err)
        }
        r := new(graph.Response)
        r.N = pb
        var c Codec
        if _, err = c.Marshal(r); err != nil {
            b.Fatal(err)
        }
    }
}

// Benchmark test for ToJSON
func benchmarkToJson(file string, b *testing.B) {
    b.ReportAllocs()
    var sg SubGraph
    var l Latency

    f, err := ioutil.ReadFile(file)
    if err != nil {
        b.Error(err)
    }

    buf := bytes.NewBuffer(f)
    dec := gob.NewDecoder(buf)
    err = dec.Decode(&amp;amp;sg)
    if err != nil {
        b.Error(err)
    }

    b.ResetTimer()
    for i := 0; i &amp;lt; b.N; i++ {
        if _, err := sg.ToJSON(&amp;amp;l); err != nil {
            b.Fatal(err)
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find the complete benchmark tests &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query_test.go&#34;&gt;here&lt;/a&gt;. There are some differences in the algorithm that converts the internal Subgraph structure to JSON/Protocol Buffers. You can have a look at the code responsible for this &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/query.go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Using these benchmark tests we were able to improve our metrics by over 50% by switching over to &lt;code&gt;[]byte&lt;/code&gt; from &lt;code&gt;{}interface&lt;/code&gt; for &lt;code&gt;ObjectValue&lt;/code&gt; as part of &lt;a href=&#34;https://github.com/dgraph-io/dgraph/pull/86&#34;&gt;this change&lt;/a&gt;. Later when we shifted to Gogo Protobuf, we compared these benchmarks again with the previous ones to confirm improvement.&lt;/p&gt;

&lt;h4 id=&#34;marshalling&#34;&gt;Marshalling&lt;/h4&gt;

&lt;p&gt;This is how the final benchmark results compare for a query which returns 1000 entities in the result.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToJSON_1000_Director-2  500  2512808 ns/op  560427 B/op  9682 allocs/op
BenchmarkToPB_1000_Director-2   2000  1338410 ns/op  196743 B/op  3052 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The benchmarks show that ToPB method is almost &lt;strong&gt;2x faster&lt;/strong&gt; than ToJSON as it takes much lesser nanoseconds per operation. The bytes allocated per operation show that ToPB &lt;strong&gt;allocates 65% less memory&lt;/strong&gt; compared to ToJSON. You could find more information about those benchmarks and what we changed to get here in our &lt;a href=&#34;https://github.com/dgraph-io/dgraph/blob/master/query/benchmark/README.txt&#34;&gt;README&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;unmarshalling&#34;&gt;Unmarshalling&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToJSONUnmarshal_1000_Director-4  1000  1279297 ns/op  403746 B/op  5144 allocs/op
BenchmarkToPBUnmarshal_1000_Director-4    3000   489585 ns/op  202256 B/op  5522 allocs/op
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can see that unmarshalling on the client would also be &lt;strong&gt;2.6x faster&lt;/strong&gt; for protocol buffers compared to JSON. ToPB &lt;strong&gt;allocates 50% less memory&lt;/strong&gt; compared to ToJSON.&lt;/p&gt;

&lt;h3 id=&#34;golang-protobuf-vs-gogo-protobuf&#34;&gt;Golang protobuf vs. Gogo protobuf&lt;/h3&gt;

&lt;p&gt;If both your server and client are written in Go, then we recommend &lt;a href=&#34;https://github.com/gogo/protobuf&#34;&gt;Gogo Protobuf&lt;/a&gt; instead of &lt;a href=&#34;https://github.com/golang/protobuf&#34;&gt;Golang Protobuf&lt;/a&gt; as the runtime library. Gogo has &lt;strong&gt;2.3x faster marshaling while allocating 80% fewer bytes&lt;/strong&gt; per operation and &lt;strong&gt;1.5x faster unmarshalling&lt;/strong&gt; compared to Golang protobuf as shown in the benchmarks below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;BenchmarkToPBMarshal_1000_Director-4    3000  360545 ns/op 226504 B/op   22 allocs/op # Golang protobuf
BenchmarkToPBMarshal_1000_Director-4    10000 156820 ns/op 49152 B/op     1 allocs/op # Gogo protobuf

BenchmarkToPBUnmarshal_1000_Director-4  2000  733481 ns/op 200241 B/op 5523 allocs/op # Golang protobuf
BenchmarkToPBUnmarshal_1000_Director-4  3000  487745 ns/op 202256 B/op 5522 allocs/op # Gogo protobuf
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that Gogo protobuf has support only for Go as of now. However, if you are using some other language, this isn&amp;rsquo;t a problem. Gogo protobuf is backward compatible with Golang protobuf. Our Python and Java clients can still interact with the server (which does marshaling using Gogo), hence making Gogo a safe choice.&lt;/p&gt;

&lt;h2 id=&#34;recommendations&#34;&gt;Recommendations&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;If you are interacting with the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 from the browser directly with Javascript, we recommend that you use the more browser-friendly JSON.&lt;/li&gt;
&lt;li&gt;If you are interacting with &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 through one of our language drivers, we recommend you do it using gRPC and protocol buffers.&lt;/li&gt;
&lt;li&gt;If you are using Go client with gRPC, you will automatically be using the faster Gogo protobuf.&lt;/li&gt;
&lt;li&gt;Overall, &lt;strong&gt;fastest way to query &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is via a Go client communicating over gRPC.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We would love to hear about your interaction with the &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 server.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://www.nasa.gov/image-feature/sept-14-1966-view-from-gemini-xi-850-miles-above-the-earth/&#34;&gt;View From Gemini XI, 850 Miles Above the Earth&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Gru: Open source solution for better technical interviews</title>
      <link>https://open.dgraph.io/post/gru/</link>
      <pubDate>Thu, 21 Jul 2016 11:53:04 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/gru/</guid>
      <description>&lt;p&gt;Candidate &lt;strong&gt;REJECTED&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;4 out of 5 interviewers had liked the candidate. I was one of the 4. He had received either above or very close to 3.0, which is a good score. The interviewer who didn&amp;rsquo;t like the candidate had been at Google since early 2004. And he didn&amp;rsquo;t like the candidate&amp;rsquo;s joke question about whether he was very rich because he joined before Google went IPO. &lt;em&gt;I guess he wasn&amp;rsquo;t.&lt;/em&gt;
&lt;/p&gt;

&lt;p&gt;The system in place was methodical. On a scale of 0.0 to 5.0, only terrible candidates received less than 2.0. And only in very rare cases did someone receives above 4.0. Anything above 3.0 was a pretty solid YES for hire. But how the interviewers scored a candidate was very subjective. There was no standardized training for interviewers on how to interview. Some people tend to give higher scores; some tend to give lower scores. So, the hiring committee had been asked to take the interviewer&amp;rsquo;s previous scoring patterns into account, along with how much evidence and conviction they had presented in the feedback form.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;It was duct tape on a broken system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;It&amp;rsquo;s not an issue specific to Google. Many tech companies follow some variance of the same approach. Two phone screens + five onsite technical interviews, followed by feedback presented to a committee which then decided if the candidate should be hired or not.&lt;/p&gt;

&lt;p&gt;Except that the interviewers have no particular training in judging other people. Most would ask one question; which would get dragged on for the entire length of the interview. If the candidate did well on that question, they might ask another one. So, if the candidate messes up that first question, there&amp;rsquo;s no coming back, mostly even including the rest of the interviews (unless you do exceptionally well in the rest).&lt;/p&gt;

&lt;p&gt;Also, given the inflow of smart young engineers flowing into the valley, the questions are generic enough to be answered by &lt;em&gt;anyone&lt;/em&gt;. So, these drill down to basic computer science concepts &amp;ndash; graphs, trees, sorting, and other algorithms. The candidate is expected to come up with a solution and code it up on a whiteboard within the allocated time under pressure.&lt;/p&gt;

&lt;p&gt;Not surprisingly, &lt;strong&gt;experienced professionals tend to do worse at these interviews than fresh grads&lt;/strong&gt;. Very few professional tech problem can be coded up in 20 mins. Over years of coding, they lose the practice of solving simple problems under time pressure, instead focusing on deeper, harder design problems.&lt;/p&gt;

&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Google: 90% of our engineers use the software you wrote (Homebrew), but you can’t invert a binary tree on a whiteboard so fuck off.&lt;/p&gt;&amp;mdash; Max Howell (@mxcl) &lt;a href=&#34;https://twitter.com/mxcl/status/608682016205344768&#34;&gt;June 10, 2015&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;

&lt;p&gt;I&amp;rsquo;m convinced that the existing technical interview system is expensive and broken.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Without any objective measurement, judging the smarts, skills and experience of an engineer is just handwaving.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Triplebyte recently &lt;a href=&#34;http://blog.triplebyte.com/three-hundred-programming-interviews-in-thirty-days&#34;&gt;came up with a post about hiring&lt;/a&gt;. I found it instantly interesting. With a lot of data, they found a higher correlation between a quiz and successful candidates; and a lower one between coding questions and successful candidates.
This got us thinking.
&lt;strong&gt;If we wanted to design an objective interviewing system, we should design a quiz.&lt;/strong&gt;
It would have multiple benefits:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A single question wouldn&amp;rsquo;t dictate the entire interview. If the candidate is stuck, they can just skip the question.&lt;/li&gt;
&lt;li&gt;Focus on different aspects of systems and algorithms, with multiple questions from each. Looking at a final report would make it clear where the strengths and weaknesses of the candidate lie.&lt;/li&gt;
&lt;li&gt;Give us an objective score, which we can then use to compare them against other candidates.&lt;/li&gt;
&lt;li&gt;Generate a common repository of interview questions, which can ascertain that any leaked questions can&amp;rsquo;t be asked again, and new ones can be added collectively by engineers.&lt;/li&gt;
&lt;li&gt;Cut down on engineers&amp;rsquo; time spent on interviewing significantly. That in itself is a huge benefit about this system. &lt;strong&gt;Any human interaction can then focus on the cultural fit&lt;/strong&gt;, which I think is equally important to technical skills.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And we did exactly this. We painstakingly and after much cross-examination came up with 30 or so quiz questions in the house. These questions test various aspects of algorithms, concurrency and server interaction.&lt;/p&gt;

&lt;p&gt;Over the past months, we have had 20 candidates take our quiz. It&amp;rsquo;s a small number, but it&amp;rsquo;s still telling. The following graph shows how the candidates fared.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/score.png&#34; alt=&#34;Graph representing scores of different candidates&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the red dots represent the score (y-axis left), and the green dots represent the time taken (y-axis right). Candidates with experience in big companies are tagged as such - GB for Googlers who primarily worked on backend/infrastructure projects, GO for Googlers who worked on other projects, Intel, Microsoft and Amazon. Every other company whose name we didn&amp;rsquo;t recognize (startup/smaller company) is tagged as OC.&lt;/p&gt;

&lt;p&gt;What we can learn from this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we have an affinity for Googlers!&lt;/li&gt;
&lt;li&gt;The performance of Googlers on our quiz varied quite a lot. Googlers with backend experience performed not only great but the best out of all candidates.&lt;/li&gt;
&lt;li&gt;Googlers from other fields didn&amp;rsquo;t fare so well. This goes to show that there&amp;rsquo;s quite a significant difference in skills and experience of Googlers working on different projects.&lt;/li&gt;
&lt;li&gt;Note also that there&amp;rsquo;s a selection bias here because our quiz includes questions about concurrency and distributed systems. Folks with frontend experience don&amp;rsquo;t deal with these problems on a regular basis and hence didn&amp;rsquo;t do so well; which in a way is a validation that the quiz system worked as intended.&lt;/li&gt;
&lt;li&gt;Worst scorers tend to take more time than the best. In fact, all 4 top scorers finished approximately under 50 mins, at least 10 mins before the test ended, because they ran out of questions to answer. In fact, the top scoring candidate finished the quiz in half the time!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;So, we decided to improve upon this basic quiz and converted it to an adaptive test.&lt;/strong&gt;
Based on Triplebyte&amp;rsquo;s and our experience, we know that best candidates take less time to solve the quiz.
We hypothesize if the best performers were allowed to answer more questions in the same fixed time, their score would have been significantly better.&lt;/p&gt;

&lt;p&gt;So, instead of showing a fixed number of questions to be answered in a given maximum time duration, we fix the time and let the candidates answer as many questions as they can in an hour.
And if they&amp;rsquo;re performing well, we show them harder questions carrying higher scores (and vice-versa).
This system would make the difference between an okay candidate and a stellar candidate much more evident.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In fact, the best candidates would become outliers.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This inspiration is what &lt;a href=&#34;https://github.com/dgraph-io/gru&#34;&gt;lead to Gru&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;gru-finding-the-right-minions&#34;&gt;Gru: Finding the right minions&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Update: Gru&amp;rsquo;s design has changed significantly since this blog post. It has a browser based frontend, and uses &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 as backend. Over 200 candidates have taken &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 screening quiz using this new version of Gru.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gru is an open-source, adaptive quiz system written entirely in Go. Gru server has a simple design and is very easy to setup. It doesn&amp;rsquo;t require maintaining a database. Questions and candidate information are stored and read from files. All the communication between the client and the server is encrypted.&lt;/p&gt;

&lt;p&gt;Engineers collectively come up with questions from different areas and put them in a YAML formatted file. They tag them as &lt;code&gt;easy&lt;/code&gt;, &lt;code&gt;medium&lt;/code&gt;, &lt;code&gt;hard&lt;/code&gt;. You can add more tags to define the field, for, e.g., &lt;code&gt;concurrency&lt;/code&gt;, &lt;code&gt;graph&lt;/code&gt;, &lt;code&gt;sorting&lt;/code&gt;, &lt;code&gt;searching&lt;/code&gt;, etc. Each question has it&amp;rsquo;s own positive and negative scores, generally determined based on their complexity, uniqueness, or statistical probability of anyone getting it right, etc. Here&amp;rsquo;s an example from our demo quiz.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;- id: spacecraftmars
  str: Which year did we first land a spacecraft on Mars?
  correct: [spacecraftmars-1976]
  opt:
  - uid: spacecraftmars-2001
    str: 2001
  - uid: spacecraftmars-1976
    str: 1976
  - uid: spacecraftmars-1981
    str: 1981
  - uid: spacecraftmars-2013
    str: 2013
  positive: 5
  negative: 2.5
  tags: [medium,demo,mars]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Gru client runs on the command line and makes use of &lt;a href=&#34;https://github.com/gizak/termui&#34;&gt;termui&lt;/a&gt; for displaying the questions. The score of the candidate is always visible to them, providing real-time feedback on how they are doing during the test.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/gru_screenshot.png&#34; alt=&#34;Screenshot of the Gru client in action&#34; /&gt;&lt;/p&gt;

&lt;p&gt;If you want to get your hands dirty, we have a server running with some demo questions. The binaries for both Gru server and Gru client &lt;a href=&#34;https://github.com/dgraph-io/gru/releases&#34;&gt;are released here&lt;/a&gt;. To take the demo quiz, download the gruclient binary for your platform and just run it. It would automatically connect to our Gru server, and test your knowledge about humankind&amp;rsquo;s space missions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;You could start running Gru at your company for free. For more details on how Gru works and how to host it, please visit &lt;a href=&#34;https://wiki.dgraph.io/Gru&#34;&gt;Gru wiki&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Gru is a work in progress. Let us know what you think about it and how we could improve it on &lt;a href=&#34;https://discuss.dgraph.io&#34;&gt;discuss.dgraph.io&lt;/a&gt;. If you find any issues with Gru, &lt;a href=&#34;https://github.com/dgraph-io/gru/issues&#34;&gt;file a bug&lt;/a&gt;. Hope you like Gru and looking forward to a world with better technical interviews.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Gru Links
- &lt;a href=&#34;https://github.com/dgraph-io/gru&#34;&gt;Github repository&lt;/a&gt;
- &lt;a href=&#34;https://wiki.dgraph.io/Gru&#34;&gt;Gru Wiki&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Other posts I&amp;rsquo;ve written about interview process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@manishrjain/technical-interviews-open-ended-design-questions-ea7fff3486a7#.d6y5gyjys&#34;&gt;Technical Interviews&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/Why-cant-I-get-a-job-at-some-tech-giants-despite-doing-well-at-interviews/answer/Manish-Rai-Jain?srid=5tVr&#34;&gt;Why can&amp;rsquo;t I get a job despite doing well in interviews?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;</description>
    </item>
    
    <item>
      <title>Releasing v0.4</title>
      <link>https://open.dgraph.io/post/v0.4-release/</link>
      <pubDate>Thu, 14 Jul 2016 16:16:14 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/v0.4-release/</guid>
      <description>&lt;p&gt;Thanks for your feedback over the last couple of months. This release addresses some of the main pain points of using &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;installation&#34;&gt;Installation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 uses &lt;a href=&#34;http://rocksdb.org/&#34;&gt;RocksDB&lt;/a&gt;, which doesn&amp;rsquo;t have a native Go interface.
To use RocksDB via Go, Cgo is required, which makes doing a simple &lt;code&gt;go get&lt;/code&gt; installation of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 hard.
You first need to download, compile and install RocksDB, before installing &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
While &lt;code&gt;go get&lt;/code&gt; would still require more manual steps, starting this version only contributors to &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 would have to do that.&lt;/p&gt;

&lt;p&gt;We have embedded RocksDB into &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 binary and generated binaries for both Linux and Mac.
Now, most users can just choose one of these two options:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl https://get.dgraph.io | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Or, download the latest release &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases&#34;&gt;from Github&lt;/a&gt;. And extract the binaries to &lt;code&gt;/usr/local/bin&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# For Linux
$ sudo tar -C /usr/local/bin -xzf dgraph-linux-amd64-VERSION.tar.gz

# For Mac
$ sudo tar -C /usr/local/bin -xzf dgraph-darwin-amd64-VERSION.tar.gz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s it! These simple steps give you everything that you need to install &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;h2 id=&#34;documentation&#34;&gt;Documentation&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is a small team of enthusiastic developers, who like to code more than they like to write docs.
Even when the team writes documentation, it gets stale very quickly.
Honestly, that&amp;rsquo;s not a story unique to us. It&amp;rsquo;s a common problem affecting many projects.&lt;/p&gt;

&lt;p&gt;So, I thought why not solve it in a way where our documentation would never get stale.
I looked around for inspiration and found these two documentations that maximized screen estate usage and were easy to follow.
Each of these allowed search engines to easily index them while providing a lot of content per web page, which made doing a browser search easy.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.archlinux.org/&#34;&gt;Arch Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.gentoo.org/wiki/Main_Page&#34;&gt;Gentoo Linux&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I run Arch Linux on my desktop and laptop, and love it&amp;rsquo;s thorough up to date documentation.
So, I couldn&amp;rsquo;t be more excited about building something similar for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.&lt;/p&gt;

&lt;p&gt;So, after last 3 weeks of &lt;em&gt;no-coding-only-documentation&lt;/em&gt; effort, &lt;strong&gt;presenting &lt;a href=&#34;https://wiki.dgraph.io&#34;&gt;wiki.dgraph.io&lt;/a&gt;, the official source of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 documentation&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Just like Arch and Gentoo, it&amp;rsquo;s using MediaWiki software, which most people use on a daily basis (Thanks, Wikipedia).&lt;/p&gt;

&lt;p&gt;The main reason we chose wiki over other solutions is that it puts the power of editing right in the hands of the user.
So if a user spots an error, they have everything they need to fix it.
If the fix is more complicated, writing a note stating that this article or section is out of date is sufficient to get the team and more importantly, other users notified; so they can take appropriate action.&lt;/p&gt;

&lt;p&gt;And &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 community welcomed the change! We already have contributions to wiki from community members on various pages.
They keep us accountable and help maintain the quality of the documentation.
So, check it out, and if you find any issues or need more clarity in some section, log in, and edit the page. It&amp;rsquo;s that simple.&lt;/p&gt;

&lt;p&gt;Btw, if you installed &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 above, this is the page you&amp;rsquo;re looking for: &lt;a href=&#34;https://wiki.dgraph.io/Beginners_Guide&#34;&gt;https://wiki.dgraph.io/Beginners_Guide&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;clients&#34;&gt;Clients&lt;/h2&gt;

&lt;p&gt;In v0.3, we released a Go client for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
Thanks to our enthusiastic community, we got contributions for other languages. Now we have client code for both &lt;strong&gt;Java&lt;/strong&gt; and &lt;strong&gt;Python&lt;/strong&gt;.
Thanks &lt;a href=&#34;https://github.com/bitmalloc&#34;&gt;@bitmalloc&lt;/a&gt; and &lt;a href=&#34;https://github.com/mohitranka&#34;&gt;@mohitranka&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;In fact, Python client installation is as simple as:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ pip install -U pydgraph
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can read more about how to install and use them here: &lt;a href=&#34;https://wiki.dgraph.io/Clients&#34;&gt;https://wiki.dgraph.io/Clients&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;debugging&#34;&gt;Debugging&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Why did this query take so long to run?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This question stumped us! We didn&amp;rsquo;t know why. &lt;code&gt;logrus&lt;/code&gt; was useful only for general logging.
It couldn&amp;rsquo;t pinpoint which log was from which query, and show which steps of execution took how long, during the life of the query.&lt;/p&gt;

&lt;p&gt;The moment I realized that &lt;a href=&#34;https://grpc.io&#34;&gt;grpc.io&lt;/a&gt; is a ground-up rewrite of stubby, Google&amp;rsquo;s internal rpc system; I knew that we had to switch to it.
Stubby could provide amazing debugging information about each request to the server, and something that&amp;rsquo;s very well translated to grpc.&lt;/p&gt;

&lt;p&gt;So, after thorough effort, I was able to replace most of the &lt;code&gt;logrus.Log&lt;/code&gt; statements to use &lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;context&lt;/a&gt; and &lt;a href=&#34;https://godoc.org/golang.org/x/net/trace&#34;&gt;trace&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Thanks to these, you can now easily debug live queries running on &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
In fact, you can see all this in action on one of our demo &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 instance &lt;a href=&#34;http://dgraph.xyz/debug/requests?fam=Dgraph&amp;amp;b=0&amp;amp;exp=1&#34;&gt;via /debug/requests&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/07/14 06:54:55.615143    0.003184    Query
06:54:55.615157     .    14    ... Query received: { me(_xid_: m.0bxtg) { type.object.name.en film.actor.film { film.performance.film { type.object.name.en type.object.name.ru } } } }
06:54:55.615295     .   138    ... Xid: m.0bxtg Uid: 14685953405111677952
06:54:55.615312     .    17    ... Query parsed
06:54:55.615323     .    11    ... Sample value for attr: _root_ Val:
06:54:55.617188     .    55    ... (18 events discarded)
06:54:55.617190     .     3    ... Reply from child. Index: 1 Attr: type.object.name.ru
06:54:55.617192     .     2    ... Reply from child. Index: 0 Attr: film.performance.film
06:54:55.617194     .     2    ... Reply from child. Index: 1 Attr: film.actor.film
06:54:55.617195     .     1    ... Graph processed
06:54:55.618252     .  1057    ... Latencies: Total: 3.102143ms Parsing: 163.283µs Process: 1.88333ms Json: 601.266µs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These live queries are further categorized by how long they took to run. So, you can easily identify slower queries.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;2016/07/14 03:16:13.684030    0.100109    Query
03:16:13.684045     .    15    ... Query received: { me(_xid_: m.06pj8) { type.object.name.en film.director.film { type.object.name.en film.film.initial_release_date film.film.country film.film.starring { film.performance.actor { type.object.name.en } film.performance.character { type.object.name.en } } film.film.genre { type.object.name.en } } } }
03:16:13.684175     .   130    ... Xid: m.06pj8 Uid: 4255310415198890869
03:16:13.684193     .    17    ... Query parsed
03:16:13.684197     .     4    ... Sample value for attr: _root_ Val:
03:16:13.744452     .    41    ... (47 events discarded)
03:16:13.744458     .     5    ... Reply from child. Index: 1 Attr: film.performance.character
03:16:13.744466     .     8    ... Reply from child. Index: 4 Attr: film.film.genre
03:16:13.744477     .    11    ... Reply from child. Index: 1 Attr: film.director.film
03:16:13.744482     .     5    ... Graph processed
03:16:13.783501     . 39020    ... Latencies: Total: 99.461379ms Parsing: 156.916µs Process: 60.288205ms Json: 25.813948ms
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, you can see latency (in microseconds) statistics over various time intervals.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Count: 20    Mean: 59979    StdDev: 37593    Median: 84261
[    2048,    4096)    4    20.000%    20.000%
[    4096,    8192)    2    10.000%    30.000%
[    65536,    131072)    14    70.000%    100.000%
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the first time we have such data available, and we&amp;rsquo;ll tweak what gets reported over time to make these logs more and more useful.&lt;/p&gt;

&lt;p&gt;Hope you like these features and try out &lt;a href=&#34;https://github.com/dgraph-io/dgraph/releases&#34;&gt;the new release&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Thanks &lt;a href=&#34;https://twitter.com/mholt6&#34;&gt;Matt Holt&lt;/a&gt; from the Caddy team, for the inspiration to have &lt;code&gt;https://get.dgraph.io&lt;/code&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;https://www.nasa.gov/image-feature/cygnus-cargo-craft-released-from-space-station/&#34;&gt;Cygnus Cargo Craft Released From Space Station&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Custom encoding: Go implementation in net/rpc vs grpc and why we switched</title>
      <link>https://open.dgraph.io/post/rpc-vs-grpc/</link>
      <pubDate>Sat, 25 Jun 2016 19:06:45 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/rpc-vs-grpc/</guid>
      <description>&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we aim to build a low latency, distributed graph database.
This means our data is distributed among nodes in the cluster.
Executing a query means multiple nodes are communicating with each other.
To keep our latency of communication low, we use a new form of serialization library called &lt;a href=&#34;https://google.github.io/flatbuffers/&#34;&gt;Flatbuffers&lt;/a&gt;.

&amp;gt; What sets FlatBuffers apart is that it represents hierarchical data in a flat binary buffer in such a way that it can still be accessed directly without parsing/unpacking, while also still supporting data structure evolution (forwards/backwards compatibility).
&amp;gt; The only memory needed to access your data is that of the buffer.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How is Flatbuffers better than &lt;a href=&#34;https://developers.google.com/protocol-buffers/&#34;&gt;Protocol Buffers&lt;/a&gt;&lt;/strong&gt;? FlatBuffers does not need a parsing/unpacking step to a secondary representation before you can access data, often coupled with per-object memory allocation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 responses can contain millions of entities and binary blob values.
And the fact that Flatbuffers doesn&amp;rsquo;t need to recreate the entire information in language specific data structures is very helpful for both memory and speed.&lt;/p&gt;

&lt;p&gt;Also, TCP is always going to be faster than HTTP, because HTTP is one extra layer on top of TCP.
So, our goal was to implement communication using RPC over custom encoding utilizing Flatbuffers.&lt;/p&gt;

&lt;h1 id=&#34;go-net-rpc&#34;&gt;Go net/rpc&lt;/h1&gt;

&lt;p&gt;Our first approach was to use Go language library &lt;code&gt;net/rpc&lt;/code&gt; and implement custom encoding in it.&lt;/p&gt;

&lt;p&gt;Helper function to deal with writing and parsing header for the payload:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;bytes&amp;quot;
    &amp;quot;encoding/binary&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;

    &amp;quot;github.com/dgraph-io/dgraph/x&amp;quot;
)

type Query struct {
    Data []byte
}

type Reply struct {
    Data []byte
}

func writeHeader(rwc io.ReadWriteCloser, seq uint64,
    method string, data []byte) error {

    var bh bytes.Buffer
    var rerr error

    // In package x: func SetError(prev *error, n error)
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, seq))
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, int32(len(method))))
    x.SetError(&amp;amp;rerr, binary.Write(&amp;amp;bh, binary.LittleEndian, int32(len(data))))
    _, err := bh.Write([]byte(method))
    x.SetError(&amp;amp;rerr, err)
    if rerr != nil {
        return rerr
    }
    _, err = rwc.Write(bh.Bytes())
    return err
}

func parseHeader(rwc io.ReadWriteCloser, seq *uint64,
    method *string, plen *int32) error {

    var err error
    var sz int32
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, seq))
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, &amp;amp;sz))
    x.SetError(&amp;amp;err, binary.Read(rwc, binary.LittleEndian, plen))
    if err != nil {
        return err
    }

    buf := make([]byte, sz)
    n, err := rwc.Read(buf)
    if err != nil {
        return err
    }
    if n != int(sz) {
        return fmt.Errorf(&amp;quot;Expected: %v. Got: %v\n&amp;quot;, sz, n)
    }
    *method = string(buf)
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Code at server to read requests and write responses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;io&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net/rpc&amp;quot;
)

type ServerCodec struct {
    Rwc        io.ReadWriteCloser
    payloadLen int32
}

func (c *ServerCodec) ReadRequestHeader(r *rpc.Request) error {
    return parseHeader(c.Rwc, &amp;amp;r.Seq, &amp;amp;r.ServiceMethod, &amp;amp;c.payloadLen)
}

func (c *ServerCodec) ReadRequestBody(data interface{}) error {
    b := make([]byte, c.payloadLen)
    _, err := io.ReadFull(c.Rwc, b)
    if err != nil {
        return err
    }

    if data == nil {
        // If data is nil, discard this request.
        return nil
    }
    query := data.(*Query)
    query.Data = b
    return nil
}

func (c *ServerCodec) WriteResponse(resp *rpc.Response,
    data interface{}) error {

    if len(resp.Error) &amp;gt; 0 {
        log.Fatal(&amp;quot;Response has error: &amp;quot; + resp.Error)
    }
    if data == nil {
        log.Fatal(&amp;quot;Worker write response data is nil&amp;quot;)
    }
    reply, ok := data.(*Reply)
    if !ok {
        log.Fatal(&amp;quot;Unable to convert to reply&amp;quot;)
    }

    if err := writeHeader(c.Rwc, resp.Seq,
        resp.ServiceMethod, reply.Data); err != nil {
        return err
    }

    _, err := c.Rwc.Write(reply.Data)
    return err
}

func (c *ServerCodec) Close() error {
    return c.Rwc.Close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Similarly, the code at the client to read requests and write responses:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;errors&amp;quot;
    &amp;quot;fmt&amp;quot;
    &amp;quot;io&amp;quot;
    &amp;quot;log&amp;quot;
    &amp;quot;net/rpc&amp;quot;
)

type ClientCodec struct {
    Rwc        io.ReadWriteCloser
    payloadLen int32
}

func (c *ClientCodec) WriteRequest(r *rpc.Request, body interface{}) error {
    if body == nil {
        return fmt.Errorf(&amp;quot;Nil request body from client.&amp;quot;)
    }

    query := body.(*Query)
    if err := writeHeader(c.Rwc, r.Seq, r.ServiceMethod, query.Data); err != nil {
        return err
    }
    n, err := c.Rwc.Write(query.Data)
    if n != len(query.Data) {
        return errors.New(&amp;quot;Unable to write payload.&amp;quot;)
    }
    return err
}

func (c *ClientCodec) ReadResponseHeader(r *rpc.Response) error {
    if len(r.Error) &amp;gt; 0 {
        log.Fatal(&amp;quot;client got response error: &amp;quot; + r.Error)
    }
    if err := parseHeader(c.Rwc, &amp;amp;r.Seq,
        &amp;amp;r.ServiceMethod, &amp;amp;c.payloadLen); err != nil {
        return err
    }
    return nil
}

func (c *ClientCodec) ReadResponseBody(body interface{}) error {
    buf := make([]byte, c.payloadLen)
    _, err := io.ReadFull(c.Rwc, buf)
    reply := body.(*Reply)
    reply.Data = buf
    return err
}

func (c *ClientCodec) Close() error {
    return c.Rwc.Close()
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Also, each server should be able to send multiple requests in parallel.
So, we built a connection pool to create, store and reuse multiple connections:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package conn

import (
    &amp;quot;net&amp;quot;
    &amp;quot;net/rpc&amp;quot;
    &amp;quot;strings&amp;quot;
    &amp;quot;time&amp;quot;

    &amp;quot;github.com/dgraph-io/dgraph/x&amp;quot;
)

var glog = x.Log(&amp;quot;conn&amp;quot;) // In package x: func Log(p string) *logrus.Entry

type Pool struct {
    clients chan *rpc.Client
    Addr    string
}

func NewPool(addr string, maxCap int) *Pool {
    p := new(Pool)
    p.Addr = addr
    p.clients = make(chan *rpc.Client, maxCap)
    client, err := p.dialNew()
    if err != nil {
        glog.Fatal(err)
        return nil
    }
    p.clients &amp;lt;- client
    return p
}

func (p *Pool) dialNew() (*rpc.Client, error) {
    d := &amp;amp;net.Dialer{
        Timeout: 3 * time.Minute,
    }
    var nconn net.Conn
    var err error
    // This loop will retry for 10 minutes before giving up.
    for i := 0; i &amp;lt; 60; i++ {
        nconn, err = d.Dial(&amp;quot;tcp&amp;quot;, p.Addr)
        if err == nil {
            break
        }
        if !strings.Contains(err.Error(), &amp;quot;refused&amp;quot;) {
            break
        }

        glog.WithField(&amp;quot;error&amp;quot;, err).WithField(&amp;quot;addr&amp;quot;, p.Addr).
            Info(&amp;quot;Retrying connection...&amp;quot;)
        time.Sleep(10 * time.Second)
    }
    if err != nil {
        return nil, err
    }
    cc := &amp;amp;ClientCodec{
        Rwc: nconn,
    }
    return rpc.NewClientWithCodec(cc), nil
}

func (p *Pool) Call(serviceMethod string, args interface{},
    reply interface{}) error {

    client, err := p.get()
    if err != nil {
        return err
    }
    if err = client.Call(serviceMethod, args, reply); err != nil {
        return err
    }

    select {
    case p.clients &amp;lt;- client:
        return nil
    default:
        return client.Close()
    }
}

func (p *Pool) get() (*rpc.Client, error) {
    select {
    case client := &amp;lt;-p.clients:
        return client, nil
    default:
        return p.dialNew()
    }
}

func (p *Pool) Close() error {
    // We&#39;re not doing a clean exit here. A clean exit here would require
    // synchronization, which seems unnecessary for now. But, we should
    // add one if required later.
    return nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This worked well.
And both v0.2 and v0.3 of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 were using this code for the nodes to communicate with each other.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;the-switch&#34;&gt;The Switch&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/martian-receiving.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we spend Fridays learning and improving.
This means reading books, papers, articles, watching talks.
And we came across a great talk by Jeff Dean of Google: &lt;a href=&#34;https://discuss.dgraph.io/t/jeff-deans-talk-about-rapid-response-times/83&#34;&gt;Rapid Response Times&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;As I mentioned above, we care a lot about query latency.
After watching it a couple of times from two different conferences, the prime learning I gathered from his talk was:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Send request to the first replica, telling it that it&amp;rsquo;s going to send it to a second one.&lt;/li&gt;
&lt;li&gt;2 ms later, send the request to the second one, telling it that it&amp;rsquo;s already sent to the first one.&lt;/li&gt;
&lt;li&gt;When one of them starts processing the request, it sends a cancellation request directly to its peer.&lt;/li&gt;
&lt;li&gt;If the peer hasn&amp;rsquo;t started processing the request, it would just cancel the request.&lt;/li&gt;
&lt;li&gt;In a rare case, both of them process it and overall do twice the work.&lt;/li&gt;
&lt;li&gt;Overall, your latencies improve considerably due to this method.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Jeff_Dean_(computer_scientist)&#34;&gt;Jeff Dean&lt;/a&gt; has an impressive track record at Google. He&amp;rsquo;s behind almost every distributed system in production at Google.
So, when he gives a suggestion, you take it seriously.&lt;/p&gt;

&lt;p&gt;At v0.4, we&amp;rsquo;re not doing replication yet. So, we can&amp;rsquo;t send queries to multiple servers in parallel.
However, that&amp;rsquo;s how the system is going to look like a few minor releases down the lane.&lt;/p&gt;

&lt;p&gt;So, we started thinking about how we could change our custom encoding based RPC implementation to achieve something like this.
Around the same time, we were looking for a way to figure out slow rpcs on servers.
&lt;a href=&#34;https://forum.golangbridge.org/t/equivalent-of-rpcz-at-google/2609&#34;&gt;Dave Cheney&amp;rsquo;s response&lt;/a&gt; pointed us to &lt;a href=&#34;http://www.grpc.io/&#34;&gt;grpc.io&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While I had considered Google built &lt;code&gt;grpc&lt;/code&gt; in the past, I&amp;rsquo;d rejected it understanding that it requires you to use Protocol Buffers; but we&amp;rsquo;d already chosen to go with Flatbuffers.
But when &lt;a href=&#34;https://www.youtube.com/watch?v=sZx3oZt7LVg&#34;&gt;Sameer Ajmani&amp;rsquo;s talk&lt;/a&gt; pointed that &lt;code&gt;grpc&lt;/code&gt; is essentially a rewrite of Google internal Stubby from ground up, that got me to dig deeper.
&lt;code&gt;grpc&lt;/code&gt; came with &lt;code&gt;net/context&lt;/code&gt; which could easily do what Jeff Dean had talked about.
Also, it can help see live rpcs and track the slowest ones.&lt;/p&gt;

&lt;p&gt;Overall, there was a lot of advantages to switching to &lt;code&gt;grpc&lt;/code&gt;.
But, we didn&amp;rsquo;t want to give up the performance benefits of Flatbuffers.&lt;/p&gt;

&lt;p&gt;So, digging deeper, we found that &lt;code&gt;grpc&lt;/code&gt; did support custom encoding. And we implemented it.
This is the whole equivalent code implemented in &lt;code&gt;grpc&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/*
 * Copyright 2016 DGraph Labs, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the &amp;quot;License&amp;quot;);
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an &amp;quot;AS IS&amp;quot; BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package worker

import (
    &amp;quot;log&amp;quot;

    &amp;quot;google.golang.org/grpc&amp;quot;
)

type PayloadCodec struct{}

func (cb *PayloadCodec) Marshal(v interface{}) ([]byte, error) {
    p, ok := v.(*Payload)
    if !ok {
        log.Fatalf(&amp;quot;Invalid type of struct: %+v&amp;quot;, v)
    }
    return p.Data, nil
}

func (cb *PayloadCodec) Unmarshal(data []byte, v interface{}) error {
    p, ok := v.(*Payload)
    if !ok {
        log.Fatalf(&amp;quot;Invalid type of struct: %+v&amp;quot;, v)
    }
    p.Data = data
    return nil
}

func (cb *PayloadCodec) String() string {
    return &amp;quot;worker.PayloadCodec&amp;quot;
}

type Pool struct {
    conns chan *grpc.ClientConn
    Addr  string
}

func NewPool(addr string, maxCap int) *Pool {
    p := new(Pool)
    p.Addr = addr
    p.conns = make(chan *grpc.ClientConn, maxCap)
    conn, err := p.dialNew()
    if err != nil {
        glog.Fatal(err)
        return nil
    }
    p.conns &amp;lt;- conn
    return p
}

func (p *Pool) dialNew() (*grpc.ClientConn, error) {
    return grpc.Dial(p.Addr, grpc.WithInsecure(), grpc.WithInsecure(),
        grpc.WithCodec(&amp;amp;PayloadCodec{}))
}

func (p *Pool) Get() (*grpc.ClientConn, error) {
    select {
    case conn := &amp;lt;-p.conns:
        return conn, nil
    default:
        return p.dialNew()
    }
}

func (p *Pool) Put(conn *grpc.ClientConn) error {
    select {
    case p.conns &amp;lt;- conn:
        return nil
    default:
        return conn.Close()
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And this is the proto file with Payload and &lt;code&gt;service&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;syntax = &amp;quot;proto3&amp;quot;;

package worker;

message Payload {
    bytes Data = 1;
}

service Worker {
    rpc Hello (Payload) returns (Payload) {}
    rpc GetOrAssign (Payload) returns (Payload) {}
    rpc Mutate (Payload) returns (Payload) {}
    rpc ServeTask (Payload) returns (Payload) {}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;So, turns out, &lt;code&gt;grpc&lt;/code&gt; not only does custom encoding, but it also leads to&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;smaller code footprint.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/context&#34;&gt;net/context&lt;/a&gt;, which in turn allows client to cancel pending rpc requests to servers, among many other benefits.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://godoc.org/golang.org/x/net/trace&#34;&gt;net/trace&lt;/a&gt;, which allows tracing of rpcs and long-lived objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For more, read the &lt;a href=&#34;https://github.com/dgraph-io/dgraph/commit/c4629b907702748694712637cbef1fb2c1f15d07&#34;&gt;pull request which made this change&lt;/a&gt; across our code base.
Hope you find this useful.&lt;/p&gt;

&lt;p&gt;Also read:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Research paper on &lt;a href=&#34;https://www.google.com.au/url?sa=t&amp;amp;rct=j&amp;amp;q=&amp;amp;esrc=s&amp;amp;source=web&amp;amp;cd=2&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=0ahUKEwipuJ3rjsPNAhWEopQKHeeZBkMQFggiMAE&amp;amp;url=http%3A%2F%2Fresearch.google.com%2Fpeople%2Fjeff%2FBerkeley-Latency-Mar2012.pdf&amp;amp;usg=AFQjCNGnP9v7v9xN93MM6KPVJ7FcML6LvQ&amp;amp;bvm=bv.125596728,d.dGo&#34;&gt;Rapid Response Times&lt;/a&gt; by Jeff Dean.&lt;/li&gt;
&lt;li&gt;Blog post on &lt;a href=&#34;https://blog.golang.org/context&#34;&gt;Go Concurrency Patterns: Context&lt;/a&gt; by Sameer Ajmani.&lt;/li&gt;
&lt;li&gt;Slides on &lt;a href=&#34;https://talks.golang.org/2014/gotham-context.slide#1&#34;&gt;Cancellation, Context and Plumbing&lt;/a&gt; by Sameer Ajmani.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Images courtesy: &lt;a href=&#34;http://www.foxmovies.com/movies/the-martian&#34;&gt;The Martian&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;</description>
    </item>
    
    <item>
      <title>Can it really scale?</title>
      <link>https://open.dgraph.io/post/performance-throughput-latency/</link>
      <pubDate>Tue, 21 Jun 2016 10:20:32 +0530</pubDate>
      
      <guid>https://open.dgraph.io/post/performance-throughput-latency/</guid>
      <description>&lt;p&gt;In this post, we’ll look at how &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 performs on varying the number of nodes in the cluster, specs of the machine and load on the server to answer the ultimate question: &lt;em&gt;Can it really scale?&lt;/em&gt;
&lt;/p&gt;

&lt;h2 id=&#34;the-dataset&#34;&gt;The Dataset&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Freebase&#34;&gt;Freebase&lt;/a&gt; is an online collection of structured data which includes contributions from many sources including individual and user-generated contributions.
Currently, it has &lt;a href=&#34;https://developers.google.com/freebase/&#34;&gt;1.9 Billion RDF N-Triples&lt;/a&gt; worth 250GB of uncompressed data.
On top of that, this dataset is over 95% accurate with a complex and rich real world schema.
It is an ideal data set to test the performance of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
.
We decided not to use the entire data set as it wasn&amp;rsquo;t necessary for our goal here.&lt;/p&gt;

&lt;p&gt;Given our love for movies, we narrowed it down to the film data.
We ran some scripts and filtered in the movie data only.
All the data and scripts are present in &lt;a href=&#34;https://github.com/dgraph-io/benchmarks/tree/master/data&#34;&gt;our benchmarks repository&lt;/a&gt;.
There are two million nodes, which represent directors, actors, films and all the other objects in the database.
Moreover, 21 million edges (including 4M edges for names) are representing the relationships between actors, films, directors and all the other nodes in the database.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Some interesting information about this data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# film.film --{film.film.starring}--&amp;gt; [mediator] --{film.performance.actor}--&amp;gt; film.actor
# Film --&amp;gt; Mediator
$ zgrep &amp;quot;&amp;lt;film.film.starring&amp;gt;&amp;quot; rdf-films.gz | wc -l
1397647

# Mediator --&amp;gt; Actor
$ zgrep &amp;quot;&amp;lt;film.performance.actor&amp;gt;&amp;quot; rdf-films.gz | wc -l
1396420

# Film --&amp;gt; Director
$ zgrep &amp;quot;&amp;lt;film.film.directed_by&amp;gt;&amp;quot; rdf-films.gz | wc -l
242212

# Director --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.director.film&amp;gt;&amp;quot; rdf-films.gz | wc -l
245274

# Film --&amp;gt; Initial Release Date
$ zgrep &amp;quot;&amp;lt;film.film.initial_release_date&amp;gt;&amp;quot; rdf-films.gz | wc -l
240858

# Film --&amp;gt; Genre
$ zgrep &amp;quot;&amp;lt;film.film.genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
548152

# Genre --&amp;gt; Film
$ zgrep &amp;quot;&amp;lt;film.film_genre.films_in_this_genre&amp;gt;&amp;quot; rdf-films.gz | wc -l
546698

# Generated language names from names freebase rdf data.
$ zcat langnames.gz | awk &#39;{print $1}&#39; | uniq | sort | uniq | wc -l
55

# Total number of countries.
$ zgrep &amp;quot;&amp;lt;film.film.country&amp;gt;&amp;quot; rdf-films.gz | awk &#39;{print $3}&#39; | uniq | sort | uniq | wc -l
304
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;This data set contains information about ~480K actors, ~100K directors and ~240K films.
Some example of entries in the dataset are :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;m.0102j2vq&amp;gt; &amp;lt;film.actor.film&amp;gt; &amp;lt;m.011kyqsq&amp;gt; .
&amp;lt;m.0102xz6t&amp;gt; &amp;lt;film.performance.film&amp;gt; &amp;lt;m.0kv00q&amp;gt; .
&amp;lt;m.050llt&amp;gt; &amp;lt;type.object.name&amp;gt; “Aishwarya Rai Bachchan”@hr .
&amp;lt;m.0bxtg&amp;gt; &amp;lt;type.object.name&amp;gt; “Tom Hanks”@es .
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;terminology&#34;&gt;Terminology&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Throughput: Number of queries served by the server per second and received by the client&lt;/li&gt;
&lt;li&gt;Latency: Difference between the time when the server received the request and the time it finished processing the request&lt;/li&gt;
&lt;li&gt;95 percentile latency: The worst case latency which 95 percentage of users that query the database face&lt;/li&gt;
&lt;li&gt;50 percentile latency: The worst case latency which half the users that query the database face&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;

&lt;p&gt;All the testing was done on GCE instances. Each machine had 30GB of SSD and at least 7.5 GB of RAM. The number of cores varied depending on the experiments performed.&lt;/p&gt;

&lt;p&gt;The tests were run for 1-minute intervals during which all the parallel connections made requests to the database.
This was repeated ten times and throughput, mean latency, 95th percentile latency, 50th percentile latency were measured.
Note that for user-facing systems, measuring percentile latency is better than mean latency as the average can be skewed by outliers.&lt;/p&gt;

&lt;p&gt;In a multi-node cluster set up, the queries were distributed among each node in a round-robin fashion.
Note that no single machine contains all the data to answer these queries, in a multi-node cluster.
They still have to communicate with each other to respond to the queries.&lt;/p&gt;

&lt;h2 id=&#34;variables&#34;&gt;Variables&lt;/h2&gt;

&lt;p&gt;The parameters that were varied were:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;A number of parallel connections to the database. In Go, this equated to the number of goroutines a client would have. Each goroutine would run in an infinite loop, querying the database via a blocking function.&lt;/li&gt;
&lt;li&gt;Number of cores per server&lt;/li&gt;
&lt;li&gt;Number of servers in the cluster&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This gave us an idea of what to expect from the system and would help in predicting the configuration required to handle a given load.&lt;/p&gt;

&lt;h2 id=&#34;queries&#34;&gt;Queries&lt;/h2&gt;

&lt;p&gt;We ran broadly 2 categories of queries.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For each actor (478,936 actors), get their name, the films they acted in, and those films&amp;rsquo; names.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.actor.film {
      film.performance.film {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;For each director (90,063 directors), get their name, the films they directed, and names of all the genres of those films.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;{
  me ( _xid_ : XID ) {
    type.object.name.en
    film.director.film {
      film.film.genre {
        type.object.name.en
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;During each iteration, either an actor or a director category was chosen randomly.
Furthermore, for that category, an actor or director was chosen randomly; their &lt;code&gt;XID&lt;/code&gt; filled in in the query template.&lt;/p&gt;

&lt;h2 id=&#34;performance&#34;&gt;Performance&lt;/h2&gt;

&lt;p&gt;Let us look at some graphs obtained by varying the machine specs and the number of nodes in the cluster under different loads.&lt;/p&gt;

&lt;h3 id=&#34;vary-the-number-of-cores-in-a-single-instance&#34;&gt;Vary the number of cores in a single instance&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_thru.jpg&#34; alt=&#34;Throughput on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/cores_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of cores&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;With the same number of cores, when we increase the number of connections, i.e. load on the system, the throughput as well as the latency increase.&lt;/li&gt;
&lt;li&gt;Throughput increases till some point and then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;As expected, the latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;When we increase the number of cores, the latency decreases and the throughput increases.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;vary-number-of-instances&#34;&gt;Vary number of instances&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/topo_thru.jpg&#34; alt=&#34;Throughput on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_50.jpg&#34; alt=&#34;50 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_95.jpg&#34; alt=&#34;95 percentile latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/dist_lat_mean.jpg&#34; alt=&#34;mean latency on varying number of instances&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When we increase the number of parallel connections, the throughput increases, but then flattens out. This is the point where the computational capacity is being utilized almost fully.&lt;/li&gt;
&lt;li&gt;The latency increases almost linearly with the number of connections.&lt;/li&gt;
&lt;li&gt;Latency in the case of a single instance is observed to be the equal to (or a bit lower than) that of distributed configurations as the former doesn’t require any network calls. However, as the number of requests/load increase, the cumulative computational power comes into play and overshadows the latency incurred due to network calls. Hence, the latency reduces in the distributed version under higher loads.&lt;/li&gt;
&lt;li&gt;On comparing across the one, two and five node clusters, we can see that the latency, as well as the throughput, are better for configurations with a higher number of nodes, i.e., when there is more computational capacity at disposal. The throughput increases as we have greater computational power and can handle more queries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;From the above experiments, we can see a relationship between the throughput, latency and the overall computational power of the cluster.
The graphs show that the throughput increases as the computational power increases.
Which can be achieved either by increasing the number of cores on each server or the number of nodes in the cluster.&lt;/p&gt;

&lt;p&gt;The latency increases as the amount of load on the database increases.
However, the rate of the increase differs based on how much computational power we have available.&lt;/p&gt;

&lt;p&gt;This experiment also shows that there is a limit on how much computational power a single node can have, and once we reach that limit, scaling horizontally is the right option.
Not only that, but it also proves that scaling horizontally improves the performance.
Hence, having more replicas, distributing the dataset optimally across machines are some factors which help in improving the throughput and reducing the latency that the users face.&lt;/p&gt;

&lt;p&gt;Based on this experiment, our recommendation for running &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 would be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use as many cores as possible&lt;/li&gt;
&lt;li&gt;Have the servers geographically close-by so that network latency is reduced&lt;/li&gt;
&lt;li&gt;Distribute the data among servers and query them in a round-robin fashion for greater throughput&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These might seem pretty obvious recommendations for a distributed system, but &lt;strong&gt;this experiment proves that the underlying design of &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
 is scalable.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hope this helps you get a sense of what sort of performance you could expect out of Dgraph!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is derived from my report for B.tech Project on “A Distributed Implementation of the Graph Database System, Dgraph”.
The full report is &lt;a href=&#34;https://www.dropbox.com/s/7h4ytak39r2pdun/Ashwin_Thesis.pdf?dl=0&#34;&gt;available for download here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;


&lt;p&gt;&lt;em&gt;Top image: &lt;a href=&#34;http://mars.nasa.gov/images/PIA14840.jpg&#34;&gt;Mars Rover Landing via Nasa&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Wisemonk: A slackbot to move discussions from Slack to Discourse</title>
      <link>https://open.dgraph.io/post/wisemonk/</link>
      <pubDate>Wed, 15 Jun 2016 11:39:27 +1000</pubDate>
      
      <guid>https://open.dgraph.io/post/wisemonk/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Then there was the fact that we had so many channels and direct messages and group chats.
It multiplexed my brain and left me in a constant state of anxiety, feeling that I needed to always be on guard.
&lt;em&gt;— &lt;a href=&#34;https://blog.agilebits.com/2016/04/19/curing-our-slack-addiction/&#34;&gt;Dave Teare, Curing Our Slack Addiction&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-beginning&#34;&gt;The Beginning&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;— Manish Jain&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Sitting in a Japanese restaurant, waiting for my lunch, this is the line that hit me hard.
I’d experienced this exact thing in my previous company.&lt;/p&gt;

&lt;p&gt;Every block of time dedicated to coding was either interrupted by pings on the chat system, or a consistent feeling that you’re missing out.
Away from the desk, phones would start ringing every evening.
And they’d ring some more on the weekends, Sunday evenings in particular.
We were always doing something — the feeling was like being on &lt;em&gt;unpaid pager duty&lt;/em&gt;.
People are talking, and if I’m not around to show my presence, it would mean I’m not working.
But what was getting done, I wasn’t so clear about.&lt;/p&gt;

&lt;p&gt;So, when we started exploring options for both internal and external communication for &lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;Dgraph&lt;/a&gt;
, we wanted to do things differently.
We’d focus on asynchronous communication, so people can take their time before jumping in.
People can reply when they get to it — this might be hours later.
And there’ll be an incentive to modify your reply as more things become clear to you or you find better words to express yourself.
Something better than Email, but not so distracting as Slack.
The winner came out to be Discourse by Jeff Atwood and his team(edit: not Discord, another chat app).&lt;/p&gt;

&lt;p&gt;Having run it for over two months, we couldn’t have been happier.
Discourse sits somewhere between emails and real-time chat systems.
You feel like you’re having a real-time conversation.
But it won’t interrupt you in the middle of a 3-hour block of time you’ve set for distraction-free coding.
Discourse has become such an integral part of our company that we abandoned making decisions in meetings entirely.
All decisions happen over discourse, so everyone has a chance to voice their opinions and suggestions at their pace.
And others can embark on fact-finding and put figures together to support or deny arguments.
I’ve seen a lot smarter discussions, and hence decisions happening over our Discourse forum than over any other medium.&lt;/p&gt;

&lt;p&gt;Don’t get me wrong.
&lt;strong&gt;We still need Slack&lt;/strong&gt; for casual chit chat and team bonding.
But, Slack is an addiction.
You write one thing, someone replies; then someone else jumps in; and the result is an hour-long frenzy, where everyone feels like they’ve contributed a lot.
But a few hours later, you can’t pinpoint what changed.&lt;/p&gt;

&lt;p&gt;Most useful discussions require a bit more time and thought.
More than when someone else is typing while you’re in the middle of your sentence.&lt;/p&gt;

&lt;p&gt;This is what lead to Wisemonk.
This bot would push the conversation away from Slack into Discourse.
And this has to happen just when the team is getting sucked into the frenzy.
&lt;strong&gt;Before it’s too late&lt;/strong&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;how-we-built-it&#34;&gt;How we built it&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;— Pawan Rawal&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Wisemonk makes use of the Slack RTM API.
We make good use of the concurrency features in Go.
For each Slack channel passed in channels flag, we initialise an instance of type Counter.
The counter keeps track of the messages and other states for a Slack channel.
Each counter has a buffered channel (called &lt;code&gt;messages&lt;/code&gt;) to which Slack messages are sent.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cmap := make(map[string]*Counter)
for _, cid := range schannels {
  wg.Add(1)
  c := &amp;amp;Counter{channelId: cid}
  c.messages = make(chan *slack.Msg, 500)
  cmap[cid] = c
  go c.checkOrIncr(rtm, wg, memmap)
}
go listen(rtm)
wg.Wait()
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The listen function which runs as a goroutine gives us access to the messages sent on Slack.
We use this library to authenticate with and get messages from Slack.
Then the listen function passes messages on the relevant Go channel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;case *slack.MessageEvent:
  if sm, ok := msg.Data.(*slack.MessageEvent); ok {
  // Putting the message on the Counter it belongs to
  m := sm.Msg
  if c, ok := cmap[m.Channel]; ok {
    c.messages &amp;lt;- &amp;amp;m
  }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;code&gt;checkOrIncr&lt;/code&gt; method which runs as a goroutine for every counter keeps a count of the number of messages exchanged in a given interval.
Below is the basic version of the method.
It runs a never ending &lt;code&gt;for&lt;/code&gt; loop.
Now every time a message is received on the messages channel of the counter instance, it adds the message.
NewTicker function from the time package provides us with a Ticker, which sends the time on a channel with the period specified.
So every 10 seconds we get a time value and check if the count of messages exchanged increases the &lt;code&gt;maxmsg&lt;/code&gt; that we passed as a flag.
If it does, then we send a warning to the relevant Slack channel.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;func (c *Counter) checkOrIncr(rtm *slack.RTM, wg sync.WaitGroup, memmap map[string]string) {
   defer wg.Done()
   ticker := time.NewTicker(time.Second * 10)
   for {
       select {
       case msg := &amp;lt;-c.messages:
           c.Increment(msg, memmap)
       case &amp;lt;-ticker.C:
           count := c.Count()
           if count &amp;gt;= *maxmsg {
               go sendMessage(c, rtm)
           }
       }
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once the basic functionality was in place, we added integration with discourse.
Wisemonk stores the last n messages exchanged, creates a discourse topic with the messages when they exceed the max count and shares the URL with us on Slack.&lt;/p&gt;

&lt;p&gt;You can create a discourse topic on demand too and get the URL for it. This makes shifting conversations to Discourse super easy.&lt;/p&gt;

&lt;p&gt;For the weekends or in the evenings when you want to have a casual chat and don’t want to be interrupted by Wisemonk, you could ask him to meditate, and it won’t disturb you for a while.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;wisemonk-in-action&#34;&gt;Wisemonk in Action&lt;/h1&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-in-action.png&#34; alt=&#34;Wisemonk alerting us when we talk too much&#34; /&gt;
&lt;em&gt;Wisemonk alerting us when we talk too much&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-creating-topic.png&#34; alt=&#34;Asking wisemonk to create a topic&#34; /&gt;
&lt;em&gt;Asking wisemonk to create a topic&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://open.dgraph.io/images/wisemonk-meditating.png&#34; alt=&#34;Asking wisemonk to meditate&#34; /&gt;
&lt;em&gt;Asking wisemonk to meditate&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;parting-thoughts&#34;&gt;Parting Thoughts&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://github.com/dgraph-io/wisemonk#install&#34;&gt;Setting up wisemonk&lt;/a&gt; is super easy and we have found that it has enhanced our productivity a lot.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s open source and &lt;a href=&#34;https://github.com/dgraph-io/wisemonk&#34;&gt;available at Github&lt;/a&gt;, so feel free to contribute to it. We would love to hear about your usage of Wisemonk.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Yoda guides actions. Wisemonk guides conversations. Image courtesy: &lt;a href=&#34;http://www.wired.com/wp-content/uploads/2015/08/Yoda-featured1.jpg&#34;&gt;wired.com&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;div class=&#34;engage&#34;&gt;
	&lt;p&gt;&lt;strong&gt;We are building an open source, real time, horizontally scalable and distributed graph database.&lt;/strong&gt;&lt;/p&gt;
  &lt;table&gt;
    &lt;thead&gt;
    &lt;tr&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Get started with Dgraph.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://wiki.dgraph.io/Get_Started&#34; target=&#34;_blank&#34;&gt;https://wiki.dgraph.io/Get_Started&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;See our live demo.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io&#34; target=&#34;_blank&#34;&gt;https://dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;We are hiring. Join us!&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://dgraph.io/careers.html&#34; target=&#34;_blank&#34;&gt;https://dgraph.io/careers.html&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Star us on Github.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://github.com/dgraph-io/dgraph&#34; target=&#34;_blank&#34;&gt;https://github.com/dgraph-io/dgraph&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Ask us questions.&lt;/td&gt;
      &lt;td&gt;&lt;a href=&#34;https://discuss.dgraph.io&#34; target=&#34;_blank&#34;&gt;https://discuss.dgraph.io&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;
	&lt;strong&gt;We&#39;re starting to support enterprises in deploying Dgraph in production. &lt;a href=&#34;mailto:manish@dgraph.io&#34;&gt;Talk to us&lt;/a&gt;, if you want us to help you try out Dgraph at your organization.&lt;/strong&gt;
&lt;/div&gt;
&lt;br/&gt;</description>
    </item>
    
  </channel>
</rss>